<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>e+Thomas</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://thomaslau.github.io/"/>
  <updated>2019-08-12T17:12:06.864Z</updated>
  <id>http://thomaslau.github.io/</id>
  
  <author>
    <name>Thomas Lau</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mac电脑效能神器 Hammerspoon 入门和几个改善</title>
    <link href="http://thomaslau.github.io/2019/08/11/2019-08-11-on_hammerspoon/"/>
    <id>http://thomaslau.github.io/2019/08/11/2019-08-11-on_hammerspoon/</id>
    <published>2019-08-10T17:09:07.000Z</published>
    <updated>2019-08-12T17:12:06.864Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><i><strong>intro1</strong>: 你是否为在Mac电脑上切换不同的应用时也需要切换输入法而觉得恼怒？比如刚在微信中文下聊天，这时转向命令行工具，打了一半才发现是中文，不得不再重新输入？</i><br><i><strong>intro2</strong>: 如果你恰巧还是一名 hacker，是否苦于为了某些系统改进而搜索一堆 Applescript最后发现实现不了你要的功能。</i><br><i><strong>intro3</strong>: 这是去年写的短文，一直没时间(懒)再深入完善，今天修改了些，但也只做了简单的入门和介绍</i></p>
</blockquote>
<h2 id="Hammerspoon"><a href="#Hammerspoon" class="headerlink" title="Hammerspoon"></a>Hammerspoon</h2><p>最近升级了Mac系统，发现之前的hammerspoon有个脚本耗电偏高，该脚本就是实现打开 Terminal/iTerm2(命令行)/Spotlight等可以将输入法自动切换到拼音输入法，打开Chrome/Firefox等可以自动切换中文输入法。<br><a id="more"></a><br><blockquote><p>如果你还不了解Hammerspoon是什么，可以参考下面几个链接：</p>
<ol>
<li><a href="https://sspai.com/post/53992" target="_blank" rel="external">免费又强大的 macOS 自动化工具，Hammerspoon 可以让你少买很多 App</a></li>
<li><a href="https://www.v2ex.com/amp/t/553241" target="_blank" rel="external">推荐一个 MacOS 上用了就无法自拔的神器Hammerspoon</a></li>
<li><a href="https://juejin.im/entry/59737e16f265da6c317de185" target="_blank" rel="external">打造 macOS 的生产力环境 - Hammerspoon</a></li>
</ol>
</blockquote><br>最开始是在某论坛看到的一段脚本实现输入法自动切换，大概功能就是绑定 Alt+Tab快捷键，切换时就切换了输入法，很早期了。最近刚好想到 Hammerspoon 除了事件机制，窗口焦点事件，于是想想是否有这类机制的实现。</p>
<p>于是我尝试用 “Hammerspoon + 窗口事件” 搜索了一番，找到了几篇文章。实际上不看文章，只是看代码的话也并不难，就在 Hammerspoon.app的Contents/Resources/extensions/hs/window目录下，可以看到下图：<br><img src="/images/hammerspoon1.png" width="100%"></p>
<p>在这里，订阅 <strong>hs.window.filter.windowCreated</strong>，<strong>hs.window.filter.windowFocused</strong> 事件一般可以满足上述输入法自动切换的需求了。</p>
<p>但是应该怎样把上述联系起来，编码实现功能？我并不算是个深入了解 Hammerspoon 的用户，所以首先求助其文档，幸亏他的文档写的好又详细，<a href="http://www.hammerspoon.org/docs/hs.window.filter.html" target="_blank" rel="external">在这里hs.window.filter</a></p>
<p>上面帮助文档罗列描述很清楚，如果留意上面提到的 hs/window/filter.lua 的代码，我们还可以发现这段注释：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--- A *default windowfilter* (not to be confused with the default filter *within* a windowfilter) is provided as convenience;</span></div><div class="line"><span class="comment">--- it excludes some known apps and windows that are transient in nature, therefore unlikely to be "interesting" for e.g. window management.</span></div><div class="line"><span class="comment">--- `hs.window.filter.new()` (with no arguments) returns a copy of the default windowfilter that you can further tailor to your needs - see `hs.window.filter.default` and `hs.window.filter.new()` for more information.</span></div><div class="line"></div><div class="line"><span class="comment">---</span></div><div class="line"><span class="comment">--- -- set the exact scope of what you're interested in - see hs.window.filter:setAppFilter()</span></div><div class="line"><span class="comment">--- wf_terminal = wf.new&#123;'Terminal','iTerm2'&#125; -- all visible terminal windows</span></div><div class="line"><span class="comment">--- wf_timewaster = wf.new(false):setAppFilter('Safari',&#123;allowTitles='reddit'&#125;) -- any Safari windows with "reddit" anywhere in the title</span></div><div class="line"><span class="comment">--- wf_leftscreen = wf.new&#123;override=&#123;visible=true,fullscreen=false,allowScreens='-1,0',currentSpace=true&#125;&#125;</span></div><div class="line"><span class="comment">--- -- all visible and non-fullscreen windows that are on the screen to the left of the primary screen in the current Space</span></div><div class="line"><span class="comment">--- wf_editors_righthalf = wf.new&#123;'TextEdit','Sublime Text','BBEdit'&#125;:setRegions(hs.screen.primaryScreen():fromUnitRect'0.5,0/1,1')</span></div><div class="line"><span class="comment">--- -- text editor windows that are on the right half of the primary screen</span></div><div class="line"><span class="comment">--- wf_bigwindows = wf.new(function(w)return w:frame().area&gt;3000000 end) -- only very large windows</span></div><div class="line"><span class="comment">--- wf_notif = wf.new&#123;['Notification Center']=&#123;allowRoles='AXNotificationCenterAlert'&#125;&#125; -- notification center alerts</span></div><div class="line"><span class="comment">---</span></div><div class="line"><span class="comment">--- -- subscribe to events</span></div><div class="line"><span class="comment">--- wf_terminal:subscribe(wf.windowFocused,some_fn) -- run a function whenever a terminal window is focused</span></div><div class="line"><span class="comment">--- wf_timewaster:subscribe(wf.hasWindow,startAnnoyingMe):subscribe(wf.hasNoWindows,stopAnnoyingMe) -- fight procrastination :)</span></div><div class="line"><span class="comment">---</span></div></pre></td></tr></table></figure>
<p>这个注释是不是非常地清晰，看完后代码就出来了呢？<br><i><strong>是的！</strong></i><br>下面就是一个完整可运行的代码，直接拷贝到自己的 ~/.hammerspoon/init.lua  – Finally那段注释上面就可以运行了。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">-----------------------mine start-----------------------------</span></div><div class="line"><span class="comment">-- ADD by Thomas</span></div><div class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">Chinese</span><span class="params">()</span></span></div><div class="line">  hs.console.printStyledtext(<span class="string">"chinese"</span>)</div><div class="line">  hs.keycodes.currentSourceID(<span class="string">"com.apple.inputmethod.SCIM.ITABC"</span>)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">English</span><span class="params">()</span></span></div><div class="line">  hs.console.printStyledtext(hs.keycodes.currentSourceID())</div><div class="line">  hs.keycodes.currentSourceID(<span class="string">"com.apple.keylayout.ABC"</span>)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">hs.console.printStyledtext(<span class="string">"inputM:"</span> + hs.keycodes.currentSourceID())</div><div class="line"></div><div class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">set_app_input_method</span><span class="params">(app_name, set_input_method_function, event)</span></span></div><div class="line">  event = event <span class="keyword">or</span> hs.window.filter.windowFocused</div><div class="line">  hs.window.filter.new(app_name)</div><div class="line">    :subscribe(event, <span class="function"><span class="keyword">function</span><span class="params">()</span></span> set_input_method_function() <span class="keyword">end</span>)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">set_app_input_method(<span class="string">'Hammerspoon'</span>, English, hs.window.filter.windowCreated)</div><div class="line">set_app_input_method(<span class="string">'Spotlight'</span>, English, hs.window.filter.windowCreated)</div><div class="line"><span class="comment">-- set_app_input_method('Emacs', English)</span></div><div class="line">set_app_input_method(<span class="string">'Slack'</span>, English)</div><div class="line">set_app_input_method(<span class="string">'Terminal'</span>, English)</div><div class="line">set_app_input_method(<span class="string">'iTerm2'</span>, English)</div><div class="line">set_app_input_method(<span class="string">'Google Chrome'</span>, English)</div><div class="line">set_app_input_method(<span class="string">'WeChat'</span>, Chinese)</div><div class="line"><span class="comment">-----------------------mine end-----------------------------</span></div></pre></td></tr></table></figure>
<p>其中：</p>
<ol>
<li>“com.apple.inputmethod.SCIM.ITABC”/“com.apple.keylayout.ABC”就是我的电脑上在用的中英文输入法，<br>如果你不知道自己使用的输入法的名称可以切换对应输入法，打开 Hammerspoon 控制台，点击 Hammerspoon的 reload config，就会在Hammerspoon 控制台看到inputM 一段，就是你的输入法，替换上面对应名字即可。</li>
<li>如果有自己的应用需要，可以追加 set_app_input_method。</li>
</ol>
<h2 id="Bing-必应桌面的改进"><a href="#Bing-必应桌面的改进" class="headerlink" title="Bing 必应桌面的改进"></a>Bing 必应桌面的改进</h2><p>使用 awesome-hammerspoon.git 下的Bing脚本，可以自动更新自己的桌面壁纸和必应官方同步，但是我发现有几个问题：<br>1）不支持多桌面。现在大多数工作环境都是两个或多个显示器，使用该脚本，发现只有一个桌面壁纸更新了。<br>原因在于 hammerspoon 默认更新的是mainScreen，它还有一个primaryScreen甚至allScreens区别，所以这里需要改一下。<br>2）下载的壁纸没有保存下来<br>3）桌面壁纸在大陆其实用的是 bing 国内版搜索的壁纸，想使用更适合做背景的国外版壁纸该怎么办？<br>只需要在请求链接的时候加一个 ENSEARCH=BENVER=1 的cookie就可以了。</p>
<p>上面问题的解决方法：<br>修改.hammerspoon/Spoons/BingDaily.spoon/init.lua文件，将下面代码中 +开头的代码行替换-开头的源代码行即可：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">-        <span class="keyword">local</span> localpath = <span class="built_in">os</span>.<span class="built_in">getenv</span>(<span class="string">"HOME"</span>) .. <span class="string">"/.Trash/"</span> .. hs.http.urlParts(obj.full_url).lastPathComponent</div><div class="line">-        hs.screen.mainScreen():desktopImageURL(<span class="string">"file://"</span> .. localpath)</div><div class="line">+        <span class="keyword">local</span> localpath = <span class="built_in">os</span>.<span class="built_in">getenv</span>(<span class="string">"HOME"</span>) .. <span class="string">"/Public/bing/"</span> .. hs.http.urlParts(obj.full_url).queryItems[<span class="number">1</span>].id</div><div class="line">+        hs.console.printStyledtext(<span class="string">"desktopIMG:"</span> .. localpath)</div><div class="line">+        hs.screen.primaryScreen():desktopImageURL(<span class="string">"file://"</span> .. localpath)</div><div class="line">+        <span class="keyword">local</span> scs=hs.screen.allScreens()</div><div class="line">+        <span class="keyword">local</span> count = <span class="number">0</span></div><div class="line">+        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">pairs</span>(scs) <span class="keyword">do</span> count = count + <span class="number">1</span> <span class="keyword">end</span></div><div class="line">+        hs.console.printStyledtext(<span class="string">"table.size: "</span> .. count)</div><div class="line">+        <span class="keyword">for</span> i=<span class="number">1</span>,#scs <span class="keyword">do</span> scs[i]:desktopImageURL(<span class="string">"file://"</span> .. localpath) <span class="keyword">end</span></div><div class="line"></div><div class="line"></div><div class="line">-    <span class="keyword">local</span> user_agent_str = <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/603.2.4 (KHTML, like Gecko) Version/10.1.1 Safari/603.2.4"</span></div><div class="line">+    <span class="keyword">local</span> user_agent_str = <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36"</span></div><div class="line">-    hs.http.asyncGet(json_req_url, &#123;[<span class="string">"User-Agent"</span>]=user_agent_str&#125;, <span class="function"><span class="keyword">function</span><span class="params">(stat,body,header)</span></span></div><div class="line">+    hs.http.asyncGet(json_req_url, &#123;[<span class="string">"User-Agent"</span>]=user_agent_str,[<span class="string">"cookie"</span>]=<span class="string">"ENSEARCH=BENVER=1"</span>&#125;, <span class="function"><span class="keyword">function</span><span class="params">(stat,body,header)</span></span></div><div class="line"></div><div class="line">-                    <span class="keyword">local</span> localpath = <span class="built_in">os</span>.<span class="built_in">getenv</span>(<span class="string">"HOME"</span>) .. <span class="string">"/.Trash/"</span> .. hs.http.urlParts(obj.full_url).lastPathComponent</div><div class="line">+                    <span class="keyword">local</span> localpath = <span class="built_in">os</span>.<span class="built_in">getenv</span>(<span class="string">"HOME"</span>) .. <span class="string">"/Public/bing/"</span> .. hs.http.urlParts(obj.full_url).queryItems[<span class="number">1</span>].id</div></pre></td></tr></table></figure>
<h2 id="其他："><a href="#其他：" class="headerlink" title="其他："></a>其他：</h2><p>在.hammerspoon/Spoons 文件夹下修改canlendar/aclokck的分布位置/大小/用色都较简单直白，就不列代码了。</p>
<p>最后，主要是对 Hammerspoon 扩展支持的功能还没深入了解过，希望有时间可以再做点开发，根据个人使用来看可添加的效率脚本太多了.</p>
<h2 id="How"><a href="#How" class="headerlink" title="How"></a>How</h2><p>上面链接可见 Hammerspoon 是什么以及怎么用，可以重复下，非常简单：</p>
<p>1) 到官网下载并安装 <a href="https://github.com/Hammerspoon/hammerspoon/releases/latest" target="_blank" rel="external">Hammerspoon</a><br>2）最好给 Hammerspoon 授权，点击 “Enable Accessbility”<br><img src="/images/hammerspoon2.png" width="80%"><br>3）如果你是开发者，可以运行：</p>
<pre><code>git clone https://github.com/ashfinal/awesome-hammerspoon.git   .hammerspoon
</code></pre><p>否则可直接下载 并保存到你的home文件夹下 的 .hammerspoon目录。</p>
<p>实际上述2步完成就是可用了，但只提供基本功能，如有需求可以自己写脚本了。不过感谢强大的开源文化，许多网友就开源了许多自己写的脚本，一开始可以用 3 步里的脚本合集，应该是早且权威的。</p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><ol>
<li><a href="https://www.v2ex.com/amp/t/553241" target="_blank" rel="external">推荐一个 MacOS 上用了就无法自拔的神器Hammerspoon</a></li>
<li><a href="https://sspai.com/post/53992" target="_blank" rel="external">免费又强大的 macOS 自动化工具，Hammerspoon 可以让你少买很多 App</a></li>
<li><a href="https://yiming.dev/blog/2017/08/09/use-hammerspoon-to-auto-switch-input-methods/" target="_blank" rel="external">Use Hammerspoon to auto switch input methods
</a></li>
<li><a href="https://juejin.im/entry/59737e16f265da6c317de185" target="_blank" rel="external">打造 macOS 的生产力环境 - Hammerspoon</a></li>
<li><a href="http://www.hammerspoon.org/docs/hs.window.filter.html" target="_blank" rel="external">docs » hs.window.filter</a></li>
<li><a href="https://emacs-china.org/t/topic/6348/20" target="_blank" rel="external">Emacs China </a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;&lt;p&gt;&lt;i&gt;&lt;strong&gt;intro1&lt;/strong&gt;: 你是否为在Mac电脑上切换不同的应用时也需要切换输入法而觉得恼怒？比如刚在微信中文下聊天，这时转向命令行工具，打了一半才发现是中文，不得不再重新输入？&lt;/i&gt;&lt;br&gt;&lt;i&gt;&lt;strong&gt;intro2&lt;/strong&gt;: 如果你恰巧还是一名 hacker，是否苦于为了某些系统改进而搜索一堆 Applescript最后发现实现不了你要的功能。&lt;/i&gt;&lt;br&gt;&lt;i&gt;&lt;strong&gt;intro3&lt;/strong&gt;: 这是去年写的短文，一直没时间(懒)再深入完善，今天修改了些，但也只做了简单的入门和介绍&lt;/i&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Hammerspoon&quot;&gt;&lt;a href=&quot;#Hammerspoon&quot; class=&quot;headerlink&quot; title=&quot;Hammerspoon&quot;&gt;&lt;/a&gt;Hammerspoon&lt;/h2&gt;&lt;p&gt;最近升级了Mac系统，发现之前的hammerspoon有个脚本耗电偏高，该脚本就是实现打开 Terminal/iTerm2(命令行)/Spotlight等可以将输入法自动切换到拼音输入法，打开Chrome/Firefox等可以自动切换中文输入法。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="Tools" scheme="http://thomaslau.github.io/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch删除特殊字符索引</title>
    <link href="http://thomaslau.github.io/2019/08/07/2019-08-07-Deleting_ElasticSearch_unicode/"/>
    <id>http://thomaslau.github.io/2019/08/07/2019-08-07-Deleting_ElasticSearch_unicode/</id>
    <published>2019-08-06T17:09:07.000Z</published>
    <updated>2019-08-08T17:15:08.972Z</updated>
    
    <content type="html"><![CDATA[<p>长话短说，查看生产环境Elasticsearch (5.6版本) 时，发现一些如下有着非ascii码的索引</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">red zhangxin-xxx-༠༠༣༡.༠༣.༢༢</div><div class="line">red zhangxin-xxx-༠༠༣༡.༠༣.༢༣</div><div class="line">red zhangxin-xxx-༠༠༣༡.༠༣.༢༤</div><div class="line">red zhangxin-xxx-༠༠༣༡.༠༤.༡༢</div><div class="line">red zhangxin-xxx-༠༠༣༡.༠༤.༡༧</div><div class="line">red zh날炷gxꆀ鍀ᒶ⒐ጆ䬯ꀳ20₨炠.021</div></pre></td></tr></table></figure>
<p>上面是某系统因为历史缘故，使用用户的数据创建索引了，因暂时无法推动其做修改，于是需要考虑用脚本定时删除。<br><a id="more"></a><br>如果你对过程不感兴趣，可以考虑跳到 总结2 直接看方法。<br><i>题外话：上述看起来是藏文，用了bing/sogou翻译，识别为北欧语言(为：我的天呐)，看起来不一样而且不像，不过用google翻译像日期格式(为:0031.03.22)倒是接近。</i>i&gt;</p>
<p>不过，如果直接用 curl -XDELETE ‘10.135.20.38:9200/zhangxin-xxx-༠༠༣༡.༠༣.༢༢’ 会提示索引不存在，因为需要转义。<br>而且，ES也不存在POST方式删除索引的方法，索引需要修改为：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a3.%e0%bc%a2%e0%bc%a2</div><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a3.%e0%bc%a2%e0%bc%a3</div><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a3.%e0%bc%a2%e0%bc%a4</div><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a4.%e0%bc%a1%e0%bc%a2</div><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a4.%e0%bc%a1%e0%bc%a7</div><div class="line">curl -XDELETE 10.135.20.38:9200/zhangxin-xxx-%e0%bc%a0%e0%bc%a0%e0%bc%a3%e0%bc%a1.%e0%bc%a0%e0%bc%a4.%e0%bc%a1%e0%bc%a8</div><div class="line">curl -XDELETE <span class="string">'10.135.20.38:9200/zh%EB%82%A0%E7%82%B7gx%EA%86%80%00%E9%8D%80%E1%92%B6%E2%92%90%E1%8C%86%01%00%E4%AC%AF%EA%80%B3%32%30%E2%82%A8%E7%82%A0%2E%30%1A%00%32%31'</span></div></pre></td></tr></table></figure>
<p>方式删除，这里索引可以使用逗号分隔拼凑起来，不过为了脚本方便就一行一条了。</p>
<p>那么怎么去定位这些非正常字符的索引呢？</p>
<pre><code>curl -s 10.135.20.38:9200/_cat/indices?v|grep -P &apos;[\xB0\xA1-\xF7\xFE]+&apos;
</code></pre><p>上面索引就是用该行grep出来，不过按上述删完后，发现‘zh날炷gxꆀ鍀ᒶ⒐ጆ䬯ꀳ20₨炠.021’ 这个索引还在。</p>
<p>这让我有点不知所措，直到我把grep出来的结果保存，并用16进制模式查看时，才发现，原来是自己手动从服务器拷贝该索引时把部分不可string化的字符拷贝丢了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">curl -s 10.135.20.38:9200/_cat/indices?v|grep -P &apos;[\xB0\xA1-\xF7\xFE]+&apos;</div><div class="line">green  open   zh날炷gxꆀ鍀ᒶ⒐ጆ䬯ꀳ20₨炠.021          tfpRU2KeRCG6yBWhYq5J2w   5   1          1            0      9.2kb          4.6kb</div><div class="line"></div><div class="line"># 将上述结果打开vi十六进制模式，部分如下</div><div class="line">                                            7a68  green  open   zh</div><div class="line">0000010: eb82 a0e7 82b7 6778 ea86 8000 e98d 80e1  ......gx........</div><div class="line">0000020: 92b6 e292 90e1 8c86 0100 e4ac afea 80b3  ................</div><div class="line">0000030: 3230 e282 a8e7 82a0 2e30 1a00 3231       20.......0..21</div></pre></td></tr></table></figure></p>
<p>可以看到通过字符串拷贝时丢失，还是老老实实写脚本实现删除吧。</p>
<p>总结1</p>
<p>如下是完整实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 首先是之前通过curl命令进行 urlencode 编码的函数</div><div class="line">function urlencode() &#123;</div><div class="line">    local data</div><div class="line">    if [[ $# != 1 ]]; then</div><div class="line">        echo &quot;Usage: $0 str&quot;</div><div class="line">        return 1</div><div class="line">    fi</div><div class="line">    data=&quot;$(curl -s -o /dev/null -w %&#123;url_effective&#125; --get --data-urlencode &quot;$1&quot; &quot;&quot;)&quot;</div><div class="line">    # if [[ $? == 0 ]]; then</div><div class="line">    echo &quot;$&#123;data##/?&#125;&quot;</div><div class="line">    # fi</div><div class="line">    return 0</div><div class="line">&#125;</div><div class="line">function callDel()&#123;</div><div class="line">    indx=$(urlencode $1)</div><div class="line">    curl -s -XDELETE 10.135.20.38:9200/$indx</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其次合起来完整的脚本就是<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">curl -s 10.135.20.38:9200/_cat/indices?v|grep -P <span class="string">'[\xB0\xA1-\xF7\xFE]+'</span>| \ </div><div class="line">    awk <span class="string">'&#123;print $3&#125;'</span>|xargs -I@ -P4 bash -c <span class="string">"<span class="variable">$(declare -f urlencode; declare -f callDel)</span> ; callDel @ ; echo @ "</span></div></pre></td></tr></table></figure></p>
<p><i>题外话：起先怀疑这个urlencode有误，后来使用 python -c “import urllib;print urllib.quote(raw_input())” &lt;&lt;&lt; “zhangxin-xxx-༢༥༦༢.༠༤.༠༡” 也是如此。</i></p>
<p>总结2</p>
<p>上述方法可以完美运行，但是觉得有点麻烦，实现的不是非常的 Elasticsearch。</p>
<p>无意翻看了下 Elasticsearch 的索引匹配支持，显然索引匹配是不支持正则表达式的，但是支持通配符，include，excluse，具体代码可以看 Elasticsearch 的 IndexNameExpressionResolver 实现，在innerResolve 会判断是否支持。有个exclude模式是支持的。<br>即，也可以用这种方式去删除：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -XDELETE <span class="string">'10.135.20.38:9200/zhangxin-xxx-*,-zhangxin-xxx-2019.07.*'</span></div></pre></td></tr></table></figure></p>
<p>这句就表示删除 zhangxin-xxx- 除 zhangxin-xxx-2019.07- 开头的索引。</p>
<p>不过这个方案不如上面的通用，但是非常简单且清晰易懂。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;长话短说，查看生产环境Elasticsearch (5.6版本) 时，发现一些如下有着非ascii码的索引&lt;/p&gt;
&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;red zhangxin-xxx-༠༠༣༡.༠༣.༢༢&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;red zhangxin-xxx-༠༠༣༡.༠༣.༢༣&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;red zhangxin-xxx-༠༠༣༡.༠༣.༢༤&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;red zhangxin-xxx-༠༠༣༡.༠༤.༡༢&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;red zhangxin-xxx-༠༠༣༡.༠༤.༡༧&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;red zh날炷gxꆀ鍀ᒶ⒐ጆ䬯ꀳ20₨炠.021&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上面是某系统因为历史缘故，使用用户的数据创建索引了，因暂时无法推动其做修改，于是需要考虑用脚本定时删除。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="Tools" scheme="http://thomaslau.github.io/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>python 2.6.6 SimpleHTTPServer耗时的bug</title>
    <link href="http://thomaslau.github.io/2019/05/30/2019-05-30-python%202.6.6%20SimpleHTTPServer%E8%80%97%E6%97%B6%E7%9A%84bug/"/>
    <id>http://thomaslau.github.io/2019/05/30/2019-05-30-python 2.6.6 SimpleHTTPServer耗时的bug/</id>
    <published>2019-05-29T17:09:07.000Z</published>
    <updated>2019-08-08T16:58:03.156Z</updated>
    
    <content type="html"><![CDATA[<p>之前因为时间紧迫的缘故，在公司的CentOS 7 机器上部署一个快速实现的数据收集工具，考虑到避免其他语言发布和变更起来麻烦，于是就用 python+bash 实现。</p>
<p>服务端就是最简单不引入任何python包的SimpleHTTPServer+Handler实现的。</p>
<p>偶然一次看日志发现本来应该在三分钟内完成的一个同步/上报循环结果未能如期完成，每个请求看起来相隔十秒左右，最后定位下来是python2.6.6的问题。<br><a id="more"></a><br>简单起见，我用下面重现一下： 10.135.20.45上开了一个进程</p>
<p>   python -m SimpleHTTPServer 12888</p>
<p>在另外一台机器上</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[java@10-135-20-62 ~]$ cat curl-format.txt</div><div class="line">time_namelookup: %&#123;time_namelookup&#125;\n</div><div class="line">time_connect: %&#123;time_connect&#125;\n</div><div class="line">time_appconnect: %&#123;time_appconnect&#125;\n</div><div class="line">time_redirect: %&#123;time_redirect&#125;\n</div><div class="line">time_pretransfer: %&#123;time_pretransfer&#125;\n</div><div class="line">time_starttransfer: %&#123;time_starttransfer&#125;\n</div><div class="line">----------time_total: %&#123;time_total&#125;\n</div><div class="line">[java@10-135-20-62 ~]$ curl -w <span class="string">"@curl-format.txt"</span> -o /dev/null -s -L <span class="string">"10.135.20.45:12888"</span></div><div class="line">time_namelookup: 0.000</div><div class="line">time_connect: 0.000</div><div class="line">time_appconnect: 0.000</div><div class="line">time_redirect: 0.000</div><div class="line">time_pretransfer: 0.000</div><div class="line">time_starttransfer: 10.013</div><div class="line">----------time_total: 10.013</div></pre></td></tr></table></figure>
<p>这里两个问题：<br>1）一个简单的GET请求耗时10秒，10秒看起来像是服务器设置的超时时间。<br>2）而且10秒都花费在 starttransfer</p>
<p>如何定位问题？显然逐步打点耗时是可以的，但是如果用搜索引擎更快，我在python社区上找到一个提问，作者遇到同样现象，但是pytohn2.7以后就没有问题。</p>
<p>有个回答说是 pytohn解析header时候\r\n的问题，也有说是socket未close问题，我看了下代码，不像。</p>
<p>不过这个提问给了我思路，于是我比较了python 2.6/2.7各自的SimpleHTTPServer.py文件。<br>考虑到linux版本众多且你可能也记不住，友情提示一个定位该文件的方法：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[java@10-135-20-62 ~]$ python --version</div><div class="line">Python 2.6.6</div><div class="line">[java@10-135-20-62 ~]$ python -c <span class="string">'import sys; print sys.path'</span></div><div class="line">[<span class="string">''</span>, <span class="string">'/usr/lib64/python26.zip'</span>, <span class="string">'/usr/lib64/python2.6'</span>, <span class="string">'/usr/lib64/python2.6/plat-linux2'</span>, <span class="string">'/usr/lib64/python2.6/lib-tk'</span>, <span class="string">'/usr/lib64/python2.6/lib-old'</span>, <span class="string">'/usr/lib64/python2.6/lib-dynload'</span>, <span class="string">'/usr/lib64/python2.6/site-packages'</span>, <span class="string">'/usr/lib64/python2.6/site-packages/gtk-2.0'</span>, <span class="string">'/usr/lib/python2.6/site-packages'</span>, <span class="string">'/usr/lib/python2.6/site-packages/setuptools-0.6c11-py2.6.egg-info'</span>]</div></pre></td></tr></table></figure>
<p>一般就在 /usr/lib64/python2.6/ 下面了。<br>不过2.6/2.7的SimpleHTTPServer.py没有明显差异，继续再比对他们的父类：BaseHTTPServer.py<br>下图简单列下不同点。</p>
<p><img src="/images/python2.6_1.png" width="100%"><br><img src="/images/python2.6_2.png" width="100%"><br><img src="/images/python2.6_3.png" width="100%"></p>
<p>时间问题，直接上答案，问题就出在log_message里，python原意只是记录response的相关结果，但没想到会成为耗时的元凶：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def address_string(self):</div><div class="line">    &quot;&quot;&quot;Return the client address formatted for logging.</div><div class="line">    This version looks up the full hostname using gethostbyaddr(),</div><div class="line">    and tries to find a name that contains at least one dot.</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    host, port = self.client_address[:2]</div><div class="line">    return socket.getfqdn(host)</div></pre></td></tr></table></figure></p>
<p>我在该机器上跑一下，发现却是是耗费10秒</p>
<pre><code>time python -c &apos;import socket; print socket.getfqdn()&apos;
</code></pre><p>python 2.7 之后就改过来了，不再适用 address_string，所以在现代服务器上不会出现上述问题。</p>
<p>getfqdn为什么会耗时呢？这和pyhon hostname 解析实现相关，后续可分享一下。</p>
<p>以上简单记录遇到的问题，读者可留意。解决方法其实可以替换python的BaseHTTPServer.py，也可以自己拷贝出来一份修改，但说到底不如正规的方案去实现。</p>
<p>后记：</p>
<p>getfqdn 底层调用的就是 socket.gethostbyaddr() – map an IP number or hostname to DNS info<br>(生产环境配置 域名/反向域名解析服务)<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[java@10-135-20-62 ~]$ time python -c <span class="string">'import socket; print socket.gethostbyaddr("10.135.20.62")'</span></div><div class="line">(<span class="string">'localhost'</span>, [<span class="string">'localhost.localdomain'</span>, <span class="string">'localhost4'</span>, <span class="string">'localhost4.localdomain4'</span>], [<span class="string">'10.135.20.62'</span>])</div><div class="line"></div><div class="line">real    0m0.019s</div><div class="line">user    0m0.014s</div><div class="line">sys 0m0.004s</div><div class="line">[java@10-135-20-62 ~]$ time python -c <span class="string">'import socket; print socket.gethostbyaddr("10.135.20.39")'</span></div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;string&gt;"</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">socket.herror: [Errno 2] Host name lookup failure</div><div class="line"></div><div class="line">real    0m10.033s</div><div class="line">user    0m0.018s</div><div class="line">sys 0m0.004s</div></pre></td></tr></table></figure></p>
<p>另 <a href="/images/socket.py">socket.py</a><br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[java@10-135-20-62 ~]$ python -c <span class="string">'import _socket;print(_socket.__file__)'</span></div><div class="line">/usr/lib64/python2.6/lib-dynload/_socketmodule.so</div><div class="line">[java@10-135-20-62 ~]$ nm -D /usr/lib64/python2.6/lib-dynload/_socketmodule.so</div><div class="line">[java@10-135-20-62 ~]$ objdump -tT /usr/lib64/python2.6/lib-dynload/_socketmodule.so</div><div class="line">...</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前因为时间紧迫的缘故，在公司的CentOS 7 机器上部署一个快速实现的数据收集工具，考虑到避免其他语言发布和变更起来麻烦，于是就用 python+bash 实现。&lt;/p&gt;
&lt;p&gt;服务端就是最简单不引入任何python包的SimpleHTTPServer+Handler实现的。&lt;/p&gt;
&lt;p&gt;偶然一次看日志发现本来应该在三分钟内完成的一个同步/上报循环结果未能如期完成，每个请求看起来相隔十秒左右，最后定位下来是python2.6.6的问题。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="Python" scheme="http://thomaslau.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0130</title>
    <link href="http://thomaslau.github.io/2019/01/30/2019-01-30-many_links_0130/"/>
    <id>http://thomaslau.github.io/2019/01/30/2019-01-30-many_links_0130/</id>
    <published>2019-01-29T17:09:07.000Z</published>
    <updated>2019-07-24T15:59:11.841Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>Running Envoy as an Edge Proxy at eBay: Replacing Hardware Load Balancers with a Software Solution<br><a href="https://www.infoq.com/news/2018/12/envoycon-ebay-edge" target="_blank" rel="external">https://www.infoq.com/news/2018/12/envoycon-ebay-edge</a><br>eBay的Envoy实践。</p>
<p>2.<br>Spring源码探究：容器<br><a href="https://www.jianshu.com/p/4a82770fd188" target="_blank" rel="external">https://www.jianshu.com/p/4a82770fd188</a><br>你遇到过定义了一个拦截器/bean，在controller层的代码生效，而service层没生效？<br>这篇文章做了解读。虽然问题是适合Spring初学者，但是作者解释的还是清晰的，而且不过分深入，适合初步了解Spring。<br><a id="more"></a><br><blockquote><p>当上门这句话放在springmvc.xml中时，名为”printTimeProcessor”的bean会存在于Springmvc容器，那么Spring容器是无法获取它的。而Service层恰巧是存在于Spring容器中，所以”printTimeProcessor”切面对Service层不起作用。而Controller层本身存在于Springmvc容器，所以Controller层可以正常工作。而当它放在spring.xml中时，”printTimeProcessor”是存在于Spring容器中，Springmvc容器是Spring容器的子容器，子容器可以获取到父容器的bean，所以Controller层与Service层都能获取到该bean，所有都能正常使用它</p>
</blockquote><br>这里可能有点混乱，把“Springmvc容器”当作Web容器(WebApplicationContext),“Spring容器”当作App容器(ApplicationContext)。<br>作者的源码可能和文中有些出入，但是其中原理探索是值得一看的。</p>
<p>3.<br>MIT Tech Review JANUARY/FEBRUARY 2019  The China issue<br>其他几篇需要订阅阅读<br><a href="https://www.technologyreview.com/magazine/2019/01/" target="_blank" rel="external">https://www.technologyreview.com/magazine/2019/01/</a><br>数字统计不知真假，看起来是个强国啊，这几年的的科技发展迅猛<br><blockquote><p>China’s tech giants want to go global. Just one thing might stand in their way.<br>China’s losing its taste for nuclear power. That’s bad news.<br>The man turning China into a quantum superpower<br>China has never had a real chip industry. Making AI chips could change that.<br>Aboard the giant sand-sucking ships that China uses to reshape the world<br>China’s losing its taste for nuclear power. That’s bad<br>China’s giant transmission grid could be the key to cutting climate emissions<br>The man turning China into a quantum superpower<br>Years before CRISPR babies, this man was the first to edit human embryos<br>Science vs. the state: a family saga at the Caltech of China<br>How Google took on China—and lost<br>The Reunion: a new science-fiction story about surveillance in China<br>The US and China aren’t in a “cold war,” so stop calling it that<br>How China got a head start in fintech, and why the West won’t catch up</p>
</blockquote></p>
<p>4.<br>《从0开始学架构》–笔记<br><a href="https://coderbee.net/index.php/framework/20180918/1655" target="_blank" rel="external">https://coderbee.net/index.php/framework/20180918/1655</a></p>
<p>5.<br>微服务消息传递协议简介<br><a href="http://mushiming.top/mushblog/archives/890" target="_blank" rel="external">http://mushiming.top/mushblog/archives/890</a><br><blockquote><p>那么，微服务架构如何处理分布式独立进程中的通信？一些交叉的方式：<br>同步协议<br>异步协议<br>单接收器<br>多个接收器<br>如何避免同步依赖？<br>复制和传播将有助于回避同步性问题。通过复制，您可以将数据存储在多个站点（如服务器）中。这极大地提高了数据的可用性并减少了不一致性。通过传播，您可以将数据从服务器推送到客户端，这对于本地访问方案非常有用。</p>
<p>如果复制和传播不是当前路由，您还可以跨微服务复制数据。这与每个微服务的域模型边界密切配合。在处理域模型边界时，您需要关注业务功能的范围，并在服务之间创建可理解且有意义的分离。如果实现有意义的分离，这也将有助于提高数据和迭代的可伸缩性和域驱动选择。</p>
</blockquote></p>
<p>6.<br>How Much of the Internet Is Fake? Turns Out, a Lot of It, Actually.<br><a href="http://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html" target="_blank" rel="external">http://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html</a><br>长文，作者论述了现实中存在的 Fake，听起来一种Fake致死的感觉，在这个当今离开手机离开互联网寸步难行的时代。<br>但作者是在耸人听闻吗：<br><blockquote><p>Where does that leave us? I’m not sure the solution is to seek out some pre-Inversion authenticity — to red-pill ourselves back to “reality.” What’s gone from the internet, after all, isn’t “truth,” but trust: the sense that the people and things we encounter are what they represent themselves to be. Years of metrics-driven growth, lucrative manipulative systems, and unregulated platform marketplaces, have created an environment where it makes more sense to be fake online — to be disingenuous and cynical, to lie and cheat, to misrepresent and distort — than it does to be real. Fixing that would require cultural and political reform in Silicon Valley and around the world, but it’s our only choice. Otherwise we’ll all end up on the bot internet of fake people, fake clicks, fake sites, and fake computers, where the only real thing is the ads.</p>
</blockquote></p>
<p>7.<br>中美贸易摩擦加关税商品<br><a href="http://blog.fens.me/china-trade-merchandise/" target="_blank" rel="external">http://blog.fens.me/china-trade-merchandise/</a></p>
<p>8.<br>2018年JAVA回顾<br>JVM Calendar: Java in 2018<br><a href="https://dzone.com/articles/java-advent-java-in-2018" target="_blank" rel="external">https://dzone.com/articles/java-advent-java-in-2018</a></p>
<p>9.<br>下面的主要来自ruanyf本期(和其它)的分享,偷个懒，直接引用部分，有兴趣请移步原文：<br><a href="http://www.ruanyifeng.com/blog/2018/12/weekly-issue-37.html" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2018/12/weekly-issue-37.html</a></p>
<p><a href="https://github.com/sdmg15/Best-websites-a-programmer-should-visit" target="_blank" rel="external">https://github.com/sdmg15/Best-websites-a-programmer-should-visit</a><br>该仓库收集对程序员有用的网址，包含问题查找、技术新闻、技术博客、开源社区、英文提升、新奇的玩意儿、视频教程、在线工具等数十个方向的内容。（@qiurenbo 投稿）</p>
<p><a href="https://tus.io/" target="_blank" rel="external">https://tus.io/</a><br>文件上传到一半突然断了，往往只能重新上传。tus 是一个允许断点上传的轻量级协议，可以从中断的地方继续上传。官方提供开源的客户端和服务端实现。</p>
<p><a href="https://github.com/jabcode/jabcode" target="_blank" rel="external">https://github.com/jabcode/jabcode</a><br>JAB 码是彩色二维码方案，可以比黑白二维码写入多得多的信息。</p>
<p>Linux 内核揭密（中文）<br><a href="https://xinqiu.gitbooks.io/linux-insides-cn/content/index.html" target="_blank" rel="external">https://xinqiu.gitbooks.io/linux-insides-cn/content/index.html</a><br>本书是《Linux inside》一书的中译，介绍 Linux 内核知识，从计算机通电讲起，需要 C 语言和汇编语言的知识。（@imilano 投稿）<br><a href="https://github.com/0xAX/linux-insides" target="_blank" rel="external">https://github.com/0xAX/linux-insides</a></p>
<p><a href="http://incompleteideas.net/book/the-book.html" target="_blank" rel="external">http://incompleteideas.net/book/the-book.html</a><br>《Reinforcement Learning: An Introduction》，2018年出版的新书，作者开源了。</p>
<p><a href="https://swtch.com/~rsc/regexp/regexp4.html" target="_blank" rel="external">https://swtch.com/~rsc/regexp/regexp4.html</a><br>谷歌代码搜索的作者，介绍搜索的算法原理。</p>
<p><a href="https://www.vulture.com/2018/10/the-making-of-rockstar-games-red-dead-redemption-2.html" target="_blank" rel="external">https://www.vulture.com/2018/10/the-making-of-rockstar-games-red-dead-redemption-2.html</a><br>这篇长篇报道介绍 RockStar 游戏公司和它开发的游戏《Red Dead Redemption 2》。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;Running Envoy as an Edge Proxy at eBay: Replacing Hardware Load Balancers with a Software Solution&lt;br&gt;&lt;a href=&quot;https://www.infoq.com/news/2018/12/envoycon-ebay-edge&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.infoq.com/news/2018/12/envoycon-ebay-edge&lt;/a&gt;&lt;br&gt;eBay的Envoy实践。&lt;/p&gt;
&lt;p&gt;2.&lt;br&gt;Spring源码探究：容器&lt;br&gt;&lt;a href=&quot;https://www.jianshu.com/p/4a82770fd188&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.jianshu.com/p/4a82770fd188&lt;/a&gt;&lt;br&gt;你遇到过定义了一个拦截器/bean，在controller层的代码生效，而service层没生效？&lt;br&gt;这篇文章做了解读。虽然问题是适合Spring初学者，但是作者解释的还是清晰的，而且不过分深入，适合初步了解Spring。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 1119</title>
    <link href="http://thomaslau.github.io/2018/11/19/2018-11-19-many_links_1119%20copy/"/>
    <id>http://thomaslau.github.io/2018/11/19/2018-11-19-many_links_1119 copy/</id>
    <published>2018-11-18T17:09:07.000Z</published>
    <updated>2018-11-20T17:41:17.906Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>NIPS不更名，我就撤资：赞助商加入联合抗议行列<br><a href="https://www.jiqizhixin.com/articles/2018-11-02-12" target="_blank" rel="external">https://www.jiqizhixin.com/articles/2018-11-02-12</a><br>不过后来还是改名字了 <a href="https://www.jiqizhixin.com/articles/2018-11-17" target="_blank" rel="external">NeurIPS</a><br>以后看文章要找对地方啊。<br>2.<br>GitHub Incident Analysis Shows How to Improve Service Reliability<br><a href="https://www.infoq.com/news/2018/11/github-incident-analysis" target="_blank" rel="external">https://www.infoq.com/news/2018/11/github-incident-analysis</a><br>GitHub服务中断24小时11分钟事故分析报告<br><a href="https://mp.weixin.qq.com/s/fFv1ASElHsVNEPPkP53qAQ" target="_blank" rel="external">https://mp.weixin.qq.com/s/fFv1ASElHsVNEPPkP53qAQ</a><br>了解下：<br><blockquote><p>GitHub 拥有多个 MySQL 集群，大小从几百 GB 到 5TB 不等，每个集群最多有几十个只读副本来存储非 Git 元数据，因此我们的应用程序可以提供拉取请求和问题管理、身份验证管理、后台处理协调等原始 Git 对象存储之外的其他功能。应用程序不同部分的数据通过功能分片存储在各种集群中。<br>为了大规模提高性能，应用程序将数据直接写入每个集群的主数据库，但在绝大多数情况下将读取请求委派给副本服务器。我们使用 Orchestrator 来管理 MySQL 集群拓扑和处理自动故障转移。Orchestrator 以 Raft 的共识算法为基础，可以实现应用程序无法支持的拓扑，因此必须十分小心让 Orchestrator 配置与应用程序的期望保持一致。</p>
</blockquote><br>3.<br>Java应用性能调优之调优准备<br><a href="http://www.rowkey.me/blog/2018/10/31/profile-ready/" target="_blank" rel="external">http://www.rowkey.me/blog/2018/10/31/profile-ready/</a><br>基本涵盖常见注意点，可以保存文章随时查阅。<br>总结简单记住几个命令：<br><a id="more"></a><br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">dmesg丨tail</div><div class="line">vmstat 1</div><div class="line">mpstat -P ALL 1</div><div class="line">free -m</div><div class="line">sar -n DEV 1</div><div class="line">top</div></pre></td></tr></table></figure></p>
<p>4.<br>1年将30PB数据迁移到Spark，eBay的经验有何可借鉴之处？<br><a href="http://www.infoq.com/cn/articles/ebay-30pb-spark" target="_blank" rel="external">http://www.infoq.com/cn/articles/ebay-30pb-spark</a><br>文章似乎404了，不过infoq上站内搜索还是可以搜索到，似乎没讲啥，但可以了解下这件事：<br><blockquote><p>eBay 使用 Teradata 已经有二十年的历史，这个数仓系统中积累了 60PB 数据和上万张核心表，他们支撑着 eBay 最核心的商务逻辑和站点功能。从今年开始，eBay 开始将这个庞大的数仓由 Teradata 向 Spark 做迁移，使用 eBay 自己开发的工具，迁移过程中 90% 的工作都可以由自动化完成。与此同时，研究人员通过优化 Spark 框架，节省了一半的内存。<br>…<br>eBay 第一期迁移的数仓就有 30PB 之大，包括 5000 张的目标表、20000 张的临时表和 50000 个作业。经过估算，如果是手动迁移，大概需要 1000 个人月，相当于 50 个数据工程师，专职做迁移也需要两年， 这是非常大的开销。所以 必须做自动化迁移。<br>…<br>尽管团队已经预先为大型数据仓库迁移可能会面临的问题设计了应对方案，但在真正启动数据仓库迁移后，依然遇到了很多挑战。俞育才给我们举了几个例子：<br>1)“大规模数据下的正确性验证。我们可能会直观地认为，双跑验证就可以了。尽管理论上是这样，实际情况往往会复杂很多。首先，数据源是不断变化的，目标表依赖的任何一张源表数据发生了变化，结果就会不一致。所以，双跑的时间点很重要。其次，即使数据源固定，跑多次结果未必是一致的。比如，在 Spark 中有个 UDF，可以给返回每一行加上个 ID。但实际上，这并不是一个幂等操作，因为 Shuffle 不保证每次返回行的顺序，所以每次编上 ID 都是不一样的。对于这样的列，我们就不能做比较。类似这样的问题还有很多，都需要特别注意。<br>2)非标准流程作业的迁移。在老的 Teradata 数仓中，大约有 10-15% 的作业并不是按照标准流程创建的，这些作业无法做自动化迁移，或者自动化的成本很高。所以，在初期做规划的时候，要尽可能收集到足够的信息，把他们都标识出来，然后尽早地联系相应的开发，或者修改作业，或者做手动迁移。<br>3)开源软件的企业级特性的支持。一些企业级软件提供的易用功能，现在的 Spark、Hadoop 还没有提供。比如：监控和调试信息还不是很完善，排错起来不是那么方便；对分析师来说，他们也缺乏一个好的 IDE 帮助他们做开发。这并不全是 Spark 的问题，我们自己开发了很多外围的组件来帮助改善这些问题。</p>
</blockquote><br>5.<br>一文看懂Pinterest如何构建时间序列数据库系统Goku<br><a href="http://www.infoq.com/cn/articles/how-pinterest-build-goku" target="_blank" rel="external">http://www.infoq.com/cn/articles/how-pinterest-build-goku</a><br><blockquote><p>虽然 OpenTSDB 在功能上运行良好，但其性能随着 Pinterest 的增长而降低，导致运营开销（例如严重的 GC 问题和 HBase 经常崩溃）。为了解决这个问题，Pinterest 开发了自己的内部时间序列数据库——Goku，其中包含用 C ++ 编写的 OpenTSDB 兼容 API，以支持高效的数据提取和成本昂贵的时间序列查询。<br>时间序列数据<br>Goku 遵循 OpenTSDB 的时间序列数据模型。时间序列由一个键和一系列时间数字数据点组成。key = metric name + 一组标记键值对<br>时间序列查询<br>除了开始时间和结束时间之外，每个查询都由以下部分或全部组成：度量标准名称、过滤器、聚合器、降采样器、速率选项。<br>…<br>Goku 解决了 OpenTSDB 中的许多限制，包括：<br>1）不必要的扫描：Goku 用倒排索引引擎取代了 OpenTSDB 的低效扫描。<br>2）数据大小：OpenTSDB 中的数据点是 20 字节。Pinterest 采用 Gorilla 压缩来实现 12 倍压缩。<br>3）单机聚合：OpenTSDB 将数据读取到一个服务器上并进行聚合，而 Goku 的新查询引擎是将计算迁移到更接近存储层的位置，该存储层在叶节点上进行并行处理，然后在根节点上聚合部分结果。<br>4）序列化：OpenTSDB 使用 JSON，当有太多数据点要返回时，JSON 会很慢；Goku 使用 thrift 二进制代替。<br>…<br>存储引擎<br>Goku 在内存存储引擎中使用了 Facebook Gorilla 来存储过去 24 小时内的最新数据。<br>分片和路由<br>我们使用两层分片策略。首先，我们对度量名称进行散列，以确定某一时间序列属于哪个分片组。我们在度量名称 + 标记键值集上进行散列，以确定时间序列在所在组中的哪个分片。此策略可确保数据在分片之间保持平衡。同时，由于每个查询仅进入一个组，因此扇出保持较低水平，以减少网络开销和尾部延迟。另外，我们可以独立地扩展每个分片组。<br>…<br>查询引擎<br>a)倒排索引<br>b)聚合<br>从存储引擎检索数据后，开始进行聚合和构建最终结果的步骤。<br>Pinterest 最初尝试了 OpenTSDB 的内置查询引擎。结果发现，由于所有原始数据都需要在网络上运行，性能会严重下降，而且这些短期对象也会导致很多 GC。<br>因此，Pinterest 在 Goku 中复制了 OpenTSDB 的聚合层，并尽可能地早地进行计算，以尽量减少线上的数据。</p>
<p>下一步：<br>a)基于磁盘的长期数据存储<br>Goku 最终将支持超过一天时间数据的查询。对于像一年这样的时长查询，Pinterest 将不会过分强调一秒钟内发生的事情，而是关注整体趋势。因此，Pinterest 将进行降采样和压缩，把以小时计的 bucket 合并为更长期的时长，从而减小数据量并提高查询性能。<br>b)复制<br>目前，Pinterest 有两个 goku 集群进行双行写入。此设置提高了可用性：当一个集群中存在问题时，可以轻松地将流量切换到另一个集群。但是，由于这两个集群是独立的，因此很难确保数据的一致性。例如，如果写入一个集群成功而另一个未成功时，则数据写入失败，数据由此变得不一致。另一个缺点是故障转移总是在集群层面发生。为此，Pinterest 正在开发基于日志的集群内复制，以支持主从分片。这将提高读取可用性，保持数据一致性，并支持分片级的故障转移。</p>
</blockquote><br>6.<br>Alternative code styles<br><a href="https://swalladge.id.au/archives/2018/10/15/alternative-code-styles/" target="_blank" rel="external">https://swalladge.id.au/archives/2018/10/15/alternative-code-styles/</a></p>
<p>算是搞笑文章吧，标准之外的选择，大开眼界了，特别是 斐波那契缩进的风格：<br>知名如<br>PEP8 for Python<br>Linux kernel coding style for C<br>Airbnb JavaScript Style Guide<br><blockquote><p>Ok, so there are also plenty of infoadm ation, history, tools, etc. for popular styles. Enough on them. Let’s look at some lesser known alternatives!<br><em>Bournegol</em><br>Let’s begin with the most (im)famous alternate code styles! Bournegol is the C coding style used by Steven Bourne in the sh source code. It makes C look more like Algol, which some would argue has a nicer syntax. Below is a snippet from main.c (source):<br>DISCLAIMER: use the styles that follow at your own risk.<br><em>Poetry</em><br>Code can be an art form. While function is generally put before form in code, it doesn’t hurt to break the trend and produce source code that is in itself beautiful.<br><em>Fibonacci indentation</em><br>Indentation has always been a hot topic. Tabs or spaces? Two, four, or even eight spaces? Let’s add a new option! Welcome to Fibonacci indentation.</p>
</blockquote><br>7.<br>关于Kafka broker IO的讨论，huxihx写的，非常不错，建议可以收藏看一看<br><a href="http://www.cnblogs.com/huxi2b/p/9860192.html" target="_blank" rel="external">http://www.cnblogs.com/huxi2b/p/9860192.html</a><br><blockquote><p>Apache Kafka是大量使用磁盘和页缓存(page cache)的，特别是对page cache的应用被视为是Kafka实现高吞吐量的重要因素之一。实际场景中用户调整page cache的手段并不太多，更多的还是通过管理好broker端的IO来间接影响page cache从而实现高吞吐量。我们今天就来讨论一下broker端的各种IO操作。<br>…<br>开始之前，还是简单介绍一下page cache：page cache是内核使用的最主要的磁盘缓存(disk cache)之一——实际上Linux中还有其他类型的磁盘缓存，如dentry cache、inode cache等。通常情况下Linux内核在读写磁盘时都会访问page cache。当用户进程打算读取磁盘上文件的数据时，内核会首先查看待读取数据所在的page是否在page cache中，如果存在自然命中page cache，直接返回数据即可，避免了物理磁盘读操作；反之内核会向page cache添加一个新的page并发起物理磁盘读操作将数据从磁盘读取到新加page中，之后再返回给用户进程。Linux内核总是会将系统中所有的空闲内存全部当做page cache来用，而page cache中的所有page数据将一直保存在page cache中直到内核根据特定的算法替换掉它们中的某些page——一个比较朴素的算法就是LRU。同样地，在写入page数据到磁盘之前，内核也会检查对应的page是否在page cache中，如果不存在则添加新page并将待写入数据填充到该page中，此时真正的磁盘写还尚未开始，通常都是隔几秒之后才真正写入到底层块设备上——即这是一个延迟写入操作。理论上来说，在这几秒之内的间隔中，用户进程甚至还允许修改这些待写入的数据——当然对于Kafka而言，它的写入操作本质上是append-only的，故没有这样的使用场景。</p>
</blockquote><br>8.<br>Linux Kernel 4.9 中的 BBR 算法与之前的 TCP 拥塞控制相比有什么优势？<br><a href="https://www.zhihu.com/question/53559433/answer/519062524?group_id=1039303887626481665" target="_blank" rel="external">https://www.zhihu.com/question/53559433/answer/519062524?group_id=1039303887626481665</a><br><blockquote><p>BBR是基于什么的拥塞控制？根据论文，是基于拥塞的拥塞控制（Congestion-based Congestion Control），但是看起来感觉不好理解。根据我的理解，我更倾向于称它为 基于带宽延迟的拥塞控制（BDP-based Congestion Control）。因为，BBR总是在测量最小RTT（10s内），最大Bandwidth（10 Round Trips），并且尽量控制输出到网络的数据包（in-flight）靠近 BDP（without buffer），这样既能保证带宽利用率，又能避免Bufferbloat问题。</p>
</blockquote><br>9.<br>Kafka副本管理—— 为何去掉replica.lag.max.messages参数<br><a href="https://www.cnblogs.com/huxi2b/p/5903354.html" target="_blank" rel="external">https://www.cnblogs.com/huxi2b/p/5903354.html</a><br><blockquote><p>今天查看Kafka 0.10.0的官方文档，发现了这样一句话：Configuration parameter replica.lag.max.messages was removed. Partition leaders will no longer consider the number of lagging messages when deciding which replicas are in sync. 即replica.lag.max.messages参数被正式地移除了，现在topic每个分区的leader副本都不再使用这个参数作为判断follower副本同步状态的依据。看到之后顿觉十分好奇于是抽出半天时间仔细研究了一下，终于弄明白了移除该参数的原因，特此记录一下。</p>
<p>首先我们来看一下这个参数本来的含义： If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead. 即如果某个副本落后leader副本的消息数超过了这个值，那么leader副本就会把该follower副本从ISR中移除</p>
<p>为什么取消这个参数，改用：replica.lag.time.max.ms<br>简单来说，根据这个参数，当producer发送速度假设超快，那么容易不断地被踢出ISR然后重新加回ISR，造成了与leader不同步、再同步、又不同步、再次同步的情况发生，超慢时，又未必能察觉到。</p>
</blockquote><br>10.<br>Stuff The Internet Says On Scalability For October 19th, 2018<br><a href="http://highscalability.com/blog/2018/10/19/stuff-the-internet-says-on-scalability-for-october-19th-2018.html" target="_blank" rel="external">http://highscalability.com/blog/2018/10/19/stuff-the-internet-says-on-scalability-for-october-19th-2018.html</a><br><blockquote><p>dweis: I’m an actual author of Protocol Buffers :) I think Sandy’s analysis would benefit from considering why Protocol Buffers behave the way they do rather than outright attacking the design because it doesn’t appear to make sense from a PL-centric perspective. As with all software systems, there are a number of competing constraints that have been weighed that have led to compromises.<br>atombender: I don’t think GraphQL is over-hyped at all. Maybe it’s flawed, but the design is absolutely on the right traack. GraphQL completely changes how you work with APIs in a front end.</p>
<p>Ted Kaminski: The present state of asynchronous I/O on Linux is a giant, flaming garbage fire. A big part of the reason concurrency and parallelism are so conflated is that we get many purely synchronous API calls from the operating system (not just Linux), and to get around this inherent lack of concurrency in API design, we must resort to the parallelism of threads.<br>Dan Houser: The polishing, rewrites, and reedits Rockstar does are immense. “We were working 100-hour weeks” several times in 2018, Dan says. The finished game includes 300,000 animations, 500,000 lines of dialogue, and many more lines of code. Even for each RDR2 trailer and TV commercial, “we probably made 70 versions, but the editors may make several hundred. Sam and I will both make both make lots of suggestions, as will other members of the team.”</p>
<p>@andy_pavlo: Transactions are hard. Distributed transactions are harder. Distributed transactions over the WAN are final boss hardness. I’m all for new DBMSs but people should tread carefully.</p>
</blockquote><br>11.<br>Arthas使用指南<br><a href="https://segmentfault.com/a/1190000014618329" target="_blank" rel="external">https://segmentfault.com/a/1190000014618329</a></p>
<p>12.<br>FEX 技术周刊 - 2018/11/05<br><a href="http://fex.baidu.com/blog/2018/11/fex-weekly-05/" target="_blank" rel="external">http://fex.baidu.com/blog/2018/11/fex-weekly-05/</a><br><blockquote><p>富文本编辑器的技术演进之路<br><a href="https://mp.weixin.qq.com/s?__biz=MzU0Nzk1MTg5OA==&amp;mid=2247484137&amp;;idx=1&amp;sn=8dc25f8de7d359549520c9f198721408" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzU0Nzk1MTg5OA==&amp;mid=2247484137&amp;;idx=1&amp;sn=8dc25f8de7d359549520c9f198721408</a><br>浏览器提供了两个原生特性：contenteditable、document.execCommand()，contenteditable 特性，可以指定某一容器变成可编辑器区域，即用户可以在容器内直接输入内容，或者删减内容。execCommand API，可以对选中的某一段结构体，执行一个命令，譬如赋予黑体格式。基于以上，可以做出最简单的富文本编辑器。原来富文本编辑器是这么简单？当然不止如此简单！另附：[译]为数字优先新闻编辑室开发文本编辑器.<br>Atag - Web Components 最佳实践<br><a href="http://taobaofed.org/blog/2018/10/31/a-tag/" target="_blank" rel="external">http://taobaofed.org/blog/2018/10/31/a-tag/</a><br>过去一段时间，我一直在使用 Web Components 构建淘宝小程序的 基础组件 Atag。这篇文章的目的，是希望总结在 Atag 开发阶段中使用 Web Components 的经验，避免大家踩坑。另附：October 2018: A Big Month for Web Components.<br>蚂蚁金服移动开发平台mPaaS<br><a href="https://juejin.im/post/5bd81cf2f265da0ab674096c" target="_blank" rel="external">https://juejin.im/post/5bd81cf2f265da0ab674096c</a><br>Android 拆分项目的方案</p>
</blockquote></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;NIPS不更名，我就撤资：赞助商加入联合抗议行列&lt;br&gt;&lt;a href=&quot;https://www.jiqizhixin.com/articles/2018-11-02-12&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.jiqizhixin.com/articles/2018-11-02-12&lt;/a&gt;&lt;br&gt;不过后来还是改名字了 &lt;a href=&quot;https://www.jiqizhixin.com/articles/2018-11-17&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NeurIPS&lt;/a&gt;&lt;br&gt;以后看文章要找对地方啊。&lt;br&gt;2.&lt;br&gt;GitHub Incident Analysis Shows How to Improve Service Reliability&lt;br&gt;&lt;a href=&quot;https://www.infoq.com/news/2018/11/github-incident-analysis&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.infoq.com/news/2018/11/github-incident-analysis&lt;/a&gt;&lt;br&gt;GitHub服务中断24小时11分钟事故分析报告&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/fFv1ASElHsVNEPPkP53qAQ&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://mp.weixin.qq.com/s/fFv1ASElHsVNEPPkP53qAQ&lt;/a&gt;&lt;br&gt;了解下：&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;GitHub 拥有多个 MySQL 集群，大小从几百 GB 到 5TB 不等，每个集群最多有几十个只读副本来存储非 Git 元数据，因此我们的应用程序可以提供拉取请求和问题管理、身份验证管理、后台处理协调等原始 Git 对象存储之外的其他功能。应用程序不同部分的数据通过功能分片存储在各种集群中。&lt;br&gt;为了大规模提高性能，应用程序将数据直接写入每个集群的主数据库，但在绝大多数情况下将读取请求委派给副本服务器。我们使用 Orchestrator 来管理 MySQL 集群拓扑和处理自动故障转移。Orchestrator 以 Raft 的共识算法为基础，可以实现应用程序无法支持的拓扑，因此必须十分小心让 Orchestrator 配置与应用程序的期望保持一致。&lt;/p&gt;
&lt;/blockquote&gt;&lt;br&gt;3.&lt;br&gt;Java应用性能调优之调优准备&lt;br&gt;&lt;a href=&quot;http://www.rowkey.me/blog/2018/10/31/profile-ready/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.rowkey.me/blog/2018/10/31/profile-ready/&lt;/a&gt;&lt;br&gt;基本涵盖常见注意点，可以保存文章随时查阅。&lt;br&gt;总结简单记住几个命令：&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 1025</title>
    <link href="http://thomaslau.github.io/2018/10/25/2018-10-25-many_links_1025/"/>
    <id>http://thomaslau.github.io/2018/10/25/2018-10-25-many_links_1025/</id>
    <published>2018-10-24T17:09:07.000Z</published>
    <updated>2018-10-26T01:05:27.911Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>stop using infinite scroll<br><a href="https://logrocket.com/blog/infinite-scroll/" target="_blank" rel="external">https://logrocket.com/blog/infinite-scroll/</a><br>对无限滚动屏的吐槽，说起来可多了。</p>
<p>2.<br>微软加入开放创新网络，旨在保护Linux和开源<br><a href="http://www.infoq.com/cn/news/2018/10/microsoft-oin" target="_blank" rel="external">http://www.infoq.com/cn/news/2018/10/microsoft-oin</a><br>微软是专利大企业，曾经用专利起诉著名企业，这次“拥抱Linux”，甚至打出了恶心的“ heart Linux”标语，至于未来如何，拭目以待。</p>
<p>3.<br>An HTTP proxy for Elasticsearch, Solr (etc.) to prevent a 100% full disk situation.<br><a href="https://github.com/flaxsearch/harahachibu" target="_blank" rel="external">https://github.com/flaxsearch/harahachibu</a><br><a id="more"></a><br>4.<br>网易乐得技术团队：Redis配置模板及持久化解决方案 –<br><a href="http://tech.lede.com/2017/11/14/rd/server/redistemplate/" target="_blank" rel="external">http://tech.lede.com/2017/11/14/rd/server/redistemplate/</a></p>
<p>5.<br>Writing system software: code comments.<br><a href="http://antirez.com/news/124" target="_blank" rel="external">http://antirez.com/news/124</a><br><blockquote><p>During my research I identified nine types of comments:</p>
<ul>
<li>Function comments</li>
<li>Design comments</li>
<li>Why comments</li>
<li>Teacher comments</li>
<li>Checklist comments</li>
<li>Guide comments</li>
<li>Trivial comments</li>
<li>Debt comments</li>
<li>Backup comments</li>
</ul>
<h1 id="Comments-as-an-analysis-tool"><a href="#Comments-as-an-analysis-tool" class="headerlink" title="Comments as an analysis tool."></a>Comments as an analysis tool.</h1><p>Comments are rubber duck debugging on steroids, except you are not talking with a rubber duck, but with the future reader of the code, which is more intimidating than a rubber duck, and can use Twitter. So in the process you really try to understand if what you are stating <em>is acceptable</em>, honorable, good enough. And if it is not, you make your homework, and come up with something more decent.</p>
<p>It is the same process that happens while writing documentation: the writer attempts to provide the gist of what a given piece of code does, what are the guarantees, the side effects. This is often a bug hunting opportunity. It is very easy while describing something to find that it has holes… You can’t really describe it all because you are not sure about a given behavior: such behavior is just emerging from complexity, at random. You really don’t want that, so you go back and fix it all. I find this a splendid reason to write comments.</p>
<h1 id="Writing-good-comments-is-harder-than-writing-good-code"><a href="#Writing-good-comments-is-harder-than-writing-good-code" class="headerlink" title="Writing good comments is harder than writing good code"></a>Writing good comments is harder than writing good code</h1><p>You may think that writing comments is a lesser noble form of work. After all you <em>can code</em>! However consider this: code is a set of statement and function calls, or whatever your programming paradigm is. Sometimes such statements do not make much sense, honestly, if the code is not good. Comments require always to have some design process ongoing, and to understand the code you are writing in a deeper sense. On top of that, in order to write good comments, you have to develop your writing skills. The same writing skills will assist you writing emails, documentation, design documents, blog posts, and commit messages.</p>
<p>I write code because I have an urgent sense to share and communicate more than anything else. Comments coadiuvate the code, assist it, describe our efforts, and after all I love writing them as much as I love writing code itself.</p>
</blockquote></p>
<p>5.<br>盖茨和朋友眼里的 Paul Allen<br>What I loved about Paul Allen<br><a href="https://www.gatesnotes.com/About-Bill-Gates/Remembering-Paul-Allen" target="_blank" rel="external">https://www.gatesnotes.com/About-Bill-Gates/Remembering-Paul-Allen</a><br>Remembering my friend and first business partner.<br><a href="https://www.cringely.com/2018/10/16/remembering-paul-allen/" target="_blank" rel="external">https://www.cringely.com/2018/10/16/remembering-paul-allen/</a></p>
<p>6.<br>班克斯的碎纸机本应该毁掉整幅《气球女孩》<br><a href="https://techcrunch.cn/2018/10/19/banksys-rigged-art-frame-was-supposed-to-shred-the-whole-thing/" target="_blank" rel="external">https://techcrunch.cn/2018/10/19/banksys-rigged-art-frame-was-supposed-to-shred-the-whole-thing/</a><br>文中的油管链接也是很有趣的，揭示碎纸机的制作，之前实验是成功的<br><blockquote><p>在万物互联的未来，我们还能够去真正“拥有”什么东西吗？班克斯（Banksy）在 本月早些时候 的行为艺术给出的回答是不能，当时他的一件作品在伦敦苏富比拍卖行进行拍卖。<br>…<br>视频的末尾展示了整幅画作被切碎的镜头，之后打出字幕：“在彩排中，每次都能成功……”。</p>
</blockquote><br>赞赏这种反艺术的行为，看看最近 AI制作的一幅画佳士得拍卖出300万价格</p>
<p>7.<br>知乎redis实践<br><a href="https://zhuanlan.zhihu.com/p/44441938" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/44441938</a><br>想不到在用的是 redis + tweamproxy</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;stop using infinite scroll&lt;br&gt;&lt;a href=&quot;https://logrocket.com/blog/infinite-scroll/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://logrocket.com/blog/infinite-scroll/&lt;/a&gt;&lt;br&gt;对无限滚动屏的吐槽，说起来可多了。&lt;/p&gt;
&lt;p&gt;2.&lt;br&gt;微软加入开放创新网络，旨在保护Linux和开源&lt;br&gt;&lt;a href=&quot;http://www.infoq.com/cn/news/2018/10/microsoft-oin&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.infoq.com/cn/news/2018/10/microsoft-oin&lt;/a&gt;&lt;br&gt;微软是专利大企业，曾经用专利起诉著名企业，这次“拥抱Linux”，甚至打出了恶心的“ heart Linux”标语，至于未来如何，拭目以待。&lt;/p&gt;
&lt;p&gt;3.&lt;br&gt;An HTTP proxy for Elasticsearch, Solr (etc.) to prevent a 100% full disk situation.&lt;br&gt;&lt;a href=&quot;https://github.com/flaxsearch/harahachibu&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/flaxsearch/harahachibu&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0803</title>
    <link href="http://thomaslau.github.io/2018/08/03/2018-08-03-many_links_0803/"/>
    <id>http://thomaslau.github.io/2018/08/03/2018-08-03-many_links_0803/</id>
    <published>2018-08-02T17:09:07.000Z</published>
    <updated>2018-08-02T17:30:06.087Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>继续 SCALA TIMES 上的分享<br><a href="https://mailchi.mp/softwaremill/scala-times-issue-2607957" target="_blank" rel="external">https://mailchi.mp/softwaremill/scala-times-issue-2607957</a><br><a href="https://manuel.bernhardt.io/2018/07/20/akka-anti-patterns-java-serialization/" target="_blank" rel="external">Akka anti-patterns: Java serialization</a><br><a href="https://mostafa-asg.github.io/post/practical-scala-cats-applicative-functor/" target="_blank" rel="external">Practical Cats: Functor and Applicative</a><br><a href="https://kubuszok.com/2018/implicits-type-classes-and-extension-methods-part-4/" target="_blank" rel="external">Implicits, type classes, and extension methods, part 4: understanding implicits</a><br><a href="http://lampwww.epfl.ch/~doeraene/thesis/" target="_blank" rel="external">Cross-Platform Language Design</a><br>2.<br>Be Nice And Write Stable Code<br><a href="http://technosophos.com/2018/07/04/be-nice-and-write-stable-code.html" target="_blank" rel="external">http://technosophos.com/2018/07/04/be-nice-and-write-stable-code.html</a><br><a id="more"></a><br><blockquote><p>Versions and SemVer<br>In software, we use version numbers to signal that something has changed. Version numbering schemes go from dead simple (integers that increment with every release, or date stamps) to surprisingly complex (1.0~pre3+dfsg-0.1+b2, 2.1.1+git20160721~8efc468-2, and 1.2.0+LibO5.2.7-1+deb9u4 are a few versions spotted in the wild).</p>
<p>But when it comes to software version numbers, the current leader in version numbering schemes is SemVer (or Semantic Versioning). Don’t be fooled, though! Many people claim to know how SemVer works, but have never read the specification. Since this is a critical piece of what we are about to talk about, here is a summary of the spec:</p>
<p>Version numbers take the form X.Y.Z, sometimes augmented with additional pre-release and build information: X.Y.Z-AAA#BBB. And each of those fields means something well defined and specific.</p>
<p>X is the major number. Changes in this indicate breaking changes to the API (and/or behavior).<br>Y is the minor number. Changes to this number indicate that new features were added, but that no APIs are broken as a result.<br>Z is the patch version. Changes to this indicate that internal changes were made, but that no changes (even compatible changes) were made to the API.<br>These three are the important ones for us. Again, I suggest taking 15 minutes to read the entire spec.</p>
<p>Countless projects use a format that looks like SemVer, but many of them ignore the semantics behind the version number. Often, it seems that version numbers are incremented by “gut feel” instead of any consistent semantic: “This feels like a minor version update.”</p>
</blockquote><br>3.<br>lucene中的PackedInts源码解读-1<br><a href="http://suichangkele.iteye.com/blog/2427364" target="_blank" rel="external">http://suichangkele.iteye.com/blog/2427364</a><br>4.<br>【译】 追踪同步分片副本<br><a href="https://www.easyice.cn/archives/243" target="_blank" rel="external">https://www.easyice.cn/archives/243</a><br><a href="https://www.easyice.cn/archives/283" target="_blank" rel="external">https://www.easyice.cn/archives/283</a><br>5.<br>Lucene 基础理论<br><a href="http://www.blogjava.net/hoojo/archive/2012/09/06/387140.html" target="_blank" rel="external">http://www.blogjava.net/hoojo/archive/2012/09/06/387140.html</a><br><a href="https://github.com/kakawait/cas-security-spring-boot-starter" target="_blank" rel="external">https://github.com/kakawait/cas-security-spring-boot-starter</a><br>6.<br>几个名词解释：<br><a href="https://en.wikipedia.org/wiki/High-availability_cluster" target="_blank" rel="external">https://en.wikipedia.org/wiki/High-availability_cluster</a><br><blockquote><p>Node configurations<br>Active/active — Traffic intended for the failed node is either passed onto an existing node or load balanced across the remaining nodes. This is usually only possible when the nodes use a homogeneous software configuration.<br>Active/passive — Provides a fully redundant instance of each node, which is only brought online when its associated primary node fails.[2] This configuration typically requires the most extra hardware.<br>N+1 — Provides a single extra node that is brought online to take over the role of the node that has failed. In the case of heterogeneous software configuration on each primary node, the extra node must be universally capable of assuming any of the roles of the primary nodes it is responsible for. This normally refers to clusters that have multiple services running simultaneously; in the single service case, this degenerates to active/passive.<br>N+M — In cases where a single cluster is managing many services, having only one dedicated failover node might not offer sufficient redundancy. In such cases, more than one (M) standby servers are included and available. The number of standby servers is a tradeoff between cost and reliability requirements.<br>N-to-1 — Allows the failover standby node to become the active one temporarily, until the original node can be restored or brought back online, at which point the services or instances must be failed-back to it in order to restore high availability.<br>N-to-N — A combination of active/active and N+M clusters, N to N clusters redistribute the services, instances or connections from the failed node among the remaining active nodes, thus eliminating (as with active/active) the need for a ‘standby’ node, but introducing a need for extra capacity on all active nodes.</p>
</blockquote><br>双机热备特指基于高可用系统中的两台服务器的热备（或高可用），因两机高可用在国内使用较多，故得名双机热备，双机高可用按工作中的切换方式分为：主-备方式（Active-Standby方式）和双主机方式（Active-Active方式）<br><i>active-active</i><br>很好理解, 用两个完全一样的server, 然后用一个load balancer进行请求的调度.<br><i>active-passive</i><br>active-passive也是两个服务器节点, 但是绝大多数时间是active的那个(或者说primary)进行服务, 当primary服务器出问题, 就使用另一个passive服务器作为备用.<br>7.<br>Why I don’t use JSON ASTs<br><a href="https://www.reddit.com/r/scala/comments/933s2s/why_i_dont_use_json_asts/" target="_blank" rel="external">https://www.reddit.com/r/scala/comments/933s2s/why_i_dont_use_json_asts/</a><br>lihaoyi给出的答案，可参考<br><blockquote><p>If you use uJson, you don’t need to choose:<br>1.Just need case classes? Read/write directly to case classes<br>2.Need an AST? Read/write directly to the AST<br>3.Specifically want some other AST that’s not the uJson AST? You can read/write directly to the circe/play-json/etc. ASTs too<br>4.Don’t need case classes or an AST, and just want to pretty-print JSON? Read/write directly String -&gt; String<br>5.Don’t need any output at all, and just want to parse+validate your JSON? You can do that too.</p>
<p>ASTs are a thing you sometimes want, but they don’t need to be in the critical path if you want some other thing. If you want one, great, if you want something else, a visitor-based library like uJson can give you that something else directly and without fuss.</p>
</blockquote><br>8.<br><a href="https://www.wired.co.uk/article/human-faeces-poo-as-fertiliser" target="_blank" rel="external">https://www.wired.co.uk/article/human-faeces-poo-as-fertiliser</a><br>9.<br>ActivityPub<br><a href="https://activitypub.rocks/" target="_blank" rel="external">https://activitypub.rocks/</a><br>ActivityPub is a decentralized social networking protocol based on the ActivityStreams 2.0 data format. ActivityPub is an official W3C recommended standard published by the W3C Social Web Working Group. It provides a client to server API for creating, updating and deleting content, as well as a federated server to server API for delivering notifications and subscribing to content.<br>附：ActivityPub could be the future<br>10.<br><a href="https://mp.weixin.qq.com/s?__biz=MzAwODY4OTk2Mg==&amp;mid=2652046740&amp;;idx=1&amp;sn=2b01ecd64c516d59f38253f723bcebda" target="_blank" rel="external">https://mp.weixin.qq.com/s?__biz=MzAwODY4OTk2Mg==&amp;mid=2652046740&amp;;idx=1&amp;sn=2b01ecd64c516d59f38253f723bcebda</a><br>PageSpeed Insights (PSI) 是 Google 在全球范围内应用最广的开发者工具之一。PSI 2.0 版本在2018年1月9日发布并且取得了巨大的成功。为了更好地帮助中国地区的开发者并构建一个良好的网页生态环境，今天，我们很高兴地宣布 PSI 在developers.google.cn/speed/pagespeed/insights/ 上线啦！<br>11.<br>传闻阉割版Google要归来了<br>首个独家<br><a href="https://theintercept.com/2018/08/01/google-china-search-engine-censorship/" target="_blank" rel="external">https://theintercept.com/2018/08/01/google-china-search-engine-censorship/</a><br><a href="https://www.theguardian.com/world/2018/aug/02/google-working-on-censored-search-engine-for-china" target="_blank" rel="external">https://www.theguardian.com/world/2018/aug/02/google-working-on-censored-search-engine-for-china</a><br>oschina的大约译文<br><a href="https://www.oschina.net/news/98571/google-china-search-engine-censored-report" target="_blank" rel="external">https://www.oschina.net/news/98571/google-china-search-engine-censored-report</a><br>毫无意外的，相信google会在这位任期内归来，比我预估还是快了点<br>虽然国外面临同行/国会质疑，但是，还是觉得Pichai的回复感人：<br>12.<br>Kafka 2.0重磅发布，新特性独家解读<br><a href="http://www.infoq.com/cn/news/2018/08/kafka2.0-new-features" target="_blank" rel="external">http://www.infoq.com/cn/news/2018/08/kafka2.0-new-features</a><br><blockquote><p>增强在线可进化性<br>因此我们从很早以前开始注意保证在线升级的方便性，在这一次的 2.0.0 版本中，更多相关的属性被加了进来，比如 KIP-268、KIP-279、KIP-283 等等。<br>KIP-268：简化 Kafka Streams 升级过程<br>Kafka Streams 利用 Consumer Rebalance 协议里面的元数据字符串编码诸如任务分配、全局查询、版本升级相关的信息。然而，当编码版本本身改变的时候，就需要进行离线升级。比如之前从 0.10.0 版本向更高级的版本升级的时候，用户就需要将所有的 Streams 程序下线，换上新的 Kafka 版本号，然后在全部重启。<br>KIP-268 利用 version prob 可以使得旧版本的任务分配者告知其他高版本的成员暂时使用旧版本的 Rebalance 元数据编码，这样就可以让用户依然能够通过 rolling bounce 在线升级 Kafka Streams 的版本。而当所有参与的成员全部升级完毕之后，最后一次 rebalance 会自动切换回新版本的元数据编码。<br>KIP-279：修补多次 Kafka 分区主本迁移时的日志分歧问题<br>在升级 Kafka 版本或者做定期系统维护的时候，用户往往需要进行连续的多次 Kafka 分区迁移。在这次发布中我们修补了一个在此过程中可能会出现的一个会导致日志分歧发生的边缘情况。具体方案就是将此前版本中已经加入的主本 epoch 信息扩散到 OffsetForLeaderEpochResponse。如此所有主副本就可以清晰知道自己到底处于当前分区备份的哪一个阶段，从而杜绝因为消息不对等而可能导致的日志分歧。<br>KIP-283：降低信息格式向下转换时的内存消耗<br>在一个多客户端组群的环境下，客户端与服务器端的版本不匹配是常见现象。早在 0.10.0 版本中，Kafka 已经加入了允许不同版本客户端与服务器交互的功能，即高版本的 Kafka 客户端依然可以与低版本的服务器进行数据传导，反之亦然。然而当低版本的消费者客户端和高版本的服务器进行交互时，服务器有时需要将数据向下转换（format down-conversion）成为低版本客户端可以认知的格式后才能发回给消费者。向下转换有两个缺点：<br>丢失了 Kafka 数据零拷贝（zero-copy）的性能优势；<br>向下转换需要额外的大量内存，在极端情况下甚至会导致内存溢出。<br>前者无法避免，但是后者依然可以改进：在即将发布的 2.0 版本中，我们使用了一种新的基于分块（chunking）的向下转换算法，使得需要同时占据的内存需求大幅缩减。这使得高低版本的客户端与服务器之间的交互变得更加有效。<br>在 2.0.0 版本中，我们进一步加强了 Kafka 的可监控性，包括添加了很多系统静态属性以及动态健康指标，比如 KIP-223、KIP-237、KIP-272 等等。<br>KIP-223：加入消费者客户端的领先指标<br>KIP-237：加入更多 Kafka 控制器的健康指标<br>更全面的数据安全支持<br>在 2.0.0 版本里面，我们对此提供了一系列的改进，比如更细粒度的更细粒度的前缀通配符访问控制（KIP-290、KIP-227），支持 SASL/OAUTHBEARER（KIP-255），将委托令牌扩展到管理客户端（KIP-249），等等。<br>KIP-290、KIP-227：细粒度前缀通配符访问控制<br>更多见： <a href="https://www.apache.org/dist/kafka/2.0.0/RELEASE_NOTES.html" target="_blank" rel="external">https://www.apache.org/dist/kafka/2.0.0/RELEASE_NOTES.html</a></p>
</blockquote><br>13.<br>Service Mesh是什么？至今到位的总结<br><a href="http://blog.brucefeng.info/post/what-is-service-mesh" target="_blank" rel="external">http://blog.brucefeng.info/post/what-is-service-mesh</a><br><blockquote><p>Service Mesh能做什么<br>服务发现<br>动态路由<br>负载均衡<br>请求熔断<br>安全通讯<br>多语言支持<br>多协议支持<br>Metric和链路追踪<br>重试<br>2 为什么有微服务了还要Service Mesh<br>但微服务存在以下问题：<br>多语言支持<br>微服务在开始之初就承诺了一个重要的特性，就是不同的微服务可以采用不同的变成语言实现，服务与服务之间通过协议通信。<br>但要实现多语言支持面临很多困难，所以现在大部分公司都是通过统一编程语言来实现。即使部分实现了多语言的微服务，需要美中语言都实现相同的功能服务框架，导致微服务SDK很重，需要实现服务注册发现，服务路由、负载均衡、服务鉴权、服务降级、服务限流等，成本极高。<br>对业务代码侵入<br>业务项目实现微服务需要引入微服务SDK，并进行少量的开发，这些开发是和业务项目耦合的。<br>这种侵入，导致微服务SDK在升级过程中极其痛苦，甚至为因为SDK而导致线上事故，由此带来的升级维护成本较大<br>在我所在的公司，每次进行SDK升级时，都需要公司强制执行，升级过程中又会牵涉到与其他开源组件不兼容的情况，上线后也需要花时间灰度观察。整个公司这样做，其成本可想而知。<br>学习成本高<br>服务注册发现，服务路由、负载均衡、服务鉴权、服务降级、服务限流 这些功能几乎都可以独立成一个项目，实际上很多开源项目也是这样做的。每个组件的学习及熟悉成本都会很大，而业务开发首要面对的问题是业务支持，而不是花较大的精力在基础组件的学习使用上。</p>
</blockquote><br>14.<br><a href="https://www.theatlantic.com/science/archive/2018/08/nasa-culture-optimism-james-webb/566558/?utm_source=feed" target="_blank" rel="external">https://www.theatlantic.com/science/archive/2018/08/nasa-culture-optimism-james-webb/566558/?utm_source=feed</a><br>近年似乎遭受了不少的质疑，作者从NASA最近推迟了自己的一项计划探讨NASA正在经历的一种过于乐观的文化氛围。<br>以下搜狗翻译：<br><blockquote><p>然而，将美国人送上月球的乐观心态并没有改变。2012年的报告称:“当被问及定义‘项目成功’时，我们采访的几乎所有项目经理都回答说，如果一个项目达到了技术性能目标，它就是成功的。”。“没有一个经理提到控制成本和进度增长是衡量成功的重要标准。此外，所有人都说他们的项目是成功的，尽管许多人经历了不利的成本和进度结果。”<br>马丁说NASA的员工称这种认知失调为“哈勃心理学”。“哈勃太空望远镜在1990年到达太空时并没有立即获得成功。这台望远镜研制的时间比承诺的要长得多，超出了预算，发射时主镜出现了一个缺陷，需要多次维修和保养。但是今天，哈勃被认为是国家财富，它混乱的开端已经被人们遗忘。<br>马丁说:“只要你带回——就哈勃望远镜而言——漂亮的照片，你所有的成本超支和日程延误都会被原谅。”。“因为重要的是科学到底是什么，而不是你是如何到达那里的，你是多么的混乱、预算过多还是日程安排过度。这可能有点夸张，但这是一种心态:如果你带回漂亮的照片，所有的罪过都会被原谅。”<br>这是韦伯团队似乎寄希望于的结果。项目官员一遍又一遍地说，韦伯值得等待，因为成本已经上升，终点线已经越来越远。他们希望这种回报会掩盖这个过程的痛苦。<br>研究表明，大多数人都是乐观主义者。在工作环境中，乐观可能是一种激励力量。《消极思维的积极力量》一书的作者、韦尔斯利学院心理学教授朱莉·诺尔姆说:“人们喜欢乐观而不是悲观。”该书认为，对一些人来说，乐观是一种无效的策略。“他们很有信心认为一切都会成功，因此这可以激发他们的积极性。这可能会导致人们尝试一些他们可能不会尝试的东西，因为他们非常积极，肯定会成功。”<br>在团体中，特别是那些致力于共同目标的团体中，乐观的思维可能具有传染性。伦敦大学学院研究人脑乐观倾向的神经科学家塔利·沙洛特说:“如果你让一群人参与一个项目，每个人都有一点偏见——人们的偏见相当温和，只是高估了积极的一点，低估了消极的一点——你把他们放在一起，偏见就会变得更大。”。</p>
</blockquote><br>15.<br><a href="http://www.sciencemag.org/news/2018/07/beyond-silicon-15-billion-us-program-aims-spur-new-types-computer-chips" target="_blank" rel="external">http://www.sciencemag.org/news/2018/07/beyond-silicon-15-billion-us-program-aims-spur-new-types-computer-chips</a><br><blockquote><p>Silicon computer chips have been on a roll for half a century, getting ever more powerful. But the pace of innovation is slowing.<br>Today the U.S. military’s Defense Advanced Research Projects Agency(DARPA) announced dozens of new grants totaling \$75 million in a program that aims to reinvigorate the chip industry with basic research into new designs and materials, such as carbon nanotubes.<br>Over the next few years, the DARPA program, which supports both academic and industry scientists, will grow to $300 million per year up to a total of $1.5 billion over 5 years.</p>
</blockquote><br>16.<br><a href="http://www.discoverdev.io/archive/2018-08-01.html" target="_blank" rel="external">http://www.discoverdev.io/archive/2018-08-01.html</a><br><a href="http://www.discoverdev.io/archive/2018-08-02.html" target="_blank" rel="external">http://www.discoverdev.io/archive/2018-08-02.html</a><br><a href="http://www.discoverdev.io/archive/2018-08-03.html" target="_blank" rel="external">http://www.discoverdev.io/archive/2018-08-03.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;继续 SCALA TIMES 上的分享&lt;br&gt;&lt;a href=&quot;https://mailchi.mp/softwaremill/scala-times-issue-2607957&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://mailchi.mp/softwaremill/scala-times-issue-2607957&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://manuel.bernhardt.io/2018/07/20/akka-anti-patterns-java-serialization/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Akka anti-patterns: Java serialization&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://mostafa-asg.github.io/post/practical-scala-cats-applicative-functor/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Practical Cats: Functor and Applicative&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://kubuszok.com/2018/implicits-type-classes-and-extension-methods-part-4/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Implicits, type classes, and extension methods, part 4: understanding implicits&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://lampwww.epfl.ch/~doeraene/thesis/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Cross-Platform Language Design&lt;/a&gt;&lt;br&gt;2.&lt;br&gt;Be Nice And Write Stable Code&lt;br&gt;&lt;a href=&quot;http://technosophos.com/2018/07/04/be-nice-and-write-stable-code.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://technosophos.com/2018/07/04/be-nice-and-write-stable-code.html&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Spring + Hikari的一个SQLFeatureNotSupportedException问题</title>
    <link href="http://thomaslau.github.io/2018/07/06/2018-07-06-a-ridiculous-Ex-of-Hikari/"/>
    <id>http://thomaslau.github.io/2018/07/06/2018-07-06-a-ridiculous-Ex-of-Hikari/</id>
    <published>2018-07-05T17:09:07.000Z</published>
    <updated>2018-07-05T17:00:55.712Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br><i>题记：</i><br>遇到个使用Spring xml方式配置Hikari，因为一个Bean的命名原因导致爆出 SQLFeatureNotSupportedException，追溯原因过程其实很简单，但是找到问题所在确实浪费不少时间。<br>2.<br>先看源码。<br>由于某些原因，只能使用 Spring XML方式配置 Hikari的 datasource，我自己使用jdk 1.7版本，不过粗看了下适用1.8+的Hikari代码，应该也是存在这个问题的。<br><a id="more"></a><br>参考Hikari官方的参数配置，如果在你的xml里这么配置 Hikari的 datasource<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"jdbcTemplate"</span> <span class="attr">class</span>=<span class="string">"org.springframework.jdbc.core.JdbcTemplate"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"dataSource"</span> <span class="attr">class</span>=<span class="string">"com.zaxxer.hikari.HikariDataSource"</span> <span class="attr">destroy-method</span>=<span class="string">"close"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"driverClassName"</span> <span class="attr">value</span>=<span class="string">"com.mysql.jdbc.Driver"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jdbcUrl"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.url&#125;"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"username"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.username&#125;"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">value</span>=<span class="string">"$&#123;jdbc.password&#125;"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"maximumPoolSize"</span> <span class="attr">value</span>=<span class="string">"20"</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"minimumIdle"</span> <span class="attr">value</span>=<span class="string">"2"</span> /&gt;</span></div><div class="line">    <span class="comment">&lt;!-- &lt;property name="dataSource" &gt; &lt;null/&gt;&lt;/property&gt; --&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"connectionTestQuery"</span> <span class="attr">value</span>=<span class="string">"select 1 "</span> /&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSourceProperties"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">props</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">prop</span> <span class="attr">key</span>=<span class="string">"cachePrepStmts"</span>&gt;</span>true<span class="tag">&lt;/<span class="name">prop</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">prop</span> <span class="attr">key</span>=<span class="string">"prepStmtCacheSize"</span>&gt;</span>250<span class="tag">&lt;/<span class="name">prop</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">prop</span> <span class="attr">key</span>=<span class="string">"prepStmtCacheSqlLimit"</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">prop</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">prop</span> <span class="attr">key</span>=<span class="string">"useServerPrepStmts"</span>&gt;</span>true<span class="tag">&lt;/<span class="name">prop</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">props</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>那么，当你的程序运行到到从该dataSource取connection时候，很可能会遇到下面这样的异常：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Caused by: java.sql.SQLFeatureNotSupportedException</div><div class="line">    at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:119)</div><div class="line">    at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341)</div><div class="line">    at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:193)</div><div class="line">    at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:428)</div><div class="line">    at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:499)</div><div class="line">    at com.zaxxer.hikari.pool.HikariPool.&lt;init&gt;(HikariPool.java:112)</div><div class="line">    at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:97)</div><div class="line">    at org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)</div><div class="line">    at org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)</div><div class="line">    ... 7 more</div></pre></td></tr></table></figure></p>
<p>即这个dataSource不能使用。<br>我先说一下解决办法：<br>这个异常其实是 id=”dataSource”/ref=”dataSource” 导致的，如果改一下名字，任何非 dataSource的名字，就会神奇的发现，程序正常运行了。<br>3.<br>原因呢？<br>看 <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/src/main/java/com/zaxxer/hikari/HikariDataSource.java##L133" target="_blank" rel="external">HikariDataSource.java</a><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** &#123;<span class="doctag">@inheritDoc</span>&#125; */</span></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">(String username, String password)</span> <span class="keyword">throws</span> SQLException</span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">throw</span> <span class="keyword">new</span> SQLFeatureNotSupportedException();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>发现这里并没有错，的的确确该抛异常了，所以，正常的 getConnection()不是在这个类/方法里。<br>实际上，正常是在 Hikari的 <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/src/main/java/com/zaxxer/hikari/util/DriverDataSource.java#L123" target="_blank" rel="external">DriverDataSource</a> 这个类里<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException</span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">return</span> driver.connect(jdbcUrl, driverProperties);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Connection <span class="title">getConnection</span><span class="params">(String username, String password)</span> <span class="keyword">throws</span> SQLException</span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">return</span> getConnection();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>那么是什么导致 DataSource使用了错误的实现类？<br>从HikariDataSource构造函数入口，到 getConnection 看起，追踪到 -&gt; <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/src/main/java/com/zaxxer/hikari/pool/HikariPool.java#L106" target="_blank" rel="external">HikariPool(this)</a> -&gt; <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/src/main/java/com/zaxxer/hikari/pool/PoolBase.java#L88" target="_blank" rel="external">PoolBase(final HikariConfig config)</a> -&gt; <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/src/main/java/com/zaxxer/hikari/pool/PoolBase.java#L323" target="_blank" rel="external">initializeDataSource()</a><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initializeDataSource</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">final</span> String jdbcUrl = config.getJdbcUrl();</div><div class="line">   <span class="keyword">final</span> String username = config.getUsername();</div><div class="line">   <span class="keyword">final</span> String password = config.getPassword();</div><div class="line">   <span class="keyword">final</span> String dsClassName = config.getDataSourceClassName();</div><div class="line">   <span class="keyword">final</span> String driverClassName = config.getDriverClassName();</div><div class="line">   <span class="keyword">final</span> Properties dataSourceProperties = config.getDataSourceProperties();</div><div class="line"></div><div class="line">   DataSource dataSource = config.getDataSource();</div><div class="line">   <span class="keyword">if</span> (dsClassName != <span class="keyword">null</span> &amp;&amp; dataSource == <span class="keyword">null</span>) &#123;</div><div class="line">      dataSource = createInstance(dsClassName, DataSource.class);</div><div class="line">      PropertyElf.setTargetFromProperties(dataSource, dataSourceProperties);</div><div class="line">   &#125;</div><div class="line">   <span class="keyword">else</span> <span class="keyword">if</span> (jdbcUrl != <span class="keyword">null</span> &amp;&amp; dataSource == <span class="keyword">null</span>) &#123;</div><div class="line">      dataSource = <span class="keyword">new</span> DriverDataSource(jdbcUrl, driverClassName, dataSourceProperties, username, password);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (dataSource != <span class="keyword">null</span>) &#123;</div><div class="line">      setLoginTimeout(dataSource);</div><div class="line">      createNetworkTimeoutExecutor(dataSource, dsClassName, jdbcUrl);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">this</span>.dataSource = dataSource;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里似乎看起来正常，但是，如果我们仔细看 DataSource dataSource = config.getDataSource()，也就是说 HikariConfig 其实有 get/setDataSource属性<br>再看看我们xml里定义的bean，bean id=”dataSource” class=”com.zaxxer.hikari.HikariDataSource”<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HikariDataSource</span> <span class="keyword">extends</span> <span class="title">HikariConfig</span> <span class="keyword">implements</span> <span class="title">DataSource</span>, <span class="title">Closeable</span></span>&#123;</div><div class="line">    ....</div><div class="line">&#125;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HikariConfig</span> <span class="keyword">implements</span> <span class="title">HikariConfigMXBean</span></span></div><div class="line">&#123;</div><div class="line">   ...</div><div class="line">   <span class="keyword">private</span> DataSource dataSource;</div><div class="line">   <span class="comment">/**</span></div><div class="line">    * Set a &#123;<span class="doctag">@link</span> DataSource&#125; for the pool to explicitly wrap.  This setter is not</div><div class="line">    * available through property file based initialization.</div><div class="line">    *</div><div class="line">    * <span class="doctag">@param</span> dataSource a specific &#123;<span class="doctag">@link</span> DataSource&#125; to be wrapped by the pool</div><div class="line">    */</div><div class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDataSource</span><span class="params">(DataSource dataSource)</span></span></div><div class="line">   &#123;</div><div class="line">      <span class="keyword">this</span>.dataSource = dataSource;</div><div class="line">   &#125;</div><div class="line">   ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>发现没有，HikariDataSource 其实还有一个 setDataSource 属性，即我们xml里定义的 id=”dataSource” 其实还是会将自己注入给自己的！<br>这也就是为什么上文中 initializeDataSource 方法里，最终实例化的不是 DriverDataSource 而是自己。</p>
<p>所以，改一个名字就可以了。</p>
<hr>
<p>4.<br>关于 SpringBoot<br>这令我好奇，默认支持使用Hikari作为datasource的SpringBoot是怎么实例化HikariDataSource？会有上述问题吗？<br>这部分代码在<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration</div><div class="line">    <span class="meta">@ConditionalOnClass</span>(HikariDataSource.class)</div><div class="line">        <span class="meta">@ConditionalOnProperty</span>(name = <span class="string">"spring.datasource.type"</span>, havingValue = <span class="string">"com.zaxxer.hikari.HikariDataSource"</span>, matchIfMissing = <span class="keyword">true</span>)</div><div class="line">        <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Hikari</span> <span class="keyword">extends</span> <span class="title">DataSourceConfiguration</span> </span>&#123;</div><div class="line">            <span class="meta">@Bean</span></div><div class="line">            <span class="meta">@ConfigurationProperties</span>(prefix = <span class="string">"spring.datasource.hikari"</span>)</div><div class="line">            <span class="function"><span class="keyword">public</span> HikariDataSource <span class="title">dataSource</span><span class="params">(DataSourceProperties properties)</span> </span>&#123;</div><div class="line">                <span class="keyword">return</span> createDataSource(properties, HikariDataSource.class);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line">org.springframework.boot.autoconfigure.jdbc.DataSourceConfiguration</div><div class="line">    <span class="keyword">protected</span> &lt;T&gt; <span class="function">T <span class="title">createDataSource</span><span class="params">(DataSourceProperties properties,</span></span></div><div class="line">            Class&lt;? extends DataSource&gt; type) &#123;</div><div class="line">        <span class="keyword">return</span> (T) properties.initializeDataSourceBuilder().type(type).build();</div><div class="line">    &#125;</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>不深入了，看下去，反射生成，并且未设置datasource属性，即实际是没有这个问题的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;&lt;i&gt;题记：&lt;/i&gt;&lt;br&gt;遇到个使用Spring xml方式配置Hikari，因为一个Bean的命名原因导致爆出 SQLFeatureNotSupportedException，追溯原因过程其实很简单，但是找到问题所在确实浪费不少时间。&lt;br&gt;2.&lt;br&gt;先看源码。&lt;br&gt;由于某些原因，只能使用 Spring XML方式配置 Hikari的 datasource，我自己使用jdk 1.7版本，不过粗看了下适用1.8+的Hikari代码，应该也是存在这个问题的。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0705</title>
    <link href="http://thomaslau.github.io/2018/07/05/2018-07-05-many_links_0705/"/>
    <id>http://thomaslau.github.io/2018/07/05/2018-07-05-many_links_0705/</id>
    <published>2018-07-04T17:09:07.000Z</published>
    <updated>2018-07-04T17:40:04.495Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>首先推荐来自今天的 <a href="https://wanqu.co/issues/1205?s=/issues" target="_blank" rel="external">湾区日报</a><br>从最初坚持每天5篇分享至今已经1205期了，点赞作者.<br>  1)<a href="https://wanqu.co/a/6700/2018-07-04-who-has-the-best-business-model-and-its-not-google-or-facebook.html?s=/issues/1205" target="_blank" rel="external">最好的商业模式</a>, 微软、苹果、Netflix：花钱的用户是用产品的人；谷歌与FB：花钱的是广告商，用产品的人免费；Amazon、腾讯、阿里：小比例的超级用户花大钱，间接让整个生态变得更好。哪种商业模式好？<br>  2)Firefox + Pocket：打造更好的文章推荐引擎。恐怕很多人不知道Pocket已经被Mozilla收购了。如果你有使用Firefox，打开一个空白新窗口就会看到Pocket推荐的文章，这是根据你使用Firefox的本地浏览记录推荐的。<br>2.<br>Microsoft: The Early Days: <a href="http://www.memecentral.com/mylife.htm" target="_blank" rel="external">http://www.memecentral.com/mylife.htm</a><br>这篇也是湾日的推荐。<br>1981年，作者和其老板Charles Simonyi从计算机人机交互界面发展先驱的施乐走出，经同事即3Com创始人的建议，一起成为微软第77位员工，当时微软刚要开始做应用程序，开始山寨Mac上的电子表格，后来开始做“长得像电子表格的字处理系统”，也就是Word。<br>Word，成为了之后数年的Revenue Bomb， 难怪当年求伯君把自己关在张旋龙（金山创始人，张小龙的哥哥，不是八卦里的微信张小龙）为他在深圳包的一个房间里，日夜兼程写出了字处理系统WPS， 不过当初目标据说是为了超越当时尚火WordStar，WordStar兼容DOS，不过90年后被MS Word超越。<br>求伯君后来吐露，虽然WPS每年收入数千万（1993年前后），但是自己只是个给老板打工的。<br><a id="more"></a><br>3.<br>接 2.<br>文中提到的Charles Simonyi，中文译作 查尔斯·西蒙尼，微软 Word/Excel 开发的Leader，安迪·格鲁夫的老乡，曾经微软首席架构师，高智囊团的核心，所见即所得（What you see is What you get）的发明人。<br>不仅上述实际产出，图形用户界面等，查尔斯·西蒙尼还给微软带去了:<br>1）开发应用软件的经验，当时MS不具备的系统层之上的软件应用经验。<br>2）关于程序员生产力的理论，被Gates称为“软件工厂”理论，也是数年后逃离微软的人吐槽的金字塔层级理论。<br>我曾在学校图书馆角落里看过一本介绍VB之父Alan Cooper的书，里面提到了西蒙尼非比寻常的兴趣:<br>事实上，<a href="https://zh.wikipedia.org/wiki/%E5%A4%AA%E7%A9%BA%E6%B8%B8%E5%AE%A2" target="_blank" rel="external">历史上前6位太空游客</a>，两位就是曾从事程序员的职业，其他四位或是电子计算机相关专业或是创建计算机相关的公司/投资。最让国内程序员熟悉的可能就是一位生于南非的IT界的企业家，马克·沙特尔沃思，Canonical公司创立者，Canonical就是组织创造了Ubuntu的公司，所以到了第二年10月份，知道Ubuntu组织免费提供 Ubuntu系统光盘，那个使用google还可以畅行无阻的时代，我就申请了一个32位的系统盘，珍藏着。<br>4.<br>the hidden costs of touchscreens<br><a href="https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf" target="_blank" rel="external">https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf</a><br>触摸屏真的方便了人们的操作了吗？不是所有场景都提高效率的，有的收银台的POS机变成平板电脑，收银员效率下降不少，得眼睛看屏幕才能操作。<br>我似乎理解了为什么这么多年过去了，国内许多大商场依旧是没有触摸屏的收银台，但更可能的原因是IBM的小型机及其系统确实太昂贵了。<br>其实，我确实更喜欢现在国内一些新型零售的触摸自助结账系统，不用排队，更免去了被花式插队带来的愤怒。<br>但这么做，似乎也淘汰了一批收银员，而这些人中，许多可能是出来打点工，给家庭减少财务负担的，还未到退休年纪或刚到大城市尚未着落的女性。<br>5.<br>The Story Behind How Pocket Hit 20M Users with 20 People<br><a href="http://firstround.com/review/the-story-behind-how-pocket-hit-20m-users-with-20-people" target="_blank" rel="external">http://firstround.com/review/the-story-behind-how-pocket-hit-20m-users-with-20-people</a><br>创立八年，而前四年都是一个人在单打独斗<br>记得13年就在使用pocket，不过那时确实困惑了“read it later”和packet是哪个好久？完全没想到居然是一个人在运营<br>6.<br>大概上个月爆出的 新版JDK += 操作符的副作用<br>很详细的：JDK 9/10/11: Side Effects from += on Java String<br><a href="http://marxsoftware.blogspot.com/2018/06/JDK-8204322.html" target="_blank" rel="external">http://marxsoftware.blogspot.com/2018/06/JDK-8204322.html</a><br><a href="https://stackoverflow.com/questions/50683786/why-does-arrayidx-a-increase-idx-once-in-java-8-but-twice-in-java-9-and-1" target="_blank" rel="external">https://stackoverflow.com/questions/50683786/why-does-arrayidx-a-increase-idx-once-in-java-8-but-twice-in-java-9-and-1</a><br><a href="https://bugs.openjdk.java.net/browse/JDK-8204322" target="_blank" rel="external">https://bugs.openjdk.java.net/browse/JDK-8204322</a><br><a href="http://mail.openjdk.java.net/pipermail/compiler-dev/2018-June/011997.html" target="_blank" rel="external">http://mail.openjdk.java.net/pipermail/compiler-dev/2018-June/011997.html</a><br>7.<br>是否遇到过 “javax.net.ssl.SSLException: Received fatal alert: protocol_version”的异常？<br>实际上这是JDK1.7默认支持的TLS版本导致的异常，JDK1.7+ 默认支持的TLS版本不是TLSv1.2<br><a href="https://scnuwang.github.io/2017/10/11/JDK1.7%E9%BB%98%E8%AE%A4%E6%94%AF%E6%8C%81%E7%9A%84TLS%E7%89%88%E6%9C%AC%E5%AF%BC%E8%87%B4%E5%BC%82%E5%B8%B8/" target="_blank" rel="external">https://scnuwang.github.io/2017/10/11/JDK1.7%E9%BB%98%E8%AE%A4%E6%94%AF%E6%8C%81%E7%9A%84TLS%E7%89%88%E6%9C%AC%E5%AF%BC%E8%87%B4%E5%BC%82%E5%B8%B8/</a><br>查看JDK1.7+ 支持的协议<br><a href="http://docs.oracle.com/javase/7/docs/technotes/guides/security/StandardNames.html#SSLContext" target="_blank" rel="external">http://docs.oracle.com/javase/7/docs/technotes/guides/security/StandardNames.html#SSLContext</a><br>解决方案：在发送请求前设置系统属性：System.setProperty(“https.protocols”, “TLSv1.2”);<br><a href="https://stackoverflow.com/questions/9749339/does-tomcat-support-tls-v1-2" target="_blank" rel="external">https://stackoverflow.com/questions/9749339/does-tomcat-support-tls-v1-2</a><br>8.<br><a href="http://jaminzhang.github.io/os/Linux-IO-Monitoring-and-Deep-Analysis/" target="_blank" rel="external">http://jaminzhang.github.io/os/Linux-IO-Monitoring-and-Deep-Analysis/</a><br>Linux IO 监控与深入分析<br>作者总结的很详细，才知道原来原生的还有这么多命令可用，这些命令还可以这么用。<br><blockquote><p><i><strong>1) 系统级 IO 监控</strong></i>:  iostat -xdm 1<br>如果 %iowait 的值过高，表示磁盘存在 I/O 瓶颈。<br>如果 %util 接近 100%，说明产生的 I/O 请求太多，I/O 系统已经满负荷，该磁盘可能存在瓶颈。<br>如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；<br>如果 await 远大于 svctm，说明 I/O 队列太长，I/O 响应太慢，则需要进行必要优化。<br>如果 avgqu-sz 比较大，也表示有大量 IO 在等待。<br><i><strong>2) 进程级 IO 监控</strong></i>    iotop 和 pidstat<br>pidstat -d 1<br>pidstat -u -r -d -t 1<br>可以回答系统级 IO 监控不能回答的 2 个问题<br>距离业务层相对较近(例如，可以统计进程的读写量)<br>但是也没有办法跟业务层的 read, write 联系在一起，同时颗粒度较粗，没有办法告诉你，当前进程读写了哪些文件？耗时？大小？<br><i><strong>3) 业务级 IO 监控</strong></i>    ioprofile<br>ioprofile 命令本质上是 lsof + strace ioprofile 可以回答你以下三个问题:<br>当前进程某时间内,在业务层面读写了哪些文件(read, write)？<br>读写次数是多少？(read, write 的调用次数)<br>读写数据量多少？(read, write 的 byte 数)<br>注: ioprofile 仅支持多线程程序,对单线程程序不支持. 对于单线程程序的 IO 业务级分析，strace 足以。<br>总结： ioprofile 本质上是 strace，因此可以看到 read，write 的调用轨迹，可以做业务层的 IO 分析(mmap 方式无能为力)<br><i><strong>4) 文件级 IO 监控</strong></i><br>文件级 IO 监控可以配合/补充”业务级和进程级” IO 分析<br>文件级 IO 分析，主要针对单个文件，回答当前哪些进程正在对某个文件进行读写操作<br>lsof 或者 ls /proc/pid/fd<br>inodewatch.stp<br>lsof 告诉你当前文件由哪些进程打开</p>
</blockquote><br>9.<br>jdk11比10包含哪些特性？<br><a href="https://www.oschina.net/news/97145/jdk-11-jep-332?from=20180617" target="_blank" rel="external">https://www.oschina.net/news/97145/jdk-11-jep-332?from=20180617</a><br>列出了相关JEP，可以点击原文查看，原文含详细链接<br><blockquote><p>JDK 11 已确定了 15 个 JEP，下面是完整的列表：<br>181: 基于嵌套的访问控制(Nest-Based Access Control)<br>309: 动态类文件常量(Dynamic Class-File Constants)<br>315: 改进 Aarch64 Intrinsics(Improve Aarch64 Intrinsics)<br>318: Epsilon — 一个无操作的垃圾收集器(Epsilon: A No-Op Garbage Collector)<br>320: 删除 Java EE 和 CORBA 模块(Remove the Java EE and CORBA Modules)<br>321: HTTP Client (Standard)<br>323: 用于 Lambda 参数的局部变量语法(Local-Variable Syntax for Lambda Parameters)<br>324: Curve25519 和 Curve448 算法的密钥协议(Key Agreement with Curve25519 and Curve448)<br>327: Unicode 10<br>328: Flight Recorder<br>329: ChaCha20 和 Poly1305 加密算法(ChaCha20 and Poly1305 Cryptographic Algorithms)<br>330: 启动单一文件的源代码程序(Launch Single-File Source-Code Programs)<br>331: Low-Overhead Heap Profiling<br>333: 处于试验阶段的可伸缩低延迟垃圾收集器 ZGC: A Scalable Low-Latency Garbage Collector (Experimental)<br>336: 弃用 Pack200 工具和 API(Deprecate the Pack200 Tools and API)</p>
</blockquote><br>10.<br>Kafka 源码解析之 Consumer 如何加入一个 Group（六）<br><a href="http://matt33.com/2017/10/22/consumer-join-group/" target="_blank" rel="external">http://matt33.com/2017/10/22/consumer-join-group/</a><br>推荐看作者总结的 Kafka 源码解析 系列<br>11.<br>数据库事务隔离标准分析<br><a href="https://zhuanlan.zhihu.com/p/38214642" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/38214642</a><br>一直记不住的数据库隔离级别：<br><blockquote><p>本文首先介绍了ANSI基于“异象”的隔离级别标准，并分析了其狭义和广义的描述；然后介绍了基于锁的隔离级别标准，与ANSI隔离级别进行了比较；最后分析快照隔离级别，在ANSI隔离级别标准基础上，提出了两种新的“异象”，得出快照隔离在几种标准隔离级别特性中的位置。<br>ANSI SQL-92标准(<a href="http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt)将数据库并发事务间的隔离性行为划分为3种&quot;异象(phenomena)&quot;，从低到高的自然语言定义依次为：" target="_blank" rel="external">http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt)将数据库并发事务间的隔离性行为划分为3种&quot;异象(phenomena)&quot;，从低到高的自然语言定义依次为：</a><br><i><strong>P1 脏读 (“Dirty read”)</strong></i>: SQL-transaction T1 modifies a row. SQL- transaction T2 then reads that row before T1 performs a COMMIT. If T1 then performs a ROLLBACK, T2 will have read a row that was never committed and that may thus be considered to have never existed.<br><i><strong>P2 不可重复读 (“Non-repeatable read”)</strong></i>: SQL-transaction T1 reads a row. SQL- transaction T2 then modifies or deletes that row and performs a COMMIT. If T1 then attempts to reread the row, it may receive the modified value or discover that the row has been deleted.<br><i><strong>P3 幻读 (“Phantom”)</strong></i>: SQL-transaction T1 reads the set of rows N that satisfy some <search condition="">. SQL-transaction T2 then executes SQL-statements that generate one or more rows that satisfy the <search condition=""> used by SQL-transaction T1. If SQL-transaction T1 then repeats the initial read with the same <search condition="">, it obtains a different collection of rows.<br><i><strong>P1/P2/P3的形式化描述</strong></i><br>根据标准文档的定义，可以将这三种异象使用形式化语言描述如下，称为A1/A2/A3（其中w1[x]表示事务1写入记录x，r1表示事务1读取记录x，c1表示事务1提交，a1表示事务1回滚，r1[P]表示事务1按照谓词P的条件读取若干条记录，w1[y in P]表示事务1写入记录y满足谓词P的条件）：</search></search></search></p>
<p>A1 脏读：w1[x] … r2[x] … (a1 and c2 in any order)<br>A2 不可重复读：r1[x] … w2[x] … c2 … r1[x] … c1<br>A3 幻读：r1[P] … w2[y in P] … c2 … r1[P] … c1<br>上述A1/A2/A3形式化描述，根据标准定义的P1/P2/P3异象的自然语言描述转化而来，但是ANSI标准定义的异象只针对了单个记录或谓词描述，对于多条记录需满足业务一致性的场景并未能覆盖（比如两个账户间转账要求余额总和不变），举例如下：<br>H1：r1[x=50]w1[x=10] r2[x=10]r2[y=50] c2 r1[y=50]w1[y=90] c1<br>事务1执行账户x向账户y转账40，事务2读取到了进行到了一半的事务1（Read Uncommitted），破坏了余额总和的一致性<br>因为事务1并未回滚，H1的行为并不符合A1的形式化定义<br>H2：r1[x=50] r2[x=50]w2[x=10]r2[y=50]w2[y=90] c2 r1[y=90] c1<br>事务2执行账户x向账户y转账40，事务1在事务2提交前后读取到了破坏余额总和一致性的数据（Unrepeatable Read）<br>因为事务1并未重复读取记录x，H2的行为并不符合A2的形式化定义<br>H3：r1[P] w2[insert y to P] r2[z] w2[z] c2 r1[z] c1<br>事务2增加新雇员并更新雇员总数z，事务1在事务2提交前后读取到了破坏雇员列表与雇员总数的一致性的数据（Phantom）<br>因为事务1并未重复读取谓词P指定的数据集合，H3的行为并不符合A3的形式化定义.<br>因为要增强对上述H1/H2/H3异象的约束，论文将A1/A2/A3的形式化描述称为“狭义的描述(strict interpretations)”，然后增加了“广义的描述(broad interpretation)”，去除了strict interpretations中对事务提交、回滚和数据读取范围的约束，只保留事务之间读写的时序关系，即事务之间只要包含如下时序的操作，即可能产生包含H1/H2/H3在内的异象，如下：<br>P1 脏读：w1[x] … r2[x] … ((c1 or a1) and (c2 or a2) in any order)<br>P2 不可重复读：r1[x] … w2[x] … ((c1 or a1) and (c2 or a2) in any order)<br>P3 幻读：r1[P] … w2[y in P] … ((c1 or a1) and (c2 or a2) in any order)<br>在上述形式化描述下，禁止P1即可禁止H1，禁止P1/P2即可禁止H2，禁止P1/P2/P3即可禁止H3。至此，ANSI标准隔离级别定义的三种异象，可以被扩展为适用范围更广的的P1/P2/P3的形式化定义，这种隔离级别定义被论文称之为“phenomena-based”，即基于“异象”的隔离级别定义。</p>
</blockquote><br>可以惨考这篇文章，实例分析，加深印象<br>《A Critique of ANSI SQL Isolation Levels》论文实验<br><a href="https://zhuanlan.zhihu.com/p/38334464" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/38334464</a><br>12.<br>国内Elasticsearch早期布道者 Medcl 的新书计划：Elastic 搜索开发实战<br><a href="https://elastic-search-in-action.medcl.com/0.1_abstract.html" target="_blank" rel="external">https://elastic-search-in-action.medcl.com/0.1_abstract.html</a><br>13.<br>很不错的功能: Kafka 1.1新功能：数据的路径间迁移<br><a href="http://www.cnblogs.com/huxi2b/p/9214592.html" target="_blank" rel="external">http://www.cnblogs.com/huxi2b/p/9214592.html</a><br>14.<br>JDK 11中将会加入令人惊叹的ZGC(不到2毫秒)<br><a href="http://openjdk.java.net/jeps/333" target="_blank" rel="external">http://openjdk.java.net/jeps/333</a><br><a href="https://zhuanlan.zhihu.com/p/38348775?group_id=993277353635659776" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/38348775?group_id=993277353635659776</a><br>15.<br><a href="http://vmlens.com/articles/3_tips_volatile_fields/" target="_blank" rel="external">http://vmlens.com/articles/3_tips_volatile_fields/</a><br>艺海拾贝：3 Tips for volatile fields in java<br><blockquote><p>Volatile fields are one of built-in mechanism to write multi-threaded java.<br>Volatile variables are not cached in registers or in caches where they are hidden from other processors, so a read of a volatile variable always returns the most recent write by any thread. … The visibility effects of volatile variables extend beyond the value of the volatile variable itself. When thread A writes to a volatile variable and subsequently thread B reads that same variable, the values of all variables that were visible to A prior to writing to the variable become visible to B after reading the volatile variable.<br>— Java Concurrency in Practice - Brian Goetz, et al.<br>1) Use volatile fields when writes do not depend on its current value.<br>2) Use volatile fields for reading and locks for writing<br>3) Use with JDK 9 VarHandle for atomic operations.</p>
</blockquote><br>16.<br>来点轻松的：<br>计算机领域有哪些经典的典故或笑话？<br><a href="https://www.zhihu.com/question/20034686" target="_blank" rel="external">https://www.zhihu.com/question/20034686</a><br>看到一个有趣的链接：<br>RegEx match open tags except XHTML self-contained tags<br><a href="https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags" target="_blank" rel="external">https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags</a><br>第一个高赞答案分析了一堆理由，然后作者大概是 苦正则表达式匹配 html久已，还故意留了一段 血腥字体 的示例<br>可怜的 stackoverflow 编辑 或许是苦于“Please do not flag it for our attention”特意加了一段 网页显示没问题，原文就是这样 的声明。<br>开头还加了一段 lock 讨论的声明，太多讨论无关主题<br><i><strong>向 stackoverflow 对技术对社区质量负责任的态度致敬。</strong></i></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;首先推荐来自今天的 &lt;a href=&quot;https://wanqu.co/issues/1205?s=/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;湾区日报&lt;/a&gt;&lt;br&gt;从最初坚持每天5篇分享至今已经1205期了，点赞作者.&lt;br&gt;  1)&lt;a href=&quot;https://wanqu.co/a/6700/2018-07-04-who-has-the-best-business-model-and-its-not-google-or-facebook.html?s=/issues/1205&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;最好的商业模式&lt;/a&gt;, 微软、苹果、Netflix：花钱的用户是用产品的人；谷歌与FB：花钱的是广告商，用产品的人免费；Amazon、腾讯、阿里：小比例的超级用户花大钱，间接让整个生态变得更好。哪种商业模式好？&lt;br&gt;  2)Firefox + Pocket：打造更好的文章推荐引擎。恐怕很多人不知道Pocket已经被Mozilla收购了。如果你有使用Firefox，打开一个空白新窗口就会看到Pocket推荐的文章，这是根据你使用Firefox的本地浏览记录推荐的。&lt;br&gt;2.&lt;br&gt;Microsoft: The Early Days: &lt;a href=&quot;http://www.memecentral.com/mylife.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.memecentral.com/mylife.htm&lt;/a&gt;&lt;br&gt;这篇也是湾日的推荐。&lt;br&gt;1981年，作者和其老板Charles Simonyi从计算机人机交互界面发展先驱的施乐走出，经同事即3Com创始人的建议，一起成为微软第77位员工，当时微软刚要开始做应用程序，开始山寨Mac上的电子表格，后来开始做“长得像电子表格的字处理系统”，也就是Word。&lt;br&gt;Word，成为了之后数年的Revenue Bomb， 难怪当年求伯君把自己关在张旋龙（金山创始人，张小龙的哥哥，不是八卦里的微信张小龙）为他在深圳包的一个房间里，日夜兼程写出了字处理系统WPS， 不过当初目标据说是为了超越当时尚火WordStar，WordStar兼容DOS，不过90年后被MS Word超越。&lt;br&gt;求伯君后来吐露，虽然WPS每年收入数千万（1993年前后），但是自己只是个给老板打工的。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0619</title>
    <link href="http://thomaslau.github.io/2018/06/19/2018-06-19-many_links_0619/"/>
    <id>http://thomaslau.github.io/2018/06/19/2018-06-19-many_links_0619/</id>
    <published>2018-06-18T16:09:07.000Z</published>
    <updated>2018-06-19T17:41:12.915Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>NON-Tech</em></strong><br>1.<br>看这篇文章，体会下感受下生在互联网时代，20世纪形成的政治体制正在变得“古老”的路上。<br>毕竟，现在有多少人会觉得 马基雅弗利的政治“智慧”没有过时？<br>道德危机的起源 The Making of a Moral Crisis<br>“many-chambered heart of the internet”(不知怎么翻译) 如何将特朗普政府的家庭分离政策变为另一种丑闻<br><a href="https://www.theatlantic.com/technology/archive/2018/06/the-making-of-a-moral-problem/563114/" target="_blank" rel="external">https://www.theatlantic.com/technology/archive/2018/06/the-making-of-a-moral-problem/563114/</a><br><a href="https://translate.google.com/translate?sl=auto&amp;tl=zh-CN&amp;js=y&amp;;prev=_t&amp;;hl=zh-CN&amp;ie=UTF-8&amp;u=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2018%2F06%2Fthe-making-of-a-moral-problem%2F563114%2F&amp;edit-text=&amp;authuser=0" target="_blank" rel="external">如果没时间可以速读谷歌翻译出来的中文</a>，下面是我从google翻译里摘抄部分<br><a id="more"></a><br><blockquote><p>像劳拉布什所说的那样，2岁以下的孩子已经从父母那里被带走，转移到“二十世纪二战日本美国拘禁营”的“令人毛骨悚然的”设施。 家庭正在分居。 孩子们正在笼子里的金属箔毯下睡觉。<br>这个故事受到如此多关注的主要原因很简单：这太可怕了。 当然， 大多数显示哭泣孩子的图像或者听到他们录音的孩子 的美国选民都呼吁为他们的父母提供强烈的消极反应。<br>但在当今分裂和陌生的媒体环境中，更难以回答的问题是如此多的人最终看到这些图像并听到这些故事。 毕竟，这可能是美国边界上最臭名昭着的不公正，但这不是第一次。<br>…<br>美国人喜欢相信透明度，就像路易斯·布兰代斯法官曾经说的那样，“阳光据说是最好的消毒剂”。但是阳光不再仅仅来自报纸头版或电视广播塔。 这是Facebook视频和模因，微博风暴和病毒图片。 虽然这并不是说这个故事只是从互联网的角落冒出来的。 移民局和调查记者已经上了一年多。 参议员卡马拉哈里斯在12月首次谈到这件事。 但直到5月底才成为该国最大的新闻。 怎么样？<br>…<br>但是没有任何来自边界的报道可以说明发生了什么。 有不祥的报道，但不是真实的人的考验故事。<br>然后在纽约时报上刊登了4月20日的一则重磅炸弹 。 Caitlin Dickerson写道：“自从10月份以来，已有超过700名儿童被成人自称为父母，其中包括100多名4岁以下的儿童。 现在是米里安。<br>…<br>然后，在5月15日的听证会上，参议员哈里斯向国土安全部负责人Kirstjen Nielsen提出了父母分居的答案，这在政治 出版物上引发了另一阵新闻报道。 最终，他们的交流将被NowThisPolitics打包成一个病毒视频，该视频在Facebook上分享超过7.7万次，但直到5月28日才会发布。<br>与此同时，亚利桑那共和国专栏作家EJ Montini突显了1,500名儿童的故事， 此后他的作品被“今日美国”杂志联合播出。这似乎是引发正义狂热的比赛。<br>…<br>当威斯康星州议会候选人凯茜迈耶斯将其发布到她的Facebook上时，这篇评论文章开始通过Reddit的r /政治渗透，然后通过自由世界起飞。 在Twitter上，前美国检察官Preet Bharara在Twitter上发表推文称：“在美国，边境婴幼儿的父母强行分离出什么更可耻的东西？ 然后，失去这些孩子的踪迹？“它有8万个喜欢和超过26,000转推。<br>…<br>然而，值得注意的是，随着新闻周期通过互联网的众多心脏，它没有推动这个国家的分化。 事实上，已经出现了一个很大的共识： 三分之二的美国人不希望家庭分离继续下去 ，包括各种性别，种族，年龄和教育水平的多数群体。 所有的故事，推文，视频和照片的累积力量都是向心力的，让这个国家更接近一起。<br>这基本上是技术人员的梦想，最终在边界儿童的噩梦中找到了现实。</p>
</blockquote><br>后记：<br>看到互联网，国外是Facebook/Twitter，在舆论上的“星火燎原”的力量，相比纸媒时代。相比下一开始就注重舆论监管/管控的政府，可谓未雨绸缪，技改一筹。<br>看看半互联网一代，原住民一代是如何在网络时代产生作用。<br>然而，需要反问的是，这些病毒式传播或迅速发酵的转发/评论/点赞/观点，有多少是经得起推敲和深度思考的？<br>2.<br>同样分享另一篇文章，也是跟Internet相关的，是twitter上，对Micrsoft口诛笔伐 过程被作者写的很精彩：<br>帮川普作恶，微软被围攻<br><a href="https://mp.weixin.qq.com/s/9NgFiBtD-FBWymiIbZ-q4A" target="_blank" rel="external">https://mp.weixin.qq.com/s/9NgFiBtD-FBWymiIbZ-q4A</a><br><blockquote><p>微软避锅大法<br>特朗普有甩锅大法，微软有避锅大法。他们表示坚决要和ICE的这些作为划清界限，但网友们依然不肯放过：<br>今年年初，你们可不是这么说的。<br>今年1月，微软Azure全球基础设施负责人Tom Keane在官方博客上发文，宣布微软Azure云服务拿下了美国空军和ICE的合同。博客中说，Azure会帮ICE处理敏感的未分类数据，还会帮他们运用深度学习来加速人脸识别和身份验证等。<br>ICE“正在为国土安全和公共安全部署革命性技术，我们很骄傲，可以用作为我们关键任务的云服务来支持这些工作。”Keane在一月的博客中态度很是明确：proud。<br>5月从Google离职的William Fitzgerald转发这条Twitter时，直接揪住这个“骄傲”质问微软CEO萨蒂亚·纳德拉（Satya Nadella）：从妻离子散中赚钱，你骄傲？<br>随后，微软把博客里关于ICE的部分给删掉了。<br>这种欲盖弥彰的举动，引起了群众更大的反弹，也吸引媒体的兴趣。BuzzFeed、彭博社等多家媒体都报道了这一事件，也向微软询问了抹去信息的原因。<br>于是，这篇博客没过多久又恢复了原样。<br>微软的解释是：有个员工看见社交媒体上的评论之后暂时删除了博客内容，这是个错误行为，我们发现就把博客改回来了。<br>现在，微软对ICE的这些作为表示“惊诧”，还迫切希望这一部门改变政策，敦促国会通过保障儿童不再与家庭分离的法规，但丝毫没有表现出要退出项目不再续约的意思。<br>据彭博政府数据显示，微软和ICE的合同金额是1914万美元。</p>
</blockquote><br>3.<br><a href="https://www.theatlantic.com/technology/archive/2018/06/shops-arent-for-shopping-anymore/563054/" target="_blank" rel="external">Shops Aren’t for Shopping Anymore</a><br>Retail stores used to be places to buy things. Smartphones changed that, and retailers are struggling to invent new reasons, and methods, for shopping.<br>零售店曾经是购买物品的地方。 智能手机改变了这种状况，零售商正在努力发明新的理由和方法，以便购物。<br>这是不同于国内高新零售的玩法，国内像阿里/京东做的零售店，其实主题甚至内容不过依旧都是零售，体验似乎也只在虚拟换装/支付便利性等，就像在盒马基本上就是吃吃吃而已，看看看食物而已。<br>但文中所描绘的改变显然更进一步些。<br>4.<br>HBaseConWest2018演讲 - HBase Practice In XiaoMi<br><a href="http://openinx.github.io/2018/06/18/hbaseconwest2018/" target="_blank" rel="external">http://openinx.github.io/2018/06/18/hbaseconwest2018/</a><br><blockquote><p>HBaseConWest2018于6.18日在美国加州圣何塞举办，本次会议由Hortonworks承办。每年去美国硅谷参加HBaseConWest已经算是小米HBase团队的惯例了，一方面小米团队在HBase社区的影响力有目共睹，目前已经培养了7位HBase Committer，其中有2位HBase PMC；另外一方面，小米内部也很乐意对外去分享公司一年所做的工作，相当于把一年的工作（包括内部的实践以及社区贡献）做一个年度总结分享给大家。<br>所以，2018年我们也很积极的提交了演讲议题(HBase Practice In XiaoMi)，并花了很多精力整理总结，内部还做过3次英文试讲。但遗憾的是，今年中美关系比较紧张，美国签证没有如期办下来</p>
</blockquote><br>5.<br>A Century in Wordclouds<br>想法很好，只可惜我对文中的结果存疑，但想法真的很好。<br><a href="https://towardsdatascience.com/a-century-in-wordclouds-72be5f5ca391" target="_blank" rel="external">https://towardsdatascience.com/a-century-in-wordclouds-72be5f5ca391</a></p>
<p>###Tech</p>
<p>6.<br>使用JITWatch查看JVM的JIT编译代码<br><a href="https://liuzhengyang.github.io/2017/07/27/jitwatch/" target="_blank" rel="external">https://liuzhengyang.github.io/2017/07/27/jitwatch/</a><br>7.<br>OpenJDK commiter 的正确社交礼仪<br>不过从视频看，听众似乎不多<br><a href="https://www.youtube.com/watch?v=mMvXcZV-2ZY" target="_blank" rel="external">https://www.youtube.com/watch?v=mMvXcZV-2ZY</a><br>另一篇关于OpenJDK的<br>AdoptOpenJDK: Enhancing OpenJDK’s “build, test, contribute” pipeline<br><a href="https://www.youtube.com/watch?v=d9HnAQAcfjQ" target="_blank" rel="external">https://www.youtube.com/watch?v=d9HnAQAcfjQ</a><br>8.<br>Cloud Native Java, part deux, with Josh Long<br>话唠龙之春，看看开头对 cloud java的推崇；<br><a href="https://www.youtube.com/watch?v=GW656IAU5ZE" target="_blank" rel="external">https://www.youtube.com/watch?v=GW656IAU5ZE</a><br>9.<br><a href="http://highscalability.com/blog/2018/6/15/stuff-the-internet-says-on-scalability-for-june-15th-2018.html" target="_blank" rel="external">http://highscalability.com/blog/2018/6/15/stuff-the-internet-says-on-scalability-for-june-15th-2018.html</a><br>@taotetek: The goal of an observability team is not to collect logs, metrics or traces. It is to build a culture of engineering based on facts and feedback, and then spread that culture within the broader organization.<br>有点道理，鱼渔的观点<br>@tiffanycli: Reminder: When you give your DNA data to companies like <a href="http://Ancestry.com" target="_blank" rel="external">http://Ancestry.com</a>  or 23andMe, you give up not only your own genetic privacy, but that of your entire family. (It’s in the terms &amp; conditions.)<br>匹夫无罪，基因其罪<br>10.<br>一文读懂 Spark 和 Spark Streaming<br><a href="https://ericfu.me/apache-spark-in-nutshell/" target="_blank" rel="external">https://ericfu.me/apache-spark-in-nutshell/</a><br>一般来说，想做到 fault-tolerance 只有两个方案：要么存储到外部（例如 HDFS），要么拷贝到多个副本。Spark 大胆地提出了第三种——重算一遍。但是之所以能做到这一点，是依赖于一个额外的假设：所有计算过程都是确定性的（deterministic）。Spark 借鉴了函数式编程思想，提出了 RDD（Resilient Distributed Datasets），译作“弹性分布式数据集”。<br>11.<br>很不错的分享：从头开始写一个日志采集Agent<br>日志采集中的关键技术分析<br><a href="http://jm.taobao.org/2018/06/13/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/" target="_blank" rel="external">http://jm.taobao.org/2018/06/13/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%88%86%E6%9E%90/</a><br>这里贴出一部分，非常建议去看原文，相信会有更多收获<br><blockquote><p>如何发现一个文件?<br>定时去轮询下目录或许是个不错的方法，但是轮询的周期太长会导致不够实时，太短又会耗CPU，你也不希望你的采集Agent被人吐槽占用太多CPU吧。Linux内核给我们提供了高效的Inotify的机制，由内核来监测一个目录下文件的变化，然后通过事件的方式通知用户。但是别高兴的太早，Inotify并没有我们想的那么好，它存在一些问题，首先并不是所有的文件系统都支持Inotify，此外它不支持递归的目录监测<br>基于轮询的方式其优点就是保证不会漏掉文件，除非文件系统发生了bug，通过增大轮询的周期可以避免浪费CPU、但是实时性不够。Inotify虽然很高效，实时性很好但是不能保证100%不丢事件。因此通过结合轮询和Inotify后可以相互取长补短。<br>点位文件高可用<br>点位文件? 对就是通过点位文件来记录文件名和对应的采集位置。那如何保证这个点位文件可以可靠的写入呢? 因为可能在文件写入的那一刻机器Crash了导致点位数据丢掉或者数据错乱了。要解决这个问题就需要保证文件写入要么成功，要么失败，绝对不能出现写了一半的情况。Linux内核给我们提供了原子的rename。一个文件可以原子的rename成另外一个文件，利用这个特性可以保证点位文件的高可用。假设我们已经存在一份点位文件叫做offset，每一秒我们去更新这个点位文件，将采集的位置实时的记录在里面，整个更新的过程如下：<br>将点位数据写入到磁盘的offset.bak文件中<br>fdatasync确保数据写入到磁盘<br>通过rename系统调用将offset.bak更名为offset<br>通过这个手段可以保证在任何时刻点位文件都是正常的，因为每次写入都会先确保写入到临时文件是成功的，然后原子的进行替换。这样就保证了offset文件总是可用的。在极端场景下会导致1秒内的点位没有及时更新，日志采集Agent启动后会再次采集这1秒内的数据进行重发，这基本上满足需求了。</p>
<p>但是点位文件中记录了文件名和对应的采集位置这会带来另外一个问题，如果在进程Crash的过程中，文件被重命名了该怎么办?<br>Linux内核提供了inode可以作为文件的标识信息，而且保证同一时刻Inode是不会重复的，这样就可以解决上面的问题，在点位文件中记录文件的inode和采集的位置即可。日志采集Agent启动后通过文件发现找到要采集的文件，通过获取Inode然后从点位文件中查找对应的采集位置，最后接着后面继续采集即可。那么即使文件重命名了但是它的Inode不会变化，所以还是可以从点位文件中找到对应的采集位置。但是Inode有没有限制呢? 当然有，天下没有免费的午餐，不同的文件系统Inode会重复，一个机器可以安装多个文件系统，所以我们还需要通过dev(设备号)来进一步区分，所以点位文件中需要记录的就是dev、inode、offset三元组。到此为止我们的采集Agent可以正常的采集日志了，即使Crash了再次启动后仍然可以继续进行采集。但是突然有一天我们发现有两个文件居然是同一个Inode，Linux内核不是保证同一时刻不会重复的吗?难道是内核的bug?注意我用的是“同一时刻”，内核只能保证在同一时刻不会重复，这到底是什么意思呢? 这便是日志采集Agent中会遇到的一个比较大的技术挑战，如何准确的标识一个文件。</p>
<p>如何识别一个文件?<br>如何标识一个文件算是日志采集Agent中一个比较有挑战的技术问题了，我们先是通过文件名来识别，后来发现文件名并不可靠，而且还耗费资源，后来我们换成了dev+Inode，但是发现Inode只能保证同一时刻Inode不重复，那这句话到底是什么意思呢? 想象一下在T1时刻有一个文件Inode是1我们发现了并开始采集，一段时间后这个文件被删除了，Linux内核就会将这个Inode释放掉，新创建一个文件后Linux内核会将刚释放的Inode又分配给这个新文件。那么这个新文件被发现后会从点位文件中查询上次采集到哪了，结果就会找到之前的那个文件记录的点位了，导致新文件是从一个错误的位置进行采集。如果能给每一个文件打上一个唯一标识或许就可以解决这个问题，幸好Linux内核给文件系统提供了扩展属性xattr，我们可以给每一个文件生成唯一标识记录在点位文件中，如果文件被删除了，然后创建一个新的文件即使Inode相同，但是文件标识不一样，日志采集Agent就可以识别出来这是两个文件了</p>
<p>如何知道文件内容更新了?<br>Inotify可以解决这个问题、通过Inotify监控一个文件，那么只要这个文件有新增数据就会触发事件，得到事件后就可以继续采集了。但是这个方案存在一个问题就是在大量文件写入的场景会导致事件队列溢出，比如用户连续写入日志N次就会产生N个事件，其实对于日志采集Agent只要知道内容就更新就可以了，至于更新几次这个反而不重要， 因为每次采集其实都是持续读文件，直到EOF，只要用户是连续写日志，那么就会一直采集下去。另外Intofy能监控的文件数量也是有上限的。所以这里最简单通用的方案就是轮询去查询要采集文件的stat信息，发现文件内容有更新就采集，采集完成后再触发下一次的轮询，既简单又通用<br>如何安全的释放文件句柄?<br>Fluentd的处理方式就是将这部分的责任推给用户，让用户配置一个时间，文件删除后如果在指定的时间范围内没有数据新增就释放fd，其实这就是间接的甩锅行为了。这个时间配置的太小会造成丢数据的概率增大，这个时间配置的太大会导致fd和磁盘空间一直被占用造成短时间自由浪费的假象</p>
</blockquote><br>12.<br>阿里巴巴为什么不用 ZooKeeper 做服务发现？<br><a href="http://jm.taobao.org/2018/06/13/%E5%81%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9F/" target="_blank" rel="external">http://jm.taobao.org/2018/06/13/%E5%81%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9F/</a><br>作者其实讨论的是关于服务配置/服务发现/服务状态，这些当然目前也没听说有同时实现。。。<br>这里贴出一部分，非常建议去看原文，相信会有更多收获.<br><blockquote><p>注册中心是 CP 还是 AP 系统?<br>CAP 和 BASE 理论相信读者都已经耳熟能详，其业已成了指导分布式系统及互联网应用构建的关键原则之一，在此不再赘述其理论，我们直接进入对注册中心的数据一致性和可用性需求的分析:<br>数据一致性需求分析?<br>分区容忍及可用性需求分析?:<br>接下来我们看一下网络分区（Network Partition）情况下注册中心不可用对服务调用产生的影响，即 CAP 中的A不满足时带来的影响。<br>当机房3出现网络分区(Network Partitioned)的时候，即机房3在网络上成了孤岛，我们知道虽然整体 ZooKeeper 服务是可用的，但是节点ZK5是不可写的，因为联系不上 Leader。<br>也就是说，这时候机房3的应用服务 svcB 是不可以新部署，重新启动，扩容或者缩容的，但是站在网络和服务调用的角度看，机房3的 svcA 虽然无法调用机房1和机房2的 svcB,但是与机房3的svcB之间的网络明明是 OK 的啊，为什么不让我调用本机房的服务？<br>现在因为注册中心自身为了保脑裂(P)下的数据一致性（C）而放弃了可用性，导致了同机房的服务之间出现了无法调用，这是绝对不允许的！可以说在实践中，注册中心不能因为自身的任何原因破坏服务之间本身的可连通性，这是注册中心设计应该遵循的铁律！ 后面在注册中心客户端灾容上我们还会继续讨论。<br>同时我们再考虑一下这种情况下的数据不一致性，如果机房1，2，3之间都成了孤岛，那么如果每个机房的svcA都只拿到本机房的 svcB 的ip列表，也即在各机房svcB 的ip列表数据完全不一致，影响是什么？<br>其实没啥大影响，只是这种情况下，全都变成了同机房调用，我们在设计注册中心的时候，有时候甚至会主动利用这种注册中心的数据可以不一致性，来帮助应用主动做到同机房调用，从而优化服务调用链路 RT 的效果！<br>注册中心需要持久存储和事务日志么？<br>需要，也不需要。<br>我们知道 ZooKeeper 的 ZAB 协议对每一个写请求，会在每个ZooKeeper节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，以及宕机之后的数据可恢复，这是非常好的特性，但是我们要问，在服务发现场景中，其最核心的数据-实时的健康的服务的地址列表真的需要数据持久化么？<br>Service Health Check<br>使用 ZooKeeper 作为服务注册中心时，服务的健康检测常利用 ZooKeeper 的 Session 活性 Track机制 以及结合 Ephemeral ZNode的机制，简单而言，就是将服务的健康监测绑定在了 ZooKeeper 对于 Session 的健康监测上，或者说绑定在TCP长链接活性探测上了。<br>这在很多时候也会造成致命的问题，ZK 与服务提供者机器之间的TCP长链接活性探测正常的时候，该服务就是健康的么？答案当然是否定的！注册中心应该提供更丰富的健康监测方案，服务的健康与否的逻辑应该开放给服务提供方自己定义，而不是一刀切搞成了 TCP 活性检测！<br>我们在阿里巴巴内部应用接入 ZooKeeper 时，有一个《ZooKeeper 应用接入必知必会》的 WIKI，其中关于异常处理有过如下的论述:<br>…</p>
</blockquote><br>13.<br>如上，不错的zookeeper踩坑分享<br>采用zookeeper的EPHEMERAL节点机制实现服务集群的陷阱<br><a href="https://yq.aliyun.com/articles/227260" target="_blank" rel="external">https://yq.aliyun.com/articles/227260</a><br><blockquote><p>1、不处理zk的连接状态变化事件导致zk客户端断开后与zk服务器集群没有重连。后果：连接丢失后EPHEMERAL节点会删除并且客户端watch丢失。<br>2、在synconnected事件中创建EPHEMERAL节点没有判断此节点是否已经存在，在已经存在的情况下没有判断是否应该删除重建，后果：EPHEMERAL节点丢失导致可用的服务器不在可用服务器列表中。<br>3、应用程序关闭时不主动关闭zk客户端，后果：导致可用服务器列表包含已经失效的服务器。<br>4、创建一个zk客户端时，zk客户端连接zk服务器是异步的，如果在连接还没有建立时就调用zk客户端会抛异常。<br>5、在zk的事件中执行长时间的业务<br>6、使用2.X版本的Curator时，ExponentialBackoffRetry的maxRetries参数设置的再大都会被限制到29：MAX_RETRIES_LIMIT。</p>
</blockquote><br>14.<br>很不错的总结<br>实时数据的可视化<br><a href="http://icodeit.org/2018/06/real-time-data-visualization/" target="_blank" rel="external">http://icodeit.org/2018/06/real-time-data-visualization/</a><br>15.<br>Theranos founder Elizabeth Holmes may be our first true feminist anti-hero<br><a href="https://work.qz.com/1285831/theranos-founder-elizabeth-holmes-may-be-our-first-true-feminist-anti-hero/" target="_blank" rel="external">https://work.qz.com/1285831/theranos-founder-elizabeth-holmes-may-be-our-first-true-feminist-anti-hero/</a><br>16.<br>How to prevent logback from outputting its own status at the start of every log?<br><a href="https://stackoverflow.com/questions/3257154/how-to-prevent-logback-from-outputting-its-own-status-at-the-start-of-every-log" target="_blank" rel="external">https://stackoverflow.com/questions/3257154/how-to-prevent-logback-from-outputting-its-own-status-at-the-start-of-every-log</a><br>如何让logback不输出自己的status信息，诸如在启动logback时的：“11:21:27,825 |-INFO in ch.qos.logback…”信息？<br><blockquote><p>If you have any configuration problems of level WARN or above, you will also get all status information logged to the console (including messages of level INFO). The best solution to this problem is to fix the problem (in your case replace the <layout> element with an <encoder> element).<br>If you for some reason cannot fix the problem, but want to remove the status-information from the console, you can instead configure an alternative StatusListener. Use the NopStatusListener to completely remove the status-information:</encoder></layout></p>
</blockquote><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">statusListener</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.status.NopStatusListener"</span> /&gt;</span></div><div class="line">  <span class="comment">&lt;!-- etc --&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>17.<br><a href="https://blog.softwaremill.com/scalaz-8-io-vs-akka-typed-actors-vs-monix-part-1-5672657169e1" target="_blank" rel="external">https://blog.softwaremill.com/scalaz-8-io-vs-akka-typed-actors-vs-monix-part-1-5672657169e1</a><br>18.<br>Meet the New Logstash Java Execution Engine<br><a href="https://www.elastic.co/blog/meet-the-new-logstash-java-execution-engine" target="_blank" rel="external">https://www.elastic.co/blog/meet-the-new-logstash-java-execution-engine</a><br>新版Logstash采用Java Execution Engine，大大提升性能<br>19.<br><a href="http://arganzheng.life/ai-infrastructures-from-big-data-to-deep-learning.html" target="_blank" rel="external">http://arganzheng.life/ai-infrastructures-from-big-data-to-deep-learning.html</a><br>20.<br>github上上周一个 pop 项目<br><a href="https://github.com/danistefanovic/build-your-own-x" target="_blank" rel="external">https://github.com/danistefanovic/build-your-own-x</a><br>21.<br><a href="https://github.com/pod4g/hiper" target="_blank" rel="external">https://github.com/pod4g/hiper</a><br>22.<br><a href="https://medium.com/observability/microservices-observability-26a8b7056bb4" target="_blank" rel="external">https://medium.com/observability/microservices-observability-26a8b7056bb4</a><br>23.<br><blockquote><p>From the Hotspot JVM source code, we can see the following GC roots types:</p>
</blockquote><br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> RootType &#123; </div><div class="line">  universe = <span class="number">1</span>, </div><div class="line">  jni_handles           = <span class="number">2</span>, </div><div class="line">  threads               = <span class="number">3</span>, </div><div class="line">  object_synchronizer   = <span class="number">4</span>, </div><div class="line">  system_dictionary     = <span class="number">5</span>, </div><div class="line">  class_loader_data     = <span class="number">6</span>, </div><div class="line">  management            = <span class="number">7</span>, </div><div class="line">  jvmti                 = <span class="number">8</span>, </div><div class="line">  code_cache            = <span class="number">9</span> </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<blockquote><p>And from comment of source code, we can conclude the meaning of those roots:<br>Universe: is a name space holding known system classes and objects in the VM. The object heap is allocated and accessed through Universe, and various allocation support is provided.<br><i><strong>JNIHandles</strong></i>: JNI code<br><i><strong>Threads</strong></i>: live threads<br><i><strong>ObjectSynchronizer</strong></i>: monitor object<br><i><strong>Management</strong></i>: JVM used management class<br><i><strong>JvmtiExport</strong></i>: JVM tool interface, for debug &amp; profiling;<br><i><strong>SystemDictionary</strong></i>: Loaded classes are accessible through the SystemDictionary.<br><i><strong>ClassLoaderDataGraph</strong></i>: A class loader represents a linkset. Conceptually, a linkset identifies the complete transitive closure of resolved links that a dynamic linker can produce. A ClassLoaderData also encapsulates the allocation space, called a metaspace, used by the dynamic linker to allocate the runtime representation of all the types it defines.</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;em&gt;NON-Tech&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;1.&lt;br&gt;看这篇文章，体会下感受下生在互联网时代，20世纪形成的政治体制正在变得“古老”的路上。&lt;br&gt;毕竟，现在有多少人会觉得 马基雅弗利的政治“智慧”没有过时？&lt;br&gt;道德危机的起源 The Making of a Moral Crisis&lt;br&gt;“many-chambered heart of the internet”(不知怎么翻译) 如何将特朗普政府的家庭分离政策变为另一种丑闻&lt;br&gt;&lt;a href=&quot;https://www.theatlantic.com/technology/archive/2018/06/the-making-of-a-moral-problem/563114/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.theatlantic.com/technology/archive/2018/06/the-making-of-a-moral-problem/563114/&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://translate.google.com/translate?sl=auto&amp;amp;tl=zh-CN&amp;amp;js=y&amp;amp;;prev=_t&amp;amp;;hl=zh-CN&amp;amp;ie=UTF-8&amp;amp;u=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2018%2F06%2Fthe-making-of-a-moral-problem%2F563114%2F&amp;amp;edit-text=&amp;amp;authuser=0&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;如果没时间可以速读谷歌翻译出来的中文&lt;/a&gt;，下面是我从google翻译里摘抄部分&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0612</title>
    <link href="http://thomaslau.github.io/2018/06/12/2018-06-12-many_links_0612/"/>
    <id>http://thomaslau.github.io/2018/06/12/2018-06-12-many_links_0612/</id>
    <published>2018-06-11T16:09:07.000Z</published>
    <updated>2018-06-12T17:25:16.201Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br><a href="https://www.elastic.co/blog/this-week-in-elasticsearch-and-apache-lucene-2018-05-18" target="_blank" rel="external">https://www.elastic.co/blog/this-week-in-elasticsearch-and-apache-lucene-2018-05-18</a><br>ElasticSearch 新进展:<br><blockquote><p>在7.0.0中，新索引默认接收一个分片（而不是五个）。我们进行了这项更改以帮助解决当前默认值导致的常见问题：过度分解。许多用户最终拥有太多的分片，我们认为将默认设置降为1将有助于解决这种情况<br>高级REST客户端中的搜索模板支持<br>带有静态评分信号的更快的top-k查询…还有很多可以参考更新notes</p>
</blockquote><br>2.<br><a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="external">http://karpathy.github.io/2016/09/07/phd/</a><br>A Survival Guide to a PhD<br><a id="more"></a><br>3.<br>How a Kalman filter works, in pictures<br><a href="http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/" target="_blank" rel="external">http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</a></p>
<p>大一学《机械制图》一门课时，囫囵吞枣地了解到卡尔曼滤波在测量上的作用，但如果去了解背后的思想，还是蛮惊叹的:<br><blockquote><p>卡尔曼滤波（Kalman filtering）一种利用线性系统状态方程，通过系统输入输出观测数据，对系统状态进行最优估计的算法。由于观测数据中包括系统中的噪声和干扰的影响，所以最优估计也可看作是滤波过程。<br>斯坦利·施密特(Stanley Schmidt)首次实现了卡尔曼滤波器。卡尔曼在NASA埃姆斯研究中心访问时，发现他的方法对于解决阿波罗计划的轨道预测很有用，后来阿波罗飞船的导航电脑使用了这种滤波器。 关于这种滤波器的论文由Swerling (1958), Kalman (1960)与 Kalman and Bucy (1961)发表。<br>数据滤波是去除噪声还原真实数据的一种数据处理技术, Kalman滤波在测量方差已知的情况下能够从一系列存在测量噪声的数据中，估计动态系统的状态. 由于, 它便于计算机编程实现, 并能够对现场采集的数据进行实时的更新和处理, Kalman滤波是目前应用最为广泛的滤波方法, 在通信, 导航, 制导与控制等多领域得到了较好的应用.<br>卡尔曼滤波的局限性在于其只能拟合线性高斯系统。但其最大的优点在于计算量小，能够利用前一时刻的状态（和可能的测量值）来得到当前时刻下的状态的最优估计。</p>
</blockquote><br>4.<br>Pinterest如何利用机器学习实现两亿月活跃用户，来自Infoq的分享<br><a href="http://www.infoq.com/cn/presentations/pinterest-get-two-hundred-million-global-monthly-active-users" target="_blank" rel="external">http://www.infoq.com/cn/presentations/pinterest-get-two-hundred-million-global-monthly-active-users</a><br><blockquote><p>Pinterest主要业务：个性化主页，搜索，相关图片，广告，如今实现2亿月活用户离不开其可以让用户沉浸其中的推荐。<br>Pinterest推荐模型<br>线性推荐模型<br>上线过两个版本:逻辑回归(Logistic Regression)和支持向量机排序(SVM_Rank)<br>● 都使用的开源软件<br>○ LR: scikit-learn<br>○ SVM_rank: sofia-ml<br>● 为数不多的特征<br>○ 最初版本包含12个图片特征以及图片与用户交互信息的特征<br>例如:图片的近期点击率，用户是否曾与图片所在的图板产生过互动 </p>
<p>2015年:<br>模型使用约有500个非稀疏特征<br>优点:用户活跃度显著提高 (新增20%活跃用户)<br>弊端:<br>  1.线性模型不能很好利用高维度的复杂特征/需要手动添加交叉特征 (cross features)<br>  2.单纯用户方面的特征(例如年龄，性别等)对线性模型无意义</p>
<p>2016年:<br>迭代决策树 Gradient Boosted Decision Trees (GBDT) 上线的迭代决策树模型<br>优点<br>  1.非线性模型可以有效的探索和转化特征向量空间<br>  2.对于单个特征值误差包容度较高<br>  3.准确高效的特征重要性分析<br>缺点<br>  1.模型参数数量按决策树深度几何级数增长<br>  2.无法有效利用高维度的稀疏特征<br>  3.对离散特征的概括性的总结利用不够充分<br>迭代决策树+Embedding特征<br>  缺点<br>  在迭代决策树里使用的一些离散特征只是单纯记忆(memorization) 而<br>非概括性的总结(generialization)<br>  ● 用户和图片的国家，语言等<br>  ● 一般只是用来作为比较用户和图片的相应特征是否相同 ● 未完全利用这些离散特征的潜在预测价值<br>例如<br>  ● 来自德国的用户和来自奥地利的用户可能有很多的共同喜好(啤酒，古典音乐…)<br>  ● 我们有很多德国用户的历史记录，而只有很少奥地利用户的历史记录<br>  ● 迭代决策树模型不能很好的利用基本的用户国家特征</p>
<p>2017年:基于TensorFlow平台的深度学习模型<br>● 迭代决策树对于特征交互利用的局限性<br>● 很多用户和图片的特征信息需要人为定义<br>● 深度学习在很多机器视觉项目和推荐系统中的成功应用</p>
</blockquote></p>
<p>5.<br>如何看待技术？（指的是系统）<br>曾流传“技术无罪”，很多人信以为真，或者奉为圭臬，但是本talk里，不这么认为，举了一些例子，如hack，crack，系统故障，以及本为方便考虑却被人作漏洞使用。<br>喜欢这句：<br>” Bad software ruins people’s lives.“<br>我相信随着软件逐渐渗透每个人的日常生活，或者要成为个体的一部分，软件就要考虑这类问题，甚至这些会成为一个门槛，届时对coder的要求会更高，<br>而不仅仅是现在这样，给一个需求，开发功能就ok了的。<br><blockquote><p>在一个后真相的世界里，软件并不一定要恶意才会有危险。例如，在2016年，Facebook用一种算法取代了它的(人工)新闻编辑。几天之内，阴谋论便成为了热门话题，并以“新闻”的形式出现。’<br>在本讲座中，我们将讨论在一个看起来更像是《黑镜》中每一周都在上演的情节的世界中构建软件的伦理考虑。没有软件存在于真空中。作为开发人员，我们必须了解软件的社会含义，以帮助我们对我们所涉及的内容以及如何构建软件做出道德决策。当我们认为事情可能出错时，我们必须勇敢的说出来。而且，如果别人说出来，要愿意听。<br>简而言之:我们必须谦虚，我们必须警惕，我们必须确保我们做出的决定意味着我们可以在晚上睡觉。</p>
</blockquote><br>这里推荐几个链接，关于技术的定位。<br><a href="https://www.youtube.com/watch?v=A5umy4lUOOY" target="_blank" rel="external">https://www.youtube.com/watch?v=A5umy4lUOOY</a><br>不过技术干货不多，甚至最后总结的三个方法过于抽象，可以直接看pdf<br><a href="https://files.gotocon.com/uploads/slides/conference_7/286/original/so-you-can-sleep-at-night-goto-berlin-4.key.pdf" target="_blank" rel="external">https://files.gotocon.com/uploads/slides/conference_7/286/original/so-you-can-sleep-at-night-goto-berlin-4.key.pdf</a><br>或<br><a href="https://github.com/swissmobidevs/appbuilders18/tree/master/slides" target="_blank" rel="external">https://github.com/swissmobidevs/appbuilders18/tree/master/slides</a><br>6.<br>布隆过滤器:Google Guava类库源码分析及基于Redis Bitmaps的重构<br><a href="https://segmentfault.com/a/1190000012620152" target="_blank" rel="external">https://segmentfault.com/a/1190000012620152</a><br>BloomFilter，大家应该都熟悉，简单来说 “布隆过滤器是用来判断一个元素是否出现在给定集合中的重要工具，具有快速，比哈希表更节省空间等优点，而缺点在于有一定的误识别率（false-positive，假阳性）”<br>那么你了解“那么到底需要多少个哈希函数，以及创建长度为多少的bit数组比较合适”吗， 文章作者简要分析 Guava的BloomFilter代码实现，并引出了Redis的Bitmaps的“数据结构”来实现。</p>
<p>7.<br>Amazon CTO的未来，以来的未来的技术畅想<br>The workplace of the future<br><a href="https://www.allthingsdistributed.com/2018/05/workplace-of-the-future.html" target="_blank" rel="external">https://www.allthingsdistributed.com/2018/05/workplace-of-the-future.html</a><br>作者关于未来的工作场所的思考，多读几遍，才体会到，是不是空洞的不重要，未来确是在路上。<br><blockquote><p>We already have an idea of how digitalization, and above all new technologies like machine learning, big-data analytics or IoT, will change companies’ business models — and are already changing them on a wide scale. So now’s the time to examine more closely how different facets of the workplace will look and the role humans will have.</p>
<p>In fact, the future is already here – but it’s still not evenly distributed. Science fiction author William Gibson said that nearly 20 years ago. We can observe a gap between the haves and the have-nots: namely between those who are already using future technologies and those who are not. The consequences of this are particularly visible on the labor market many people still don’t know which skills will be required in the future or how to learn them.</p>
</blockquote><br>8.<br>来自The Daily WTF的技术 WTF分享，都比较有趣<br><a href="https://thedailywtf.com/articles/perfectly-technical-difficulties" target="_blank" rel="external">https://thedailywtf.com/articles/perfectly-technical-difficulties</a><br>9.<br>Gates Notes 2018夏季读书推荐<br><a href="https://www.gatesnotes.com/About-Bill-Gates/Summer-Books-2018" target="_blank" rel="external">https://www.gatesnotes.com/About-Bill-Gates/Summer-Books-2018</a><br><blockquote><p>Leonardo da Vinci, by Walter Isaacson.<br>Everything Happens for a Reason and Other Lies I’ve Loved, by Kate Bowler.<br>Lincoln in the Bardo, by George Saunders.<br>Origin Story: A Big History of Everything, by David Christian.<br>Factfulness, by Hans Rosling, with Ola Rosling and Anna Rosling Ronnlund. </p>
</blockquote><br>10.<br>Netflix-zuul2 正式开源了，这个一些国内知名网站模仿的微服务网关组件<br><a href="https://medium.com/netflix-techblog/open-sourcing-zuul-2-82ea476cb2b3" target="_blank" rel="external">https://medium.com/netflix-techblog/open-sourcing-zuul-2-82ea476cb2b3</a><br>infoq的翻译<br><a href="http://www.infoq.com/cn/news/2018/05/netflix-zuul2" target="_blank" rel="external">http://www.infoq.com/cn/news/2018/05/netflix-zuul2</a><br>11.<br>Java的序列化特性将要退出历史舞台了<br><a href="http://www.infoq.com/cn/news/2018/05/oracle-plans-to-dump-java-serial" target="_blank" rel="external">http://www.infoq.com/cn/news/2018/05/oracle-plans-to-dump-java-serial</a><br><blockquote><p>甲骨文公司Java平台部门首席架构师Mark Reinhold表示，去除序列化机制是一项长期目标，亦是其专注于面向Java语言功能生产力强化目标的Amber项目的重要组成部分。<br>为了替换现有序列化技术，甲骨文方面将在相关记录（即Java版本的数据类）获得支持之后，向Java平台中添加一套小型序列化框架。该框架能够支持记录图，而开发人员亦可接入自己选择的序列化引擎、支持JSON或XML等格式，并以安全方式实现记录序列化功能。不过Reinhold目前还无法确定记录功能将正式登陆Java的哪个版本。<br>根据Reinhold的说法，序列化功能堪称诞生于1997年的一个“可怕错误”。他估计，至少有三分之一甚至是半数Java安全漏洞都与序列化机制有关。序列化总体而言存在巨大安全风险，但Reinhold表示其在简单用例当中的出色易用性仍具有一定吸引力。<br>最近，Java刚刚迎来了过滤功能，因此如果开发者必须在网络之上使用序列化功能且愿意接受不可信序列化数据流，则可借此选择需要过滤掉的类以实现针对序列化安全弱点的防御机制。Reinhold指出，甲骨文公司目前收到大量运行在网络之上的应用服务器的报告，并发现其中相当一部分在未受保护的端口上使用序列化流。正是为了解决这一问题，过滤功能才应运而生。</p>
</blockquote><br>12.<br>顺便回忆下另外一个关于Java Fastjson的序列化漏洞<br>Fastjson 1.2.24 反序列化分析<br><a href="https://www.secpulse.com/archives/72391.html" target="_blank" rel="external">https://www.secpulse.com/archives/72391.html</a><br>13.<br>Centrifuge: a reliable system for delivering billions of events per day<br><a href="https://segment.com/blog/introducing-centrifuge/" target="_blank" rel="external">https://segment.com/blog/introducing-centrifuge/</a><br>14.<br>Another DI 框架<br><a href="http://www.baeldung.com/dagger-2" target="_blank" rel="external">http://www.baeldung.com/dagger-2</a><br><a href="https://segmentfault.com/a/1190000008016507" target="_blank" rel="external">https://segmentfault.com/a/1190000008016507</a><br><blockquote><p>起初Square公司受到Guice的启发而开发了Dagger，但是Dagger这种半静态半运行时的框架还是有些性能问题（虽说依赖注入是完全静态的，但是其有向无环图(Directed Acyclic Graph)还是基于反射来生成的，这无论在大型的服务端应用还是在Android应用上都不是最优方案）。因此Google工程师Fork了Dagger项目，对它进行了改造。于是变演变出了今天我们要讨论的Dagger2，所以说Dagger2其实就是高配版的Dagger。</p>
</blockquote><br>15.<br><a href="https://www.cnet.com/news/inside-an-amazon-warehouse-that-ships-your-supersized-purchases" target="_blank" rel="external">https://www.cnet.com/news/inside-an-amazon-warehouse-that-ships-your-supersized-purchases</a><br>Why would Amazon even care to offer a Yeti statue for sale? After all, it’s expensive to ship that big guy. Well, that’s likely because the company is keen on building up our muscle memory, so for whatever we can dream of wanting, we’ll go to Amazon first.<br>为什么亚马逊甚至会提供一个雪人雕像出售？毕竟，运送这个大个子很贵。那可能是因为公司热衷于增强肌肉记忆力，所以无论我们想要什么，我们都会先去亚马逊。</p>
<p>16.<br>JEP社区一个有趣的帖子的总结。Shebang Coming to Java?<br><a href="https://www.javacodegeeks.com/2018/05/shebang-coming-java.html" target="_blank" rel="external">https://www.javacodegeeks.com/2018/05/shebang-coming-java.html</a><br>这样想法类似<br><blockquote><p>A Jonathan Giles message in this discussion spells out “various reasons to not want to change JLS or javac“, points out that “shebang scripts are an executable format defined on some, but not all, platforms,” points out that “creating a shebang script is typically more than just adding an initial first line to a file,” and articulates the concept of differentiating explicitly between traditional Java source code and JEP 330 executable Java scripts:<br>Another interesting side note from this discussion is Brian Goetz’s “retrace” of how JEP 330 got to its current state. He talks about the “countless hours listening to people’s concerns about Java” that led to this realization, “A general theme that people have expressed concern over is ‘activation energy’; that doing simple things in Java requires too much fixed work.” Goetz points out that JShell and JEP 330 are two of many possible ways of addressing this and that these two approaches were selected from among the many after making “subjective choices about which had the best impact” with consideration of “cost (in multiple dimensions) and benefit (or our subjective estimates of the benefits) when making these choices.”</p>
</blockquote><br>17.<br>福特汽车零件，都要生产线分类，并配备不同工种的工人专门负责一个环节，很难相信Netflix还有整条生产线工人: Full Cycle Developers at Netflix — Operate What You Build<br><a href="https://medium.com/netflix-techblog/full-cycle-developers-at-netflix-a08c31f83249" target="_blank" rel="external">https://medium.com/netflix-techblog/full-cycle-developers-at-netflix-a08c31f83249</a><br>18.<br>深入Spring Boot：实现对Fat Jar jsp的支持<br><a href="http://hengyunabc.github.io/spring-boot-fat-jar-jsp-sample/" target="_blank" rel="external">http://hengyunabc.github.io/spring-boot-fat-jar-jsp-sample/</a><br>19.<br>来自 碼天狗週刊 第 130 期 分享<br><a href="https://vinta.ws/code/vinta-on-codetengu-weekly-issue-130-programming-code-review-scrum-mongodb-nosql-ipfs.html" target="_blank" rel="external">https://vinta.ws/code/vinta-on-codetengu-weekly-issue-130-programming-code-review-scrum-mongodb-nosql-ipfs.html</a><br>20<br>Hystrix官方工作原理wiki的翻译<br><a href="http://atbug.com/how-hystrix-works/" target="_blank" rel="external">http://atbug.com/how-hystrix-works/</a><br>21<br>Made with ♥ by a group of nerds on Earth!<br><a href="http://www.discoverdev.io/archive/2018-05-22.html" target="_blank" rel="external">http://www.discoverdev.io/archive/2018-05-22.html</a><br>不错的网站，每天分享6-10个链接，我看了很久，Ruanyifeng老师也推荐的<br>22<br>如何长时间高效学习？ - Andrew Xu的回答 - 知乎<br><a href="https://www.zhihu.com/question/28358499/answer/43002343" target="_blank" rel="external">https://www.zhihu.com/question/28358499/answer/43002343</a><br>23<br>经常熬夜的人身体损失了什么？ - 格伦的回答 - 知乎<br><a href="https://www.zhihu.com/question/57235424/answer/244881132" target="_blank" rel="external">https://www.zhihu.com/question/57235424/answer/244881132</a><br>24.<br>6 months off<br>一位google go++工程师@rakyll的离开open source(github) 6个月 的理由<br><a href="https://medium.com/@rakyll/6-months-off-5a6ef304cd02" target="_blank" rel="external">https://medium.com/@rakyll/6-months-off-5a6ef304cd02</a><br><a href="https://twitter.com/rakyll" target="_blank" rel="external">https://twitter.com/rakyll</a><br><a href="https://github.com/rakyll" target="_blank" rel="external">https://github.com/rakyll</a><br>这算是这期的福利<br>25.<br>一个关于 目测是关于河马生鲜的有趣故事，我也只能呵呵了<br><a href="http://highscalability.com/blog/2018/6/8/stuff-the-internet-says-on-scalability-for-june-8th-2018.html" target="_blank" rel="external">http://highscalability.com/blog/2018/6/8/stuff-the-internet-says-on-scalability-for-june-8th-2018.html</a><br><blockquote><p>Harrison Jacobs: The joke used to be that Chinese people like to live near good public schools, Liyan Chen, the manager of international corporate affairs at Alibaba, told Business Insider. “The joke now in China is that they want to live where the Hemas are, because then they can get everything delivered to them really easily.”…The technological advancements Alibaba has brought to Hema — easy in-app ordering, ultrafast delivery, price matching, facial-recognition payment, tailored stocking based on spending habits, etc. — Amazon could easily bring to Whole Foods. And in my opinion, given Amazon’s obsession with efficiency, it’s a matter of not if, but when.</p>
</blockquote><br>26.<br>对程序员说的正能量<br>@Nick_Craver: If you’re an engineer, programmer, whatever or hoping to be one. Don’t listen to these claims. Large projects always have tons of mistakes in them. Minimize them. Learn from them. Try not to repeat them. Move on. Remember to laugh at them later. It’s part of life. Don’t sweat it.<br>27.<br>80/90分别有着自己的语言，但是程序员其实也有，比如：<br><a href="https://twitter.com/Stephan007/status/1004987356338884609" target="_blank" rel="external">https://twitter.com/Stephan007/status/1004987356338884609</a><br>28。<br>为什么说GPDR不会长久？<br>@jim_dowling: Counter example. 5 years ago your facebook landing page was built by select …group by. Now that same page load causes up to 9m machine learning model inferences per second…. You’re welcome.<br>实际上，网站已开始只有最简单的功能，但是随着公司规模的扩张，公司想要更好的的理解用户，需要新功能的开发，这就导致，同样简单请求，做的事情可能越来越多。<br>29.<br>从一笔交易说起，如何处理好数据的一致性问题<br><a href="http://www.iigrowing.cn/cong_yi_bi_jiao_yi_shuo_qi_ru_he_chu_li_hao_shu_ju_de_yi_zhi_xing_wen_ti.html" target="_blank" rel="external">http://www.iigrowing.cn/cong_yi_bi_jiao_yi_shuo_qi_ru_he_chu_li_hao_shu_ju_de_yi_zhi_xing_wen_ti.html</a><br>一直记不住这些，所以最怕别人问到这些，反正记住的大多不求甚解，真正遇到问题时考虑不到这点。而遇到问题能自然的敏感到有这么个理论存在，才是真正的掌握。就像Einstein只记得光速是c而不记得具体数字值。<br><blockquote><p>事务隔离级别<br>Read Uncommitted: 允许脏读，不可重复读，存在幻读<br>Read Committed: 没有脏读脏读，不可重复读（提交后可读），存在幻读<br>Repeatable Read: 没有有脏读，可重复度，存在幻读<br>Serializable: 没有脏读，可重复度，不存在幻读</p>
<p>Serializable串行执行，效率太低。一般使用Repeatable Read，这类隔离级别可重复读，保证一个事物内数据处理的一致性，避免了脏读也防止了事务回滚造成的脏数据，更大程度上保证了事务的一致性，至于幻读，如果我们处理好具有竞争关系的数据库资源，则可以很好的避免数据不一致的问题</p>
</blockquote><br>30.<br>你的电子设备一年耗电多少？<br><a href="http://www.chip.cn/article-175-1.html" target="_blank" rel="external">http://www.chip.cn/article-175-1.html</a><br>31.<br>收藏几个网友智慧的链接：<br>mac程序员必备以及常用app<br><a href="https://www.zhihu.com/question/20036899" target="_blank" rel="external">https://www.zhihu.com/question/20036899</a><br><a href="https://www.zhihu.com/question/19550256" target="_blank" rel="external">https://www.zhihu.com/question/19550256</a><br><a href="https://leohxj.gitbooks.io/a-programmer-prepares/software/mac/software-list.html" target="_blank" rel="external">https://leohxj.gitbooks.io/a-programmer-prepares/software/mac/software-list.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;&lt;a href=&quot;https://www.elastic.co/blog/this-week-in-elasticsearch-and-apache-lucene-2018-05-18&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.elastic.co/blog/this-week-in-elasticsearch-and-apache-lucene-2018-05-18&lt;/a&gt;&lt;br&gt;ElasticSearch 新进展:&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;在7.0.0中，新索引默认接收一个分片（而不是五个）。我们进行了这项更改以帮助解决当前默认值导致的常见问题：过度分解。许多用户最终拥有太多的分片，我们认为将默认设置降为1将有助于解决这种情况&lt;br&gt;高级REST客户端中的搜索模板支持&lt;br&gt;带有静态评分信号的更快的top-k查询…还有很多可以参考更新notes&lt;/p&gt;
&lt;/blockquote&gt;&lt;br&gt;2.&lt;br&gt;&lt;a href=&quot;http://karpathy.github.io/2016/09/07/phd/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://karpathy.github.io/2016/09/07/phd/&lt;/a&gt;&lt;br&gt;A Survival Guide to a PhD&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>捕风捉影 0524</title>
    <link href="http://thomaslau.github.io/2018/05/24/2018-05-24-pieces_0524/"/>
    <id>http://thomaslau.github.io/2018/05/24/2018-05-24-pieces_0524/</id>
    <published>2018-05-24T14:09:07.000Z</published>
    <updated>2018-05-24T16:43:30.022Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>推荐一部德剧，五一期间追完两季，可以直接看知乎上的评论<a href="https://www.zhihu.com/question/268264479" target="_blank" rel="external">如何评价18年新剧《巴比伦柏林》</a><br><blockquote><p>这部剧是于去年10月在德国播出的，今年的1月30日才在网飞上线。它是德国历史上最贵的一部剧，近4000万欧元的制作成本，也让它成了非英语类电视剧中最烧钱的作品。<br>豆瓣9.0，烂番茄新鲜度100%，IMDb8.5<br>今年的德国电视奖上，它一举斩获了最佳剧集、最佳摄像、最佳音乐和最佳美术指导四项大奖，现已续订到了第三季。</p>
</blockquote><br>如果你喜欢《大明王朝1566》，那这部剧值得一看，毕竟《大明王朝1566》其实更多聚集在这一时期“朝堂”之上的故事，围绕为官各方利益，但这部剧其实“包罗万象”，讲述魏玛共和国时期德国故事，也即1929年，希特勒登场前期，上至兴登堡总统，警察厅长将军，下至贫民百姓，电视剧描述这一时期各个阶层，有贫民窟有崛起的工人阶级有难民，从苏联逃出的沙俄后裔，以及斯大林驱逐的布尔什维克，作为逃难者都聚焦在这一时期的柏林。<br>想象一百年亲涌入的各方势力涌入一战至希特勒上台时期德国，甚至早起留学德国的中国各派。<br>看完后，或许可以理解，为什么默克尔大妈敢收留难民不惧混乱。<br><a id="more"></a><br>剧集另一个特色是各种插曲，一度误以为是一部音乐剧或者时装剧，但也不乏恐怖紧张暴力色情露骨等镜头。<br>2.<br>再推荐美剧，《Godless》，中文译作 无神 ，同样是NexFlix网飞出品，风格独具质量上乘的西部片。<br>见过唐顿庄园里的大小姐穿着西部牛仔持枪穿越枪林弹雨吗？<br>体验过拖沓烦闷的情节坚持前五集，直到最后一集才喷射而出剧情风格吗？<br>这部似乎取材于伊斯特伍德的西部片故事，让你在欣赏故事情节或是血脉喷张或是紧张或是催人泪下之余，还可以欣赏到西部自然风光。<br>更是一部真正的女权主义赞美诗。<br>3.<br>再荐姜文今年有暑期电影，《邪不压正》还有50天上映，这部高晓松欲买而不得，唯有长叹的电影，许知远十三邀姜文，期待。<br>4.<br>  <i>十分花钱买差评，百零合作赚五角。 - 打尻三表</i></p>
<p>这是听闻腾讯投资“差评君”后感想，个人了解不多，不过看过霍矩/六神等经历，还是对“差评”这个公众号印象不好的，很难相信腾讯这样体量的公司会赚这点钱。真正验证了一句俗话，一点墨染了一缸水。<br>后半句是听闻一大公司合作五角大楼项目，其员工联名反对，真是瓜田不纳鞋，李下不摘冠的自律。<br>5.<br>还是关于微信升级公众号，取消了留言的时间，所以有时候看留言会觉得突兀，以前看时间还可以看到一句留言是评论另一句留言。<br>一个产品不能自我阉割的主要功能都不剩，那是错把一穷二白当简洁了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;推荐一部德剧，五一期间追完两季，可以直接看知乎上的评论&lt;a href=&quot;https://www.zhihu.com/question/268264479&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;如何评价18年新剧《巴比伦柏林》&lt;/a&gt;&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;这部剧是于去年10月在德国播出的，今年的1月30日才在网飞上线。它是德国历史上最贵的一部剧，近4000万欧元的制作成本，也让它成了非英语类电视剧中最烧钱的作品。&lt;br&gt;豆瓣9.0，烂番茄新鲜度100%，IMDb8.5&lt;br&gt;今年的德国电视奖上，它一举斩获了最佳剧集、最佳摄像、最佳音乐和最佳美术指导四项大奖，现已续订到了第三季。&lt;/p&gt;
&lt;/blockquote&gt;&lt;br&gt;如果你喜欢《大明王朝1566》，那这部剧值得一看，毕竟《大明王朝1566》其实更多聚集在这一时期“朝堂”之上的故事，围绕为官各方利益，但这部剧其实“包罗万象”，讲述魏玛共和国时期德国故事，也即1929年，希特勒登场前期，上至兴登堡总统，警察厅长将军，下至贫民百姓，电视剧描述这一时期各个阶层，有贫民窟有崛起的工人阶级有难民，从苏联逃出的沙俄后裔，以及斯大林驱逐的布尔什维克，作为逃难者都聚焦在这一时期的柏林。&lt;br&gt;想象一百年亲涌入的各方势力涌入一战至希特勒上台时期德国，甚至早起留学德国的中国各派。&lt;br&gt;看完后，或许可以理解，为什么默克尔大妈敢收留难民不惧混乱。&lt;br&gt;
    
    </summary>
    
    
      <category term="life" scheme="http://thomaslau.github.io/tags/life/"/>
    
      <category term="碎言碎语" scheme="http://thomaslau.github.io/tags/%E7%A2%8E%E8%A8%80%E7%A2%8E%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0515</title>
    <link href="http://thomaslau.github.io/2018/05/15/2018-05-15-many_links_0515/"/>
    <id>http://thomaslau.github.io/2018/05/15/2018-05-15-many_links_0515/</id>
    <published>2018-05-14T16:09:07.000Z</published>
    <updated>2018-05-14T17:02:23.223Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br><a href="https://blog.csdn.net/dengxing1234/article/details/77965536" target="_blank" rel="external">CTR预估中的贝叶斯平滑方法（一）</a><br>学习了：<br><blockquote><p>广告形式：互联网广告可以分为以下三种：<br>1）展示广告（display ad）<br>2）搜索广告（sponsored search ad）<br>3）上下文广告（contextual ad）<br>竞价模式：对于在线广告，主要有以下几种竞价模式：<br>1）pay-per-impression（按展示付费）：广告商按照广告被展示的次数付费，这是一种最普遍的竞价模型。缺点在于没有考虑投放广告的效果。<br>2）pay-per-action（按行为付费）：只有在广告产生了销售或者类似的一些转化时，广告商才付费。缺点在于追踪用户的交易行为相对比较困难。<br>3）pay-per-click（按用户点击付费）：根据用户是否会点击广告来付费。这时候就需要对广告的点击率（CTR）进行精确的预估。<br>遇到的困难：<br>由于数据的稀疏性，对广告进行CTR预估是比较具有挑战性的，预估出来的CTR的可靠性不高，且具有较大的方差。主要有以下两类场景：<br>1）当广告的展示次数较少的时候，对其直接进行CTR的统计计算会导致一个偏高的结果。比如某个广告只展示了1次，被点击了1次，则纯粹的统计CTR=1.0，这显然是过分高估了。<br>2）当广告的展示次数很大，但点击次数很少或几乎没有的时候，对其直接进行CTR的统计计算会导致一个偏低的结果。比如某个广告没有被点击过，则纯粹的统计CTR=0.0，这显然是过分低估了。</p>
</blockquote><br><a id="more"></a><br>2.<br><a href="https://arxiv.org/pdf/1803.10195v1.pdf" target="_blank" rel="external">What we talk about when we talk about monads</a><br>作者Tomas Petricek，看似简介monad，但感觉是在探讨一种理解编程语言的思维/框架。<br>有时间可以用这篇短文打发一下：<br><blockquote><p>More generally, we present a framework for understanding programming concepts that considers them at three levels: formal, metaphorical and implementation. We base such observations on established results about the scientific method and mathematical entities – cognitive sciences suggest that the metaphors used when thinking about monads are more important than widely accepted, while philosophy of science explains how the research paradigm from which monads originate influences and restricts their use.<br>Finally, we provide evidence for why a broader philosophical, sociological look at programming concepts should be of interest for programmers. It lets us understand programming concepts better and, fundamentally, choose more appropriate abstractions as illustrated in a number of case studies that conclude the paper.</p>
</blockquote><br>3.<br><a href="https://tech.meituan.com/mt_proguard.html" target="_blank" rel="external">插件化、热补丁中绕不开的Proguard的坑</a><br>一直对proguard混淆感兴趣，可惜未深入看过，本文当入门似乎有点深，但是分析思路很好。<br><blockquote><p>ProGuard是2002年由比利时程序员Eric Lafortune发布的一款优秀的开源代码优化、混淆工具，适用于Java和Android应用，目标是让程序更小，运行更快，在Java界处于垄断地位。<br>主要分为三个模块：Shrinker（压缩器）、Optimizer（优化器）、Obfuscator（混淆器）、Retrace（堆栈反混淆）。<br>Shrinker 通过引用标记算法，将没用到的代码移除掉。<br>Optimizer 通过复杂的算法（Partial Evaluation &amp;Peephole optimization，这部分算法我们不再展开介绍）对字节码进行优化，代码优化会使部分代码块的结构出现变动。<br>Obfuscator 通过一个混淆名称发生器产生a、b、c的毫无意义名称来替换原来正常的名称，增加逆向的难度。<br>Retrace 经过ProGuard处理后的字节码运行的堆栈已经跟没有处理之前的不一样了，除了出现名称上的变化还伴随着逻辑上的变化，程序崩溃后，开发者需要借助Retrace将错误堆栈恢复为没有经过ProGuard处理的样子。<br>…<br>本文则主要介绍了Java优化&amp;混淆工具ProGuard的基本原理、ProGuard的几个模块之间的相互关系与影响、以及增量混淆使用-applymapping遇到部分方法映射错乱的Bug，Bug出现的原因以及修复方案。</p>
</blockquote><br>4.<br><a href="http://mp.weixin.qq.com/s/XiQW3Sbv_jHUYK7aoXy_Rg" target="_blank" rel="external">全栈虚拟机GraalVM初体验</a><br>最近公众号/知乎/infoq系列关于GraalVM 引用/收藏也较多的一篇文章：<br><blockquote><p>js 运行在GraalVM之上的javascript命令行<br>node 跟普通的node一样，区别是运行在GraalVM之上<br>java 跟普通的java一样，区别是运行在GraalVM之上<br>lli 运行在GraalVM之上的llvm字节码执行器，C和C++代码会编译成llvm字节码，然后通过它来运行<br>native-image 预编译程序文件生成快速二进制文件，用于加速启动程序<br>gu 其它的语言像Python、Ruby和R的支持都是通过gu进行安装的</p>
</blockquote><br>5.<br><a href="https://www.zhihu.com/question/21734569/answer/32903623" target="_blank" rel="external">真空里有什么</a><br>一个不明觉厉的回答，事实上，要理解有些困难，传统物理真空就是没有任何物质的空间状态，但是这里我们要理解的真空并不是传统的定义。<br>一种很民科的解释是，现代科学无法自圆其说，尤其在实验和量子论共同推波助澜下，于是创造了答案里的概念。<br>可以搜一搜 赛先生 一篇普及真空里有什么的文章。<br>另一个有趣的问题<br>自然数之和为什么等于-1/12<br><a href="https://www.zhihu.com/question/22506418" target="_blank" rel="external">https://www.zhihu.com/question/22506418</a><br>6.<br><a href="https://yq.aliyun.com/articles/59497" target="_blank" rel="external">高性能数据库连接池的内幕</a><br>值得一看，一个数据库连接池需要考虑哪些基本问题，也包含几大知名连接池的简单对比，就不详细贴了。<br>7.<br>同6，这里推荐一个很好的实现，Springboot 2默认的连接池，HikariCP，这篇文章有更详细的对比<br>很鸡血的技术文章，也很有趣，不说了，<a href="http://blog.didispace.com/Springboot-2-0-HikariCP-default-reason/" target="_blank" rel="external">去感受下作者浓浓的技术激情吧：</a><br><blockquote><p>HiKariCP是数据库连接池的一个后起之秀，号称性能最好，可以完美地PK掉其他连接池，是一个高性能的JDBC连接池，基于BoneCP做了不少的改进和优化。其作者还有另外一个开源作品——高性能的JSON解析器HikariJSON。<br>它，超快，快到连Spring Boot 2都宣布支持了。<br>代码体积更是少的可怜，130kb</p>
</blockquote><br>8.<br><a href="http://highscalability.com/blog/2018/4/27/stuff-the-internet-says-on-scalability-for-april-27th-2018.html" target="_blank" rel="external">http://highscalability.com/blog/2018/4/27/stuff-the-internet-says-on-scalability-for-april-27th-2018.html</a><br><blockquote><p>@kwchang: ‘The internet went from a democratizing free space to having power very centralized; crypto decentralization is a reaction to that’ - @starkness #Angels #cryptointro<br>Lynn Langit: To me, containers are the new VMs. All this frenzy about containers, and more specifically container management systems — look, somebody has to manage the things. I want to pay the cloud providers to do it so I don’t have to.<br>@kellabyte: Many-core servers are a huge problem. We have no idea how to write software to actually use the hardware properly. For example, in Go, there’s no IO library that can go faster than 10GbE.<br>Markus Winand: Don’t say relational database when referring to SQL databases. SQL is really more than just relational.<br>Catalin Cimpanu: A loud sound emitted by a fire suppression system has destroyed the hard drives of a Swedish data center, downing Nasdaq operations across Northern Europe.<br>@brendangregg: context switching &amp; CPU cache invalidations are both CPU utilization. I’d look for single-threaded/single-CPU bottlenecks first, then off-CPU analysis.</p>
</blockquote><br>9.<br><a href="http://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/" target="_blank" rel="external">http://blog.pragmaticengineer.com/distributed-architecture-concepts-i-have-learned-while-building-payments-systems/</a><br>Uber工程师的一篇文章：<br><blockquote><p>SLA<br>Horizontal vs vertical scaling<br>Consistency<br>Data Durability<br>Message Persistence and Durability<br>Idempotency<br>Sharding and Quorum<br>The Actor Model<br>Reactive Architecture<br>Closing</p>
</blockquote><br>上述几点可考虑纳入设计考量点，不多评论了，作者自己总结：<br><blockquote><p>This write-up has been strictly focused on the planning and architecting of these systems. There is a whole lot of things to be said about building, deploying and migrating between high-load systems as well as operating them reliably. But all those topics are other posts.</p>
</blockquote><br>10.<br>关于ES shard分配/路由，看完这一篇就够了<br><a href="https://blog.csdn.net/iceman1952/article/details/79957290" target="_blank" rel="external">https://blog.csdn.net/iceman1952/article/details/79957290</a><br>这是一篇译文，原文（Every shard deserves a home）于2016-11-11发布在elastic官方博客，可以保存方便即时查阅。<br>11.<br><a href="http://hbasefly.com/2018/05/02/timeseries-database-7/" target="_blank" rel="external">http://hbasefly.com/2018/05/02/timeseries-database-7/</a><br>任何一个数据库系统内核关注的重点无非：数据在内存中如何存储、在文件中如何存储、索引结构如何存储、数据写入流程以及数据读取流程。关于InfluxDB存储内核，笔者在之前的文章中已经比较全面的介绍了数据的文件存储格式、倒排索引存储实现以及数据写入流程，本篇文章重点介绍InfluxDB中时序数据的读取流程<br>12.<br><a href="https://www.elastic.co/blog/composite-aggregations-elasticsearch-pizza-delivery-metrics" target="_blank" rel="external">https://www.elastic.co/blog/composite-aggregations-elasticsearch-pizza-delivery-metrics</a><br>Composite aggregations are a powerful new feature in Elasticsearch 6.1.  To show the full power of the feature, we’ll walk through creating an analytics service for Sliceline, a fictional pizza delivery company.<br>Composite aggregations allow us to:<br>Quickly paginate through aggregation results<br>Build new indices from aggregation results<br>Develop APIs backed by Elasticsearch aggregations with consistent response times for large result sets<br>13.<br>Turning a MacBook into a Touchscreen with $1 of Hardware<br><a href="https://www.anishathalye.com/2018/04/03/macbook-touchscreen/" target="_blank" rel="external">https://www.anishathalye.com/2018/04/03/macbook-touchscreen/</a><br>只需1美元，作者在自己的MacBook的摄像头前巧妙的加装了一面小镜子，反射到摄像头，捕捉手指对屏幕的触控，并使用视觉识别，将摄像头拍摄的画面转换为触控反馈。<br>见过很多实现触摸的办法，外接镜面，外接ipad，airbar，本文介绍方法可以说，不仅便宜，而且非常的hack了。<br>不过不知道触摸效果怎样。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/dengxing1234/article/details/77965536&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;CTR预估中的贝叶斯平滑方法（一）&lt;/a&gt;&lt;br&gt;学习了：&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;广告形式：互联网广告可以分为以下三种：&lt;br&gt;1）展示广告（display ad）&lt;br&gt;2）搜索广告（sponsored search ad）&lt;br&gt;3）上下文广告（contextual ad）&lt;br&gt;竞价模式：对于在线广告，主要有以下几种竞价模式：&lt;br&gt;1）pay-per-impression（按展示付费）：广告商按照广告被展示的次数付费，这是一种最普遍的竞价模型。缺点在于没有考虑投放广告的效果。&lt;br&gt;2）pay-per-action（按行为付费）：只有在广告产生了销售或者类似的一些转化时，广告商才付费。缺点在于追踪用户的交易行为相对比较困难。&lt;br&gt;3）pay-per-click（按用户点击付费）：根据用户是否会点击广告来付费。这时候就需要对广告的点击率（CTR）进行精确的预估。&lt;br&gt;遇到的困难：&lt;br&gt;由于数据的稀疏性，对广告进行CTR预估是比较具有挑战性的，预估出来的CTR的可靠性不高，且具有较大的方差。主要有以下两类场景：&lt;br&gt;1）当广告的展示次数较少的时候，对其直接进行CTR的统计计算会导致一个偏高的结果。比如某个广告只展示了1次，被点击了1次，则纯粹的统计CTR=1.0，这显然是过分高估了。&lt;br&gt;2）当广告的展示次数很大，但点击次数很少或几乎没有的时候，对其直接进行CTR的统计计算会导致一个偏低的结果。比如某个广告没有被点击过，则纯粹的统计CTR=0.0，这显然是过分低估了。&lt;/p&gt;
&lt;/blockquote&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0513</title>
    <link href="http://thomaslau.github.io/2018/05/13/2018-05-13-many_links_0513/"/>
    <id>http://thomaslau.github.io/2018/05/13/2018-05-13-many_links_0513/</id>
    <published>2018-05-13T01:45:07.000Z</published>
    <updated>2018-05-14T16:40:35.671Z</updated>
    
    <content type="html"><![CDATA[<p>1.<br>论喝鸡汤，还是要认准大品牌。</p>
<p>超市里买鸡蛋还要看价格质量产地挑选，何况是鸡汤文？</p>
<p>记得曾经看过有人分享“苔花如米小，也学牡丹开”，初看时，还是很感动的，有种壁立千仞，迎风招展的味道。</p>
<p>说不出哪里的好，但又感觉哪里不对。</p>
<p>偶尔看到一句话，醒悟。</p>
<p>“一花一世界”</p>
<p><i>我这里拷贝一段话： “恒河沙等之恒河沙。一沙一世界国土中。所有众生。各具一心。则其心有若干种。如来以清净五眼。皆尽见而知之”。<i></i></i></p>
<p>是了，这里对比下，看出佛家的见识，几千年积累下来的，静坐卧行都在思禅思出来的见识。</p>
<p>前者有些小家子气，或许在一个年轻气盛嘴角红润的年龄段会感动肺腑，自信。</p>
<p>然而我更喜欢“一花一世界”，这种早已超越，甚至无须自信的意境，简直是大智慧。</p>
<p>就像一个曾经美国总统肯尼迪的一个故事：</p>
<p>肯尼迪去NASA访问，在洗手间碰到一位清洁工，或许是出于美国总统的义务，肯尼迪鼓舞到“感谢你把房间打扫得这样干净”，然而清洁工回答说：“不，总统先生，我不是在拖地板，我是在帮助我们登月。”<br><a id="more"></a><br>2.<br>早已接受了很多网络词汇，今天想起，为什么曾经会流行“屌丝/黑木耳”等，其实，每个时代有每个时代的词汇，犹如潘驴邓小闲。</p>
<p>其实，这些词汇和 “国民岳父”，“国民老公”，以及很早的“大众情人”反应的人群，没什么区别。</p>
<p>想引用《扎拉图斯特如是说》中一段，但想想，不如“仁者见仁智者见智”来的干脆。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;1.&lt;br&gt;论喝鸡汤，还是要认准大品牌。&lt;/p&gt;
&lt;p&gt;超市里买鸡蛋还要看价格质量产地挑选，何况是鸡汤文？&lt;/p&gt;
&lt;p&gt;记得曾经看过有人分享“苔花如米小，也学牡丹开”，初看时，还是很感动的，有种壁立千仞，迎风招展的味道。&lt;/p&gt;
&lt;p&gt;说不出哪里的好，但又感觉哪里不对。&lt;/p&gt;
&lt;p&gt;偶尔看到一句话，醒悟。&lt;/p&gt;
&lt;p&gt;“一花一世界”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;我这里拷贝一段话： “恒河沙等之恒河沙。一沙一世界国土中。所有众生。各具一心。则其心有若干种。如来以清净五眼。皆尽见而知之”。&lt;i&gt;&lt;/i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;是了，这里对比下，看出佛家的见识，几千年积累下来的，静坐卧行都在思禅思出来的见识。&lt;/p&gt;
&lt;p&gt;前者有些小家子气，或许在一个年轻气盛嘴角红润的年龄段会感动肺腑，自信。&lt;/p&gt;
&lt;p&gt;然而我更喜欢“一花一世界”，这种早已超越，甚至无须自信的意境，简直是大智慧。&lt;/p&gt;
&lt;p&gt;就像一个曾经美国总统肯尼迪的一个故事：&lt;/p&gt;
&lt;p&gt;肯尼迪去NASA访问，在洗手间碰到一位清洁工，或许是出于美国总统的义务，肯尼迪鼓舞到“感谢你把房间打扫得这样干净”，然而清洁工回答说：“不，总统先生，我不是在拖地板，我是在帮助我们登月。”&lt;br&gt;
    
    </summary>
    
    
      <category term="Thoughts" scheme="http://thomaslau.github.io/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Many Links 0509</title>
    <link href="http://thomaslau.github.io/2018/05/09/2018-05-09-many_links/"/>
    <id>http://thomaslau.github.io/2018/05/09/2018-05-09-many_links/</id>
    <published>2018-05-08T17:09:07.000Z</published>
    <updated>2018-05-14T16:50:42.774Z</updated>
    
    <content type="html"><![CDATA[<p>积攒许久链接，于是该用短文方式。改名 many links仿O’Reilly的Four Short Links.<br>1.<br><a href="https://github.com/zz85/kafka-streams-viz" target="_blank" rel="external">Kafka Streams Topology Visualizer</a><br>正如其自述“A tool helps visualizing stream topologies by generating nice looking diagrams from a kafka stream topology descriptions.”<br>如果你苦于向他人解释采用的kafka stream 数据处理逻辑，可以考虑该连接生成可视化图片展示，适合作为架构设计插图。<br>2.<br><a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101" target="_blank" rel="external">The world beyond batch: Streaming 101</a><br>老文章，流式数据处理101，正如文述“A high-level tour of modern data-processing concepts.”值得一看<br>不过文章显然着重是对几个“时间”的理解以及流的粒度探讨：<br>Event time vs. processing time<br>Data processing patterns<br>Bounded data/Unbounded data — batch<br>Fixed windows/Time-agnostic<br>Filtering/Inner-joins/Windowing<br>3.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">使用火焰图展示结果</div><div class="line">1、Flame Graph项目位于GitHub上：https://github.com/brendangregg/FlameGraph</div><div class="line">2、可以用git将其<span class="built_in">clone</span>下来：git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph.git</div><div class="line"></div><div class="line">我们以perf为例，看一下flamegraph的使用方法：</div><div class="line">1、第一步</div><div class="line"><span class="variable">$sudo</span> perf record -e cpu-clock -g -p 28591</div><div class="line">Ctrl+c结束执行后，在当前目录下会生成采样数据perf.data.</div><div class="line">2、第二步</div><div class="line">用perf script工具对perf.data进行解析</div><div class="line">perf script -i perf.data &amp;&gt; perf.unfold</div><div class="line">3、第三步</div><div class="line">将perf.unfold中的符号进行折叠：</div><div class="line"><span class="comment">#./stackcollapse-perf.pl perf.unfold &amp;&gt; perf.folded</span></div><div class="line">4、最后生成svg图：</div><div class="line">./flamegraph.pl perf.folded &gt; perf.svg</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>4.<br><a href="https://mp.weixin.qq.com/s?__biz=MzIwMzg1ODcwMw==&amp;mid=2247487627&amp;;idx=1&amp;sn=34d437a1253bdf61857cf2ac513285ac" target="_blank" rel="external">金丝雀发布、滚动发布、蓝绿发布到底有什么差别？关键点是什么</a><br>杨波大神讲解各自区分，感觉总结还是蛮详细的.<br>摘要：<br><blockquote><p>下面是对发布策略的一些选型建议，供不同阶段公司参考：<br>1)蛮力发布一般是不建议采用的，除非是开发测试环境，用户体验不敏感的非关键应用，或者是创业期什么都缺时候的无奈之举。<br>2)如果暂时还不具备研发较复杂的滚动发布工具和配套智能 LB，则功能开关是一种不错的轻量级发布技术，投入相对较小的成本，可以让研发人员灵活定制发布逻辑。<br>3)金丝雀发布通过少量新版本服务器接收生产流量的方式去验证新版本，可以显著降低风险。金丝雀发布适用于大部分场景，一般成长型公司就可以采用。<br>4)对于达到一定业务体量的公司，考虑到用户体验对业务的关键性，则需要投入研发资源开发支持滚动式发布的工具和配套的智能 LB，实现自动化和零停机的发布。滚动式发布一般和金丝雀发布配合，先发一台金丝雀去验证流量，再按批次增量发布。<br>5)随着轻量级虚拟化（例如容器）的普及，双服务器组发布方式具有更快的发布和回退速度，是值得投入的高级发布技术。蓝绿部署仅适用于双服务器组，滚动式发布既可以在单服务器组上实现，也可以在双服务器组上实现。<br>6)对于涉及关键核心业务的新功能上线，采用 A/B 测试，可以显著降低发布风险，A/B 测试是唯一一种支持针对特定用户组进行生产测试的高级发布技术。当然 A/B 测试的投入不低，建议有一定研发能力的组织采用。<br>7)对于关键核心业务的迁移重构，为确保万无一失，最后的一个大招是影子测试，影子测试对生产流量和用户完全无影响。当然这个大招的投入成本和门槛都高，建议有足够业务体量和研发能力的组织投入。<br>8)上述的各种发布策略并不是非此即彼的，一个公司常常会综合采用多种发布技术作为互补，实现灵活的发布能力。例如主流的发布手段是金丝雀 + 滚动式发布，某些业务线可能根据业务场景需要采用功能开关发布，还有一些业务线则可能采用高级的 A/B 测试发布手段。</p>
</blockquote></p>
<p>附图：<br><img src="/images/blog/yangbo_on_release.png" alt="发布对比图"></p>
<p>5.<br><a href="https://zhuanlan.zhihu.com/p/35295839" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/35295839</a><br>6.<br><a href="http://blog.didispace.com/IntelliJ-IDEA-2018-1正式发布！什么？还能这么玩？/" target="_blank" rel="external">IntelliJ IDEA 2018.1正式发布</a><br>程序猿DD的：IDEA 2018.1 最新版本给我们带来哪些惊喜</p>
<ol>
<li>stream代码自动生成更智能</li>
<li>while循环优化</li>
<li>优化多余的资源关闭操作</li>
<li>字符串数组自动排序</li>
<li>拷贝构造函数完整性提示<br>…</li>
</ol>
<p>7.<br><a href="https://www.oreilly.com/ideas/four-short-links-2-april-2018" target="_blank" rel="external">https://www.oreilly.com/ideas/four-short-links-2-april-2018</a><br><blockquote><p>1，Valve\’s Networking Code – a basic transport layer for games. The features are: connection-oriented protocol (like TCP)…but message-oriented instead of stream-oriented; mix of reliable and unreliable messages; messages can be larger than underlying MTU, the protocol performs fragmentation and reassembly, and retransmission for reliable; bandwidth estimation based on TCP-friendly rate control (RFC 5348); encryption; AES per packet, Ed25519 crypto for key exchange and cert signatures; the details for shared key derivation and per-packet IV are based on Google QUIC; tools for simulating loss and detailed stats measurement.<br>2，gron – grep JSON from the command line.<br>3，The Problem With Voting – I don\’t agree with all of the analysis, but the proposed techniques are interesting. I did like the term \”lazy consensus\” where consensus is assumed to be the default state (i.e., “default to yes”). The underlying theory is that most proposals are not interesting enough to discuss. But if anyone does object, a consensus seeking process begins. (via Daniel Bachhuber)<br>4，pix2code – open source code that generates Android, iOS, and web source code for a UI from just a photo. It\’s not coming for your job any time soon (over 77% of accuracy), but it\’s still a nifty idea. (via Two Minute Papers)</p>
</blockquote></p>
<p>8.<br>看到有些blog页面有很酷的聊天式的组件留言<br><a href="https://cn.wordpress.org/plugins/collectchat/" target="_blank" rel="external">https://cn.wordpress.org/plugins/collectchat/</a><br><a href="http://www.phpwechat.com/" target="_blank" rel="external">http://www.phpwechat.com/</a></p>
<p>9.<br><a href="https://github.com/tomnomnom/gron/" target="_blank" rel="external">https://github.com/tomnomnom/gron/</a><br>命令行解析json，如其自述：<br>Make JSON greppable!<br>gron transforms JSON into discrete assignments to make it easier to grep for what you want and see the absolute ‘path’ to it. It eases the exploration of APIs that return large blobs of JSON but have terrible documentation.</p>
<p>10.<br><a href="https://www.elastic.co/blog/leveraging-elasticsearch-for-a-1000-percent-performance-boost" target="_blank" rel="external">Leveraging Elasticsearch for a 1,000% performance boost</a> 有点意外官博还会有类似文章，不过入门可以看看</p>
<p>11.<br>其实开头讲lamda背后的数学，从哲学的角度，引用数学家戏谑的定义：<br>One of my favorite definitions comes from Dr. Eugenia Cheng who says that Category Theory is the mathematics of mathematics.<br>Over the course of three months, I was fortunate enough to attend three awesome conferences: <a href="">Lambda World</a><a href="http://www.lambda.world/" target="_blank" rel="external">http://www.lambda.world/</a> in October, <a href="https://scala.io/" target="_blank" rel="external">ScalaIO</a> in November, and <a href="https://skillsmatter.com/conferences/8784-scala-exchange-2017" target="_blank" rel="external">Scala eXchange</a> in December<br><a href="https://www.47deg.com/blog/science-behind-functional-programming/" target="_blank" rel="external">https://www.47deg.com/blog/science-behind-functional-programming/</a><br><a href="http://www.lambdadays.org/lambdadays2018" target="_blank" rel="external">http://www.lambdadays.org/lambdadays2018</a><br><a href="http://www.lambdadays.org/static/upload/media/15197229996020philipwadlercategoriesfortheworkinghacker.pdf" target="_blank" rel="external">http://www.lambdadays.org/static/upload/media/15197229996020philipwadlercategoriesfortheworkinghacker.pdf</a><br><a href="https://bartoszmilewski.com/" target="_blank" rel="external">https://bartoszmilewski.com/</a><br><a href="https://danielasfregola.com/" target="_blank" rel="external">https://danielasfregola.com/</a><br><a href="http://homepages.inf.ed.ac.uk/wadler/" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/wadler/</a><br><a href="http://eugeniacheng.com/" target="_blank" rel="external">http://eugeniacheng.com/</a></p>
<p>12.<br>理解 monoid，manad，Applicatives，functor， function<br><a href="http://www.ccs.neu.edu/home/dherman/research/tutorials/monads-for-schemers.txt" target="_blank" rel="external">http://www.ccs.neu.edu/home/dherman/research/tutorials/monads-for-schemers.txt</a><br><a href="http://dev.stephendiehl.com/hask/#monads" target="_blank" rel="external">http://dev.stephendiehl.com/hask/#monads</a><br><a href="https://www.zhihu.com/question/19635359" target="_blank" rel="external">https://www.zhihu.com/question/19635359</a><br><a href="http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html" target="_blank" rel="external">http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html</a><br>很好的几篇文章<br>13.<br><a href="http://www.infoq.com/cn/presentations/the-sre-system-under-the-international-environment-of-alibaba" target="_blank" rel="external">阿里巴巴国际环境下的SRE体系</a><br>14.<br><a href="http://www.infoq.com/cn/presentations/the-practice-of-intelligent-monitoring-and-fault-location-of-xiaojukeji" target="_blank" rel="external">滴滴出行海量数据场景下的智能监控与故障定位实践</a><br>15.<br><a href="https://github.com/ngs-doo/dsl-json" target="_blank" rel="external">DSL-JSON library</a></p>
<p>Fastest JVM (Java/Android/Scala/Kotlin) JSON library with advanced compile-time databinding support. Compatible with DSL Platform.<br>Java JSON library designed for performance. Built for invasive software composition with DSL Platform compiler.</p>
<p>16.<br>Elasticsearch 写入流程简介<br><a href="https://zhuanlan.zhihu.com/p/34875310?group_id=960576335035441152" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/34875310?group_id=960576335035441152</a><br>使用ElasticSearch的44条建议<br><a href="http://mp.weixin.qq.com/s/ER70p1edqkScx_DAMSsuVA" target="_blank" rel="external">http://mp.weixin.qq.com/s/ER70p1edqkScx_DAMSsuVA</a></p>
<p>17.<br>推荐看一看，阿里云分布式NoSQL开发王怀远的分享，不乏详细和深入，非常想大段拷贝粘贴此处。<br>Elasticsearch分布式一致性原理剖析(一)-节点篇<br><a href="https://zhuanlan.zhihu.com/p/34830403" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/34830403</a><br>讨论：ES集群构成,节点发现,Master选举,错误检测,集群扩缩容,与Zookeeper、raft等实现方式的比较<br>Elasticsearch分布式一致性原理剖析(二)-Meta篇<br><a href="https://zhuanlan.zhihu.com/p/35283785" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/35283785</a><br>讨论：Master如何管理集群，Meta组成、存储和恢复，ClusterState的更新流程，如何解决当前的一致性问题<br>Elasticsearch分布式一致性原理剖析(三)-Data篇<br><a href="https://zhuanlan.zhihu.com/p/35285514" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/35285514</a><br>讨论：问题背景，数据写入流程，PacificA算法，SequenceNumber、Checkpoint与故障恢复，ES与PacificA的比较.</p>
<p>18.<br>重新认识BM25相似性算法，看完文章就会理解shard分布如何影响搜索结果了<br>Elasticsearch官博的文章，深入浅出，似乎目前出到第三篇了，不过我第一篇还未看完。<br>In Elasticsearch 5.0, we switched to Okapi BM25 as our default similarity algorithm.<br>那么该算法除了计算相似性之外，如何影响结果得分？你知道吗，es shards的分布也会影响得分结果。<br>Understanding How Shards Affect Scoring<br><a href="https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch" target="_blank" rel="external">https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch</a><br><a href="https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables" target="_blank" rel="external">https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables</a></p>
<p>19.<br>一段一本正经的电影《The Maven》<br><a href="https://manuel.bernhardt.io/2018/04/19/quick-tour-build-tools-scala/" target="_blank" rel="external">https://manuel.bernhardt.io/2018/04/19/quick-tour-build-tools-scala/</a></p>
<p>20.<br>一个性能压测，许多组织在引用的 Kafka 0.10.x 压缩算法的选择<br><a href="http://blog.yaorenjie.com/2017/01/03/Kafka-0-10-Compression-Benchmark/" target="_blank" rel="external">http://blog.yaorenjie.com/2017/01/03/Kafka-0-10-Compression-Benchmark/</a></p>
<p>21.<br><a href="http://kriszhang.com/atomix/" target="_blank" rel="external">分布式一致性框架Atomix学习</a><br>论准确性，分布式一致性算法非Paxos莫属，但种种原因，如复杂到难以理解到大部分实现Paxos算法错误，故许多采用他的改进版本实现，比如Zookeeper、Google Chubby、RAFT等，本文就概览了RAFT的开源实现 Atomix。</p>
<p>22.<br><a href="https://blog.softwaremill.com/synchronous-or-asynchronous-and-why-wrestle-with-wrappers-2c5667eb7acf" target="_blank" rel="external">https://blog.softwaremill.com/synchronous-or-asynchronous-and-why-wrestle-with-wrappers-2c5667eb7acf</a><br>可以说是 java CompletableFuture经典探讨了<br>23.<br><a href="http://www.importnew.com/28653.html" target="_blank" rel="external">敲最少的键，编最多的码</a></p>
<p>24.<br><a href="https://www.kaggle.com/creepykoala/study-of-tree-and-forest-algorithms/notebook" target="_blank" rel="external">https://www.kaggle.com/creepykoala/study-of-tree-and-forest-algorithms/notebook</a></p>
<p>25.<br><a href="http://www.cnblogs.com/kingszelda/p/8886403.html" target="_blank" rel="external">http://www.cnblogs.com/kingszelda/p/8886403.html</a><br><blockquote><p>通过本文分析，可以得知HttpClient默认是有重试机制的，其重试策略是：<br>  1.只有发生IOExecetion时才会发生重试<br>  2.InterruptedIOException、UnknownHostException、ConnectException、SSLException，发生这4中异常不重试<br>  3.get方法可以重试3次，post方法在socket对应的输出流没有被write并flush成功时可以重试3次。<br>  4.读/写超时不进行重试<br>  5.socket传输中被重置或关闭会进行重试<br>  6.以及一些其他的IOException，暂时分析不出来。<br>5.1 我们的业务重试了吗？<br>  对于我们的场景应用中的get与post，可以总结为：<br>只有发生IOExecetion时才会发生重试<br>InterruptedIOException、UnknownHostException、ConnectException、SSLException，发生这4中异常不重试<br>get方法可以重试3次，post方法在socket对应的输出流没有被write并flush成功时可以重试3次。<br>  首先分析下不重试的异常：<br>InterruptedIOException，线程中断异常<br>UnknownHostException，找不到对应host<br>ConnectException，找到了host但是建立连接失败。<br>SSLException，https认证异常<br>  另外，我们还经常会提到两种超时，连接超时与读超时：<br>java.net.SocketTimeoutException: Read timed out<br>java.net.SocketTimeoutException: connect timed out<br>  这两种超时都是SocketTimeoutException，继承自InterruptedIOException，属于上面的第1种线程中断异常，不会进行重试。<br>5.2 哪些场景会进行重试？<br>  对于大多数系统而言，很多交互都是通过post的方式与第三方交互的。<br>  所以，我们需要知道有哪些情况HttpClient给我们进行了默认重试。<br>  我们关心的场景转化为，post请求在输出流进行write与flush的时候，会发生哪些除了InterruptedIOException、UnknownHostException、ConnectException、SSLException以外的IOExecetion。<br>  可能出问题的一步在于HttpClientConnection.flush()的一步，跟进去可以得知其操作的对象是一个SocketOutputStream,而这个类的flush是空实现，所以只需要看wirte方法即可。</p>
</blockquote></p>
<p>26.<br><a href="https://github.com/artix41/awesome-transfer-learning" target="_blank" rel="external">https://github.com/artix41/awesome-transfer-learning</a></p>
<p>27.<br>Java in containers_jdk10<br><a href="https://mjg123.github.io/2018/01/10/Java-in-containers-jdk10.html" target="_blank" rel="external">https://mjg123.github.io/2018/01/10/Java-in-containers-jdk10.html</a></p>
<p>28.<br><a href="https://code.facebook.com/posts/293371094514305/open-sourcing-racerd-fast-static-race-detection-at-scale" target="_blank" rel="external">https://code.facebook.com/posts/293371094514305/open-sourcing-racerd-fast-static-race-detection-at-scale</a></p>
<p>29.<br>Getting FIREd The tech workers who are engineering a mid-30s retirement<br>追求时间自由的工程师<br><a href="https://story.californiasunday.com/tech-retirees" target="_blank" rel="external">https://story.californiasunday.com/tech-retirees</a></p>
<p>30, 电信运营商劫持何时休<br><a href="http://www.52nlp.cn/%E7%94%B5%E4%BF%A1%E8%BF%90%E8%90%A5%E5%95%86%E5%8A%AB%E6%8C%81%E4%BD%95%E6%97%B6%E4%BC%91" target="_blank" rel="external">http://www.52nlp.cn/%E7%94%B5%E4%BF%A1%E8%BF%90%E8%90%A5%E5%95%86%E5%8A%AB%E6%8C%81%E4%BD%95%E6%97%B6%E4%BC%91</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;积攒许久链接，于是该用短文方式。改名 many links仿O’Reilly的Four Short Links.&lt;br&gt;1.&lt;br&gt;&lt;a href=&quot;https://github.com/zz85/kafka-streams-viz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Kafka Streams Topology Visualizer&lt;/a&gt;&lt;br&gt;正如其自述“A tool helps visualizing stream topologies by generating nice looking diagrams from a kafka stream topology descriptions.”&lt;br&gt;如果你苦于向他人解释采用的kafka stream 数据处理逻辑，可以考虑该连接生成可视化图片展示，适合作为架构设计插图。&lt;br&gt;2.&lt;br&gt;&lt;a href=&quot;https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;The world beyond batch: Streaming 101&lt;/a&gt;&lt;br&gt;老文章，流式数据处理101，正如文述“A high-level tour of modern data-processing concepts.”值得一看&lt;br&gt;不过文章显然着重是对几个“时间”的理解以及流的粒度探讨：&lt;br&gt;Event time vs. processing time&lt;br&gt;Data processing patterns&lt;br&gt;Bounded data/Unbounded data — batch&lt;br&gt;Fixed windows/Time-agnostic&lt;br&gt;Filtering/Inner-joins/Windowing&lt;br&gt;3.&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;使用火焰图展示结果&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;1、Flame Graph项目位于GitHub上：https://github.com/brendangregg/FlameGraph&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2、可以用git将其&lt;span class=&quot;built_in&quot;&gt;clone&lt;/span&gt;下来：git &lt;span class=&quot;built_in&quot;&gt;clone&lt;/span&gt; https://github.com/brendangregg/FlameGraph.git&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;我们以perf为例，看一下flamegraph的使用方法：&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;1、第一步&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;variable&quot;&gt;$sudo&lt;/span&gt; perf record -e cpu-clock -g -p 28591&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Ctrl+c结束执行后，在当前目录下会生成采样数据perf.data.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2、第二步&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;用perf script工具对perf.data进行解析&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;perf script -i perf.data &amp;amp;&amp;gt; perf.unfold&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3、第三步&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;将perf.unfold中的符号进行折叠：&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#./stackcollapse-perf.pl perf.unfold &amp;amp;&amp;gt; perf.folded&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4、最后生成svg图：&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;./flamegraph.pl perf.folded &amp;gt; perf.svg&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>风雨一年路</title>
    <link href="http://thomaslau.github.io/2018/05/03/2018-05-03-one_year_summarize/"/>
    <id>http://thomaslau.github.io/2018/05/03/2018-05-03-one_year_summarize/</id>
    <published>2018-05-02T16:09:07.000Z</published>
    <updated>2018-05-08T17:33:14.266Z</updated>
    
    <content type="html"><![CDATA[<p>不知不觉的，一年过去，这一年，家人身体安康，幸事。然而来者不可知也。<br><a id="more"></a><br><img src="/images/blog/201805031.png" alt="shanghai"></p>
<p><img src="/images/blog/201805032.jpg" alt="shanghai"></p>
<p><img src="/images/blog/201805033m.jpg" alt="shanghai"></p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=22242344&auto=1&height=66"></iframe>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知不觉的，一年过去，这一年，家人身体安康，幸事。然而来者不可知也。&lt;br&gt;
    
    </summary>
    
    
      <category term="life" scheme="http://thomaslau.github.io/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>Weekly Reading 180328</title>
    <link href="http://thomaslau.github.io/2018/03/28/2018-03-28-weekly_reading/"/>
    <id>http://thomaslau.github.io/2018/03/28/2018-03-28-weekly_reading/</id>
    <published>2018-03-27T16:09:07.000Z</published>
    <updated>2018-05-08T18:02:56.814Z</updated>
    
    <content type="html"><![CDATA[<p>下面是之前2-3个月积攒的文摘，清空一下，所以有些看起来可能是不够“新鲜”了。</p>
<p>1, Dubbo源代码分析九：优雅停机<br><a href="http://manzhizhen.iteye.com/blog/2404220" target="_blank" rel="external">http://manzhizhen.iteye.com/blog/2404220</a><br>这几天从dubbo-admin有机会看了一点dubbo代码，对上述shutdown方式，有了点体会。<br>可以说2.5.3版本 dubbo和dubbo-admin交互还是有多处bug的，比如可以对比 com.alibaba.dubbo.registry.integration.RegistryProtocol在2.5.3和2.5.8版本的实现（doChangeLocalExport/notify方法）。</p>
<p>3，python根据项目生成requirements.txt<br>查看一些python项目，很多并未采用requirements.txt方式，编译起来耗费时间，今天学到了可以用 pip freeze的方式：</p>
<pre><code>python项目中必须包含一个 requirements.txt 文件，用于记录所有依赖包及其精确的版本号。以便新环境部署。
在虚拟环境中使用pip生成：
(venv) $ pip freeze &gt;requirements.txt
这种方式配合virtualenv 才好使，否则把整个环境中的包都列出来了。
使用 pipreqs
这个工具的好处是可以通过对项目目录的扫描，自动发现使用了那些类库，自动生成依赖清单。
缺点是可能会有些偏差，需要检查并自己调整下。
# pip install pipreqs
# 使用方式也比较简单
pipreqs ./
</code></pre><a id="more"></a>
<p>3, JMX最佳实践与详解<br><a href="http://shift-alt-ctrl.iteye.com/blog/2404103" target="_blank" rel="external">http://shift-alt-ctrl.iteye.com/blog/2404103</a> 文中这里列举下Java已经内置的多个MXBean实现。</p>
<pre><code>1、BufferPoolMXBean：
   有关“direct”、“mapped” buffer的资源信息；如果Application为网络IO系统（比如Netty编程）、或者有大量文件操作，你应该考虑关注此MXBean。
2、ClassLoadingMXBean：
   有关JVM类加载相关的资源信息；如果Application为序列化相关的组件、脚本化集成组件、有较多代理类（包括动态加载，OSGI）等，你应该关注此MXBean。
3、GarbageCollectorMXBean：
   有关JVM GC相关的资源，包括GC时长、GC次数和相关内存状态。
4、MemoryPoolMXBean：
   有关JVM中“内存池”的相关资源信息，可以配合MemoryManagerMXBean一起使用。一个Application中可能有多个“内存池”实例，我们可以通过MemoryManagerMXBean获取内存池的列表，并查看此内存池的存量和GC相关信息。
5、OperatingSystemMXBean：
   有关操作系统的相关资源信息，比如CPU负载等。
6、PlatformManagedObject：
   内部接口，所有的JAVA平台有关的MXBean都扩展此接口，比如上述几个MXBean；通常应用程序不应该实现它。
7、RuntimeMXBean：
   有关runtime的信息，比如VM的参数、版本等。
8、ThreadMXBean：
   有关运行时线程状态的资源信息，比如“CPU高耗线程”、“死锁线程”等，可以帮助我们优化并发操作等。
</code></pre><p>实际很少用到MXBean来做一些metric/hanck技术，像Kafka也内置了一些MXBean，作为系统运行状态的参考，业界也有一些工具可以将这些MXBean打点至如grafana上展示。</p>
<p>4，暴力美学，“星星之火可以燎原”<br>记得，有诗人吟送道，大概类似，“我在春天种下希望的种子，秋天收获希望“的句子，或者类似句子。<br>但是，太祖的“星星之火可以燎原”，只是八个字，显然更有境界。</p>
<p>5， Latency Sensitive Microservices<br><a href="https://www.infoq.com/presentations/microservices-trading-system" target="_blank" rel="external">https://www.infoq.com/presentations/microservices-trading-system</a></p>
<p>6, 分布式数据库中间件TDDL、Amoeba、Cobar、MyCAT架构比较。文章简洁明了<br><a href="https://www.jianshu.com/p/ed54162d720c" target="_blank" rel="external">https://www.jianshu.com/p/ed54162d720c</a></p>
<p>7，Significant Software Development Developments of 2017<br>需要自备梯子。2017年几个重大软件研发事件备忘录，想不到去年发生这么多大事<br><a href="http://marxsoftware.blogspot.com/2017/12/big-news-2017.html" target="_blank" rel="external">http://marxsoftware.blogspot.com/2017/12/big-news-2017.html</a></p>
<p>8,踩坑无数，<a href="https://tech.meituan.com/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E8%AE%BE%E6%83%B3.html" target="_blank" rel="external">美团点评高可用数据库架构演进</a>，好文。<br><a href="https://tech.meituan.com/数据库高可用架构的演进与设想.html" target="_blank" rel="external">https://tech.meituan.com/数据库高可用架构的演进与设想.html</a><br>MMM（Master-Master replication manager for MySQL）-&gt; MHA（MySQL Master High Availability）-&gt; MHA+Zebra (DAL)</p>
<p>9, 如何设计一个DNS<br><a href="http://www.infoq.com/cn/articles/how-to-design-dns" target="_blank" rel="external">http://www.infoq.com/cn/articles/how-to-design-dns</a></p>
<p>10，2017双11核心技术揭秘—阿里数据库进入全网秒级实时监控时代 | 阿里中间件团队博客<br><a href="http://jm.taobao.org/2017/12/27/20172703/" target="_blank" rel="external">http://jm.taobao.org/2017/12/27/20172703/</a></p>
<p>11，Linux IO磁盘篇整理小记 - 朱小厮的博客 - CSDN博客<br>一篇磁盘性能简单分析的文章，可以收藏以备查询<br><a href="http://blog.csdn.net/u013256816/article/details/78945085" target="_blank" rel="external">http://blog.csdn.net/u013256816/article/details/78945085</a></p>
<p>12，Peter Norvig，大牛<br><a href="http://norvig.com/" target="_blank" rel="external">http://norvig.com/</a></p>
<p>13， Docker 公司已死 ！ | IT瘾<br><a href="http://itindex.net/detail/57847-docker-%E5%85%AC%E5%8F%B8" target="_blank" rel="external">http://itindex.net/detail/57847-docker-%E5%85%AC%E5%8F%B8</a><br>mac安装kubernetes并运行echoserver - 简书<br><a href="https://www.jianshu.com/p/a42eeb66a19c" target="_blank" rel="external">https://www.jianshu.com/p/a42eeb66a19c</a><br>很早之前看的，好像后来有文章反对，不过值得参考下。</p>
<p>14, uber 技术总结<br><a href="https://eng.uber.com/2017-highlights/" target="_blank" rel="external">https://eng.uber.com/2017-highlights/</a><br><a href="https://eng.uber.com/2017-open-source/" target="_blank" rel="external">https://eng.uber.com/2017-open-source/</a></p>
<p>15， Kafka#3：分布式设计 - 程序园<br><a href="http://www.voidcn.com/article/p-risahvbp-ez.html" target="_blank" rel="external">http://www.voidcn.com/article/p-risahvbp-ez.html</a></p>
<p>16，百亿访问量的监控平台如何炼成？ – 运维派<br><a href="http://www.yunweipai.com/archives/24462.html" target="_blank" rel="external">http://www.yunweipai.com/archives/24462.html</a></p>
<p>17，美团点评联盟广告场景化定向排序机制<br><a href="https://tech.meituan.com/targeting_agentscore.html" target="_blank" rel="external">https://tech.meituan.com/targeting_agentscore.html</a></p>
<p>18，加密数字货币和传统分布式系统共识机制 | 温国兵的随想录<br><a href="https://dbarobin.com/2017/12/27/blockchain-consensus/" target="_blank" rel="external">https://dbarobin.com/2017/12/27/blockchain-consensus/</a></p>
<p>19，Kafka 高性能吞吐揭秘 - 友盟博客 - SegmentFault<br><a href="https://segmentfault.com/a/1190000003985468" target="_blank" rel="external">https://segmentfault.com/a/1190000003985468</a><br>关于Kafka日志留存策略的讨论 - huxihx - 博客园<br><a href="http://www.cnblogs.com/huxi2b/p/8042099.html" target="_blank" rel="external">http://www.cnblogs.com/huxi2b/p/8042099.html</a></p>
<p>20 JVMTI 参考<br><a href="http://blog.caoxudong.info/blog/2017/12/07/jvmti_reference" target="_blank" rel="external">http://blog.caoxudong.info/blog/2017/12/07/jvmti_reference</a></p>
<p>21,<br>如果你使用kafka new-consumer API 即：__consumer_offset存储你的消费信息，当</p>
<p>kafka-client设置props.put(“auto.commit.interval.ms”, “3000”) </p>
<p>则，对于server端，不论client是否消费新的数据，都是每6秒提交offset，server都写入consumeroffset，server不会做去重判断的，也就是每个三秒都会提交offset到__consumer_offset这个topic存储数据</p>
<p>22，Intel meltdown &amp; spectre的几篇文章以及对spark/elasticsearch的影响，好消息。<br><a href="http://www.infoq.com/cn/news/2018/01/meltdown-spectre" target="_blank" rel="external">http://www.infoq.com/cn/news/2018/01/meltdown-spectre</a><br><a href="https://databricks.com/blog/2018/01/13/meltdown-and-spectre-performance-impact-on-big-data-workloads-in-the-cloud.html" target="_blank" rel="external">https://databricks.com/blog/2018/01/13/meltdown-and-spectre-performance-impact-on-big-data-workloads-in-the-cloud.html</a><br><a href="https://www.elastic.co/blog/performance-impact-of-meltdown-on-elasticsearch" target="_blank" rel="external">https://www.elastic.co/blog/performance-impact-of-meltdown-on-elasticsearch</a></p>
<p>23，新晋Java Champions，包括一位JVM（SUN/OpenJDK）专家，曾在infoq 网站/现场 听过，网站上视频，很值得一听。<br><a href="https://www.infoq.com/news/2018/01/JavaChampions2017" target="_blank" rel="external">https://www.infoq.com/news/2018/01/JavaChampions2017</a></p>
<p>24，简介听起来不错<br>经历400多天打磨，HSF的架构和性能有哪些新突破？<br><a href="http://jm.taobao.org/2018/01/16/post180116/" target="_blank" rel="external">http://jm.taobao.org/2018/01/16/post180116/</a></p>
<p>25，JSON-B和Yasson详解，新的JAVA EE API官方规范，以及Eclipse的实现 Yasson<br><a href="http://blog.csdn.net/chszs/article/details/79059116" target="_blank" rel="external">http://blog.csdn.net/chszs/article/details/79059116</a><br>转眼间，似乎已经定下来改名叫 Jakarta EE了</p>
<p>26，ElasticSearch如何支持深度分页<br><a href="http://arganzheng.life/deep-pagination-in-elasticsearch.html" target="_blank" rel="external">http://arganzheng.life/deep-pagination-in-elasticsearch.html</a></p>
<p>学习了，对于超过默认10000条的除了使用ES的 Scan and scroll API之外，文章还提供了官方的 Search After 机制，不过要在ES 5.0版本后。</p>
<pre><code>search_after使用方式上跟scroll很像，但是相对于scroll它是无状态的(stateless)，没有search context开销；
而且它是每次请求都实时计算的，所以也没有一致性问题（相反，有索引变化的话，每次排序顺序会变化呢）。
但是比起from+size方式，还是有同样的问题没法解决：就是只能顺序的翻页，不能随意跳页
</code></pre><p>27，Elasticsearch Performance Tuning Practice at eBay<br><a href="https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/" target="_blank" rel="external">https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/</a><br>具体不列举了，infoq还有翻译的，这里简单总结下：</p>
<pre><code>From our experience, if the index is smaller than 1G, it’s fine to set the shard number to 1. For most scenarios, we can leave the shard number as the default value 5, but if shard size exceeds 30GB, we should increase the shard number to split the index into more shards. The shard number cannot be changed once an index is created, but we can create a new index and use the reindex API to move data.
Increase refresh interval. As we mentioned in the tune indexing performance section, Elasticsearch creates new segment every time a refresh happens. Increasing the refresh interval would help reduce the segment count and reduce the IO cost for search. And, the cache would be invalid once a refresh happens and data is changed. Increasing the refresh interval can make Elasticsearch utilize cache more efficiently.
Use filter context instead of query context if possible. A query clause is used to answer “How well does this document match this clause?” A filter clause is used to answer “Does this document match this clause?” Elasticsearch only needs to answer “Yes” or “No.” It does not need to calculate a relevancy score for a filter clause, and the filter results can be cached. See Query and filter context for details. 
Node query cache. Node query cache only caches queries that are being used in a filter context. Unlike a query clause, a filter clause is a &quot;Yes&quot; or &quot;No&quot; question. Elasticsearch used a bit set mechanism to cache filter results, so that later queries with the same filter will be accelerated. Note that only segments that hold more than 10,000 documents (or 3% of the total documents, whichever is larger) will enable a query cache. For more details, see All about caching.
We can use the following request to check whether a node query cache is having an effect.
GET index_name/_stats?filter_path=indices.**.query_cache
Sort by _doc if you don’t care about the order in which documents are returned
</code></pre><p>28，最近打算kafka官方提个建议：consumeroffset设置为30个。<br>kafka默认consumeroffset设置为50个partition，50=5<em>5</em>2，这对于部署kafka机器除非5的倍数，否则不会均匀分布的，而对于kafka的partition分配策略 hash(group_id)%50，可能效果也是不理想的。而30=2<em>3</em>5，可选择性就多点，但hash(group_id)%30还要具体数据验证。</p>
<p>29, Spring Boot 2.0 New Features: Infrastructure Changes<br><a href="https://springuni.com/spring-boot-2-infrastructure-changes/" target="_blank" rel="external">https://springuni.com/spring-boot-2-infrastructure-changes/</a><br>值得了解下</p>
<p>30,<br>“Go out there and have huge dreams, then show up to work the next morning and relentlessly incrementally achieve them.”<br>~ from the book, How Google Works</p>
<p>31，<br><a href="https://www.elastic.co/blog/categorizing-non-english-log-messages-in-machine-learning-for-elasticsearch" target="_blank" rel="external">https://www.elastic.co/blog/categorizing-non-english-log-messages-in-machine-learning-for-elasticsearch</a></p>
<p>32，有趣，我已经想象到教主九泉下有知，会不会来一句“意不意外惊不惊喜?”<br><a href="https://www.theverge.com/2018/2/16/17020246/apple-park-headquarters-employees-injury-glass-doors-design" target="_blank" rel="external">https://www.theverge.com/2018/2/16/17020246/apple-park-headquarters-employees-injury-glass-doors-design</a></p>
<p>33，值得参考下<br><a href="https://rcoh.me/posts/cache-oblivious-datastructures/" target="_blank" rel="external">https://rcoh.me/posts/cache-oblivious-datastructures/</a></p>
<p>34，基于日志trace的智能故障定位系统 - 百度搜索运维团队技术负责人<br><a href="http://www.infoq.com/cn/presentations/intelligent-fault-location-system-based-on-log-trace" target="_blank" rel="external">http://www.infoq.com/cn/presentations/intelligent-fault-location-system-based-on-log-trace</a></p>
<p>35，语言设计，值得参考<br><a href="https://www.iravid.com/posts/slick-and-shapeless.html" target="_blank" rel="external">https://www.iravid.com/posts/slick-and-shapeless.html</a></p>
<p>36， Java版WAF实现<br><a href="https://www.yangguo.info/2018/01/11/Gateway/" target="_blank" rel="external">https://www.yangguo.info/2018/01/11/Gateway/</a><br>API网关的开源解决方案那么多，为什么我们却还要选择自研？<br><a href="https://github.com/chengdedeng/waf" target="_blank" rel="external">https://github.com/chengdedeng/waf</a></p>
<ul>
<li><a href="https://www.yangguo.info/2017/11/13/HttpProxy研发心得/" target="_blank" rel="external">https://www.yangguo.info/2017/11/13/HttpProxy研发心得/</a></li>
<li><a href="https://www.yangguo.info/2017/06/06/Java版WAF实现/" target="_blank" rel="external">https://www.yangguo.info/2017/06/06/Java版WAF实现/</a></li>
</ul>
<p>37，<br><a href="http://blog.llvm.org/2018/03/clang-is-now-used-to-build-chrome-for.html" target="_blank" rel="external">http://blog.llvm.org/2018/03/clang-is-now-used-to-build-chrome-for.html</a></p>
<p>38，批判的看待，而不是听风就是雨<br><a href="http://www.flax.co.uk/blog/2018/03/02/no-elastic-x-pack-not-going-open-source-according-elastic/" target="_blank" rel="external">http://www.flax.co.uk/blog/2018/03/02/no-elastic-x-pack-not-going-open-source-according-elastic/</a></p>
<p>39，杂文：<br>美团外卖原生广告推荐实践<br><a href="http://www.infoq.com/cn/presentations/the-recommended-practice-of-meituan-takeout-ad" target="_blank" rel="external">http://www.infoq.com/cn/presentations/the-recommended-practice-of-meituan-takeout-ad</a><br>阿里巴巴监控之路<br><a href="http://www.infoq.com/cn/presentations/the-road-of-monitoring-in-alibaba" target="_blank" rel="external">http://www.infoq.com/cn/presentations/the-road-of-monitoring-in-alibaba</a><br>阿里异地多活与同城双活的架构演进<br><a href="http://www.infoq.com/cn/presentations/the-structure-of-alibaba-double-living-in-the-same-city" target="_blank" rel="external">http://www.infoq.com/cn/presentations/the-structure-of-alibaba-double-living-in-the-same-city</a></p>
<p>40， Steve Jobs: Everything in this world… was created by people no smarter than you.<br><a href="http://muratbuffalo.blogspot.com/2018/02/think-before-you-code.html" target="_blank" rel="external">http://muratbuffalo.blogspot.com/2018/02/think-before-you-code.html</a></p>
<p>41，<br><a href="https://fosdem.org/2018/schedule/event/unix_evolution/" target="_blank" rel="external">https://fosdem.org/2018/schedule/event/unix_evolution/</a></p>
<p>42，kibana几个有趣使用<br><a href="https://logz.io/blog/kibana-hacks/" target="_blank" rel="external">https://logz.io/blog/kibana-hacks/</a></p>
<p>43， 快速定位生产故障问题-JVM进程CPU占用率高于100%<br><a href="http://blog.csdn.net/flysqrlboy/article/details/79314521" target="_blank" rel="external">http://blog.csdn.net/flysqrlboy/article/details/79314521</a><br>实施要点：<br>top -Hbp ‘pid’ 定位问题线程<br>jstack ‘pid’ | grep ‘thread_id’ 找出问题代码</p>
<p>44，<a href="http://blog.codefx.org/java/application-class-data-sharing/" target="_blank" rel="external">http://blog.codefx.org/java/application-class-data-sharing/</a></p>
<p>45，<br><a href="http://colobu.com/2018/03/12/Concurrency-Utilities-Enhancements-in-Java-8-Java-9/" target="_blank" rel="external">http://colobu.com/2018/03/12/Concurrency-Utilities-Enhancements-in-Java-8-Java-9/</a></p>
<p>46，来自stackoverflow的调查<br><a href="https://insights.stackoverflow.com/survey/2018/" target="_blank" rel="external">https://insights.stackoverflow.com/survey/2018/</a></p>
<p>47，Kubernetes的抗脆弱性<br><a href="http://www.infoq.com/cn/articles/antifragility-in-kubernetes" target="_blank" rel="external">http://www.infoq.com/cn/articles/antifragility-in-kubernetes</a></p>
<p>48，Java10来了，来看看它一同发布的全新JIT编译器<br><a href="https://mp.weixin.qq.com/s/fNDBX6pxw2Xa5afZpVaBEg" target="_blank" rel="external">https://mp.weixin.qq.com/s/fNDBX6pxw2Xa5afZpVaBEg</a><br><em>与interpreter，GC等JVM的其他子系统相比，JIT compiler并不依赖于诸如直接内存访问的底层语言特性。它可以看成一个输入Java bytecode输出二进制码的黑盒，其实现方式取决于开发者对开发效率，可维护性等的要求。Graal是一个以Java为主要编程语言，面向Java bytecode的编译器。与用C++实现的C1及C2相比，它的模块化更加明显，也更加容易维护。Graal既可以作为动态编译器，在运行时编译热点方法；亦可以作为静态编译器，实现AOT编译。在Java 10中，Graal作为试验性JIT compiler一同发布（JEP 317）。这篇文章将介绍Graal在动态编译上的应用。有关静态编译，可查阅JEP 295或Substrate VM</em></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;下面是之前2-3个月积攒的文摘，清空一下，所以有些看起来可能是不够“新鲜”了。&lt;/p&gt;
&lt;p&gt;1, Dubbo源代码分析九：优雅停机&lt;br&gt;&lt;a href=&quot;http://manzhizhen.iteye.com/blog/2404220&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://manzhizhen.iteye.com/blog/2404220&lt;/a&gt;&lt;br&gt;这几天从dubbo-admin有机会看了一点dubbo代码，对上述shutdown方式，有了点体会。&lt;br&gt;可以说2.5.3版本 dubbo和dubbo-admin交互还是有多处bug的，比如可以对比 com.alibaba.dubbo.registry.integration.RegistryProtocol在2.5.3和2.5.8版本的实现（doChangeLocalExport/notify方法）。&lt;/p&gt;
&lt;p&gt;3，python根据项目生成requirements.txt&lt;br&gt;查看一些python项目，很多并未采用requirements.txt方式，编译起来耗费时间，今天学到了可以用 pip freeze的方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python项目中必须包含一个 requirements.txt 文件，用于记录所有依赖包及其精确的版本号。以便新环境部署。
在虚拟环境中使用pip生成：
(venv) $ pip freeze &amp;gt;requirements.txt
这种方式配合virtualenv 才好使，否则把整个环境中的包都列出来了。
使用 pipreqs
这个工具的好处是可以通过对项目目录的扫描，自动发现使用了那些类库，自动生成依赖清单。
缺点是可能会有些偏差，需要检查并自己调整下。
# pip install pipreqs
# 使用方式也比较简单
pipreqs ./
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch几点体会</title>
    <link href="http://thomaslau.github.io/2018/03/25/2018-03-25-pearls_of_Elasticsearch/"/>
    <id>http://thomaslau.github.io/2018/03/25/2018-03-25-pearls_of_Elasticsearch/</id>
    <published>2018-03-25T07:12:07.000Z</published>
    <updated>2018-03-27T16:12:25.799Z</updated>
    
    <content type="html"><![CDATA[<p>很久没有写博客了，感觉快要生疏，今天简单写一点，记录发现的几个问题。</p>
<p>1，<br><strong> 在集群增加一个节点后，不要只看是否启动成功，一定要验证下是否加入集群 </strong><br>考虑到32G内存的官方推荐，很多人会选择同一物理机部署两个以上节点（&gt;128G内存），分配两个端口。比如9300/19300.<br>比如集群在 10.135.30.12:9200/9300 是一个master节点，之后拷贝配置新增如下一个节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cluster.name: elasts</div><div class="line">node.master: false</div><div class="line">node.data: true</div><div class="line">transport.tcp.port: 19300</div><div class="line">discovery.zen.ping.unicast.hosts: ["10.135.30.12"]</div></pre></td></tr></table></figure>
<p>会发现该节点启动成功，但是<strong><em>没有加入到elasts这个cluster里</em></strong>。 设置为debug级别再启动，不仔细看是发现不了问题的。<br><a id="more"></a><br>官方是这么解释：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Unicast discovery provides the following settings with the discovery.zen.ping.unicast.hosts:</div><div class="line">Either an array setting or a comma delimited setting. Each value should be <span class="keyword">in</span> the form of host:port or host (</div><div class="line"><span class="built_in">where</span> port defaults to the setting transport.profiles.default.port falling back to transport.tcp.port <span class="keyword">if</span> not <span class="built_in">set</span>). </div><div class="line">Note that IPv6 hosts must be bracketed. Defaults to 127.0.0.1, [::1]</div></pre></td></tr></table></figure>
<p>简单来讲就是上述节点默认使用配置里的 transport.tcp.port 这个端口做discover，而不是 9300.<br>所以建议配置 discovery.zen.ping.unicast.hosts 的时候一定配置端口（使用2.x之后的单播即可）</p>
<p>那么原文 “ort defaults to the setting transport.profiles.default.port falling back to transport.tcp.port if not set”是什么意思？<br>5.2.2代码为例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div></pre></td><td class="code"><pre><div class="line">UnicastZenPing.java</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnicastZenPing</span> <span class="keyword">extends</span> <span class="title">AbstractComponent</span> <span class="keyword">implements</span> <span class="title">ZenPing</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String ACTION_NAME = <span class="string">"internal:discovery/zen/unicast"</span>;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Setting&lt;List&lt;String&gt;&gt; DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING =</div><div class="line">        Setting.listSetting(<span class="string">"discovery.zen.ping.unicast.hosts"</span>, emptyList(), Function.identity(),</div><div class="line">            Property.NodeScope);</div><div class="line">    ...</div><div class="line">        <span class="keyword">if</span> (DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING.exists(settings)) &#123;</div><div class="line">            configuredHosts = DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING.get(settings);</div><div class="line">            <span class="comment">// we only limit to 1 addresses, makes no sense to ping 100 ports</span></div><div class="line">            limitPortCounts = LIMIT_FOREIGN_PORTS_COUNT;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">// if unicast hosts are not specified, fill with simple defaults on the local machine</span></div><div class="line">            configuredHosts = transportService.getLocalAddresses();</div><div class="line">            limitPortCounts = LIMIT_LOCAL_PORTS_COUNT;</div><div class="line">        &#125;</div><div class="line">    ...</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;DiscoveryNode&gt; <span class="title">resolveHostsLists</span><span class="params">(</span></span></div><div class="line">        ...</div><div class="line">        <span class="keyword">final</span> List&lt;String&gt; hosts,</div><div class="line">        ...) <span class="keyword">throws</span> InterruptedException &#123;</div><div class="line">        ...</div><div class="line">        <span class="comment">// create tasks to submit to the executor service; we will wait up to resolveTimeout for these tasks to complete</span></div><div class="line">        <span class="keyword">final</span> List&lt;Callable&lt;TransportAddress[]&gt;&gt; callables =</div><div class="line">            hosts.stream()</div><div class="line">                .map(hn -&gt; (Callable&lt;TransportAddress[]&gt;) () -&gt; transportService.addressesFromString(hn, limitPortCounts))</div><div class="line">                .collect(Collectors.toList());</div><div class="line">        <span class="keyword">final</span> List&lt;Future&lt;TransportAddress[]&gt;&gt; futures =</div><div class="line">            executorService.invokeAll(callables, resolveTimeout.nanos(), TimeUnit.NANOSECONDS);</div><div class="line">        <span class="keyword">final</span> List&lt;DiscoveryNode&gt; discoveryNodes = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        <span class="comment">// ExecutorService#invokeAll guarantees that the futures are returned in the iteration order of the tasks so we can associate the</span></div><div class="line">        <span class="comment">// hostname with the corresponding task by iterating together</span></div><div class="line">        <span class="keyword">final</span> Iterator&lt;String&gt; it = hosts.iterator();</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">final</span> Future&lt;TransportAddress[]&gt; future : futures) &#123;</div><div class="line">            <span class="keyword">final</span> String hostname = it.next();</div><div class="line">            <span class="keyword">if</span> (!future.isCancelled()) &#123;</div><div class="line">                <span class="keyword">assert</span> future.isDone();</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    <span class="keyword">final</span> TransportAddress[] addresses = future.get();</div><div class="line">                    logger.trace(<span class="string">"resolved host [&#123;&#125;] to &#123;&#125;"</span>, hostname, addresses);</div><div class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> addressId = <span class="number">0</span>; addressId &lt; addresses.length; addressId++) &#123;</div><div class="line">                        discoveryNodes.add(</div><div class="line">                            <span class="keyword">new</span> DiscoveryNode(</div><div class="line">                                nodeId_prefix + hostname + <span class="string">"_"</span> + addressId + <span class="string">"#"</span>,</div><div class="line">                                addresses[addressId],</div><div class="line">                                emptyMap(),</div><div class="line">                                emptySet(),</div><div class="line">                                Version.CURRENT.minimumCompatibilityVersion()));</div><div class="line">                    &#125;</div><div class="line">                &#125; <span class="keyword">catch</span> (<span class="keyword">final</span> ExecutionException e) &#123;</div><div class="line">                    <span class="keyword">assert</span> e.getCause() != <span class="keyword">null</span>;</div><div class="line">                    <span class="keyword">final</span> String message = <span class="string">"failed to resolve host ["</span> + hostname + <span class="string">"]"</span>;</div><div class="line">                    logger.warn(message, e.getCause());</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                logger.warn(<span class="string">"timed out after [&#123;&#125;] resolving host [&#123;&#125;]"</span>, resolveTimeout, hostname);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> discoveryNodes;</div><div class="line">    &#125;</div><div class="line">...</div><div class="line"></div><div class="line">TransportService.java</div><div class="line">    <span class="keyword">public</span> TransportAddress[] addressesFromString(String address, <span class="keyword">int</span> perAddressLimit) <span class="keyword">throws</span> UnknownHostException &#123;</div><div class="line">        <span class="keyword">return</span> transport.addressesFromString(address, perAddressLimit);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">TcpTransport.java</div><div class="line">    <span class="keyword">public</span> TransportAddress[] addressesFromString(String address, <span class="keyword">int</span> perAddressLimit) <span class="keyword">throws</span> UnknownHostException &#123;</div><div class="line">        <span class="keyword">return</span> parse(address, settings.get(<span class="string">"transport.profiles.default.port"</span>, TransportSettings.PORT.get(settings)), perAddressLimit);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern BRACKET_PATTERN = Pattern.compile(<span class="string">"^\\[(.*:.*)\\](?::([\\d\\-]*))?$"</span>);</div><div class="line">    <span class="comment">/** parse a hostname+port range spec into its equivalent addresses */</span></div><div class="line">    <span class="keyword">static</span> TransportAddress[] parse(String hostPortString, String defaultPortRange, <span class="keyword">int</span> perAddressLimit) <span class="keyword">throws</span> UnknownHostException &#123;</div><div class="line">        Objects.requireNonNull(hostPortString);</div><div class="line">        String host;</div><div class="line">        String portString = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (hostPortString.startsWith(<span class="string">"["</span>)) &#123;</div><div class="line">            <span class="comment">// Parse a bracketed host, typically an IPv6 literal.</span></div><div class="line">            Matcher matcher = BRACKET_PATTERN.matcher(hostPortString);</div><div class="line">            <span class="keyword">if</span> (!matcher.matches()) &#123;</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid bracketed host/port range: "</span> + hostPortString);</div><div class="line">            &#125;</div><div class="line">            host = matcher.group(<span class="number">1</span>);</div><div class="line">            portString = matcher.group(<span class="number">2</span>);  <span class="comment">// could be null</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">int</span> colonPos = hostPortString.indexOf(<span class="string">':'</span>);</div><div class="line">            <span class="keyword">if</span> (colonPos &gt;= <span class="number">0</span> &amp;&amp; hostPortString.indexOf(<span class="string">':'</span>, colonPos + <span class="number">1</span>) == -<span class="number">1</span>) &#123;</div><div class="line">                <span class="comment">// Exactly 1 colon.  Split into host:port.</span></div><div class="line">                host = hostPortString.substring(<span class="number">0</span>, colonPos);</div><div class="line">                portString = hostPortString.substring(colonPos + <span class="number">1</span>);</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="comment">// 0 or 2+ colons.  Bare hostname or IPv6 literal.</span></div><div class="line">                host = hostPortString;</div><div class="line">                <span class="comment">// 2+ colons and not bracketed: exception</span></div><div class="line">                <span class="keyword">if</span> (colonPos &gt;= <span class="number">0</span>) &#123;</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"IPv6 addresses must be bracketed: "</span> + hostPortString);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// if port isn't specified, fill with the default</span></div><div class="line">        <span class="keyword">if</span> (portString == <span class="keyword">null</span> || portString.isEmpty()) &#123;</div><div class="line">            portString = defaultPortRange;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// generate address for each port in the range</span></div><div class="line">        Set&lt;InetAddress&gt; addresses = <span class="keyword">new</span> HashSet&lt;&gt;(Arrays.asList(InetAddress.getAllByName(host)));</div><div class="line">        List&lt;TransportAddress&gt; transportAddresses = <span class="keyword">new</span> ArrayList&lt;&gt;();</div><div class="line">        <span class="keyword">int</span>[] ports = <span class="keyword">new</span> PortsRange(portString).ports();</div><div class="line">        <span class="keyword">int</span> limit = Math.min(ports.length, perAddressLimit);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; limit; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (InetAddress address : addresses) &#123;</div><div class="line">                transportAddresses.add(<span class="keyword">new</span> InetSocketTransportAddress(address, ports[i]));</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> transportAddresses.toArray(<span class="keyword">new</span> TransportAddress[transportAddresses.size()]);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">TransportSettings.java</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Setting&lt;String&gt; PORT =</div><div class="line">        <span class="keyword">new</span> Setting&lt;&gt;(<span class="string">"transport.tcp.port"</span>, <span class="string">"9300-9400"</span>, Function.identity(), Property.NodeScope);</div></pre></td></tr></table></figure>
<p>也可看到，es这块debug的日志有所欠缺，如果把UnicastZenPing这个操作时候的实际的端口log下来，方便快速定位问题。</p>
<p>2,<br><strong> ES索引性能的优化 </strong><br>之前文章已推荐<a href="https://www.paypal-engineering.com/2016/08/10/powering-transactions-search-with-elastic-learnings-from-the-field/" target="_blank" rel="external">Ebay一篇文章</a>总结过将Elasticsearch优化到极致的技巧，这里就不再重复，来看点不一样的：<br>不过，这里也不会讨论，诸如 优化索引的 index.refresh_interval，优化segment的index.merge，甚至磁盘的索引均衡（扩分片/reroute）/replia数减少。更不会讨论诸如索引字段的分词/exclude/_all字段禁用/优化_source字段等。</p>
<p>来看下面三个参数：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">index.translog.durability: async</div><div class="line">index.translog.sync_interval: 90s</div><div class="line">index.translog.flush_threshold_size: 1024mb</div></pre></td></tr></table></figure>
<p>主要是 index.translog.durability，看文档 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.2/index-modules-translog.html" target="_blank" rel="external">Translog</a></p>
<p> <strong><em>Translog settingsedit</em></strong><br>The data in the transaction log is only persisted to disk when the translog is fsynced and committed. In the event of hardware failure, any data written since the previous translog commit will be lost.</p>
<p>By default, Elasticsearch fsyncs and commits the translog every 5 seconds if index.translog.durability is set to async or if set to request (default) at the end of every index, delete, update, or bulk request. In fact, Elasticsearch will only report success of an index, delete, update, or bulk request to the client after the transaction log has been successfully fsynced and committed on the primary and on every allocated replica.</p>
<p>The following dynamically updatable per-index settings control the behaviour of the transaction log:</p>
<ul>
<li><strong> index.translog.sync_interval </strong><br>How often the translog is fsynced to disk and committed, regardless of write operations. Defaults to 5s. Values less than 100ms are not allowed.</li>
<li><strong> index.translog.durability </strong><br>Whether or not to fsync and commit the translog after every index, delete, update, or bulk request. This setting accepts the following parameters:<ul>
<li>request<br>(default) fsync and commit after every request. In the event of hardware failure, all acknowledged writes will already have been committed to disk.</li>
<li>async<br>fsync and commit in the background every sync_interval. In the event of hardware failure, all acknowledged writes since the last automatic commit will be discarded.</li>
</ul>
</li>
</ul>
<p>即，为了保证数据不丢失，es translog默认的额持久化策略是 每次请求都会flush。这里暂不代码展开分析，如果应用允许少量的几率丢失数据，那么这里可以设置为异步，并且增加translog大小周期性的flush。</p>
<p>需要注意的是，index.translog.durability 并不是一个dynamic property，即，如果修改索引的该配置，可以删除重建，不过也可以先close该索引，更新setting后再open打开索引。</p>
<p>对于大量请求（每天索引数据量10+亿条，每日索引数据500+GB，1备份，保留5天数据，32CPU，128g内存，机械硬盘，四台实体机），上面的配置优化还是很明显的。</p>
<p>3，<br><strong> 这里简单列个5.x相比2.x的改变 </strong>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">curl -XPOST &apos;localhost:9200/_cluster/reroute&apos; -d &apos;&#123; </div><div class="line">  &quot;commands&quot; : [ </div><div class="line">      &#123; &quot;allocate_empty_primary&quot; : </div><div class="line">          &#123; &quot;index&quot; : &quot;INDEX&quot;, &quot;shard&quot; : 0, &quot;node&quot;: &quot;&lt;NODE_NAME&gt;&quot;&#125;</div><div class="line">      &#125;</div><div class="line">    ]</div><div class="line">&#125;&apos;</div><div class="line">curl -XPOST  localhost:9200/_cluster/reroute -d &apos;&#123;</div><div class="line">  &quot;commands&quot; : [ </div><div class="line">    &#123;</div><div class="line">        &quot;move&quot; :&#123;</div><div class="line">            &quot;index&quot; : &quot;za-2018.03.23&quot;, &quot;shard&quot; : 0, &quot;from_node&quot; : &quot;node-20.50&quot;, &quot;to_node&quot; : &quot;node-20.39&quot;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  ]</div><div class="line">&#125;&apos;</div></pre></td></tr></table></figure>
<ul>
<li>上述node均可用名字代替，而不必查询id</li>
<li>reroute的commands，相比细化了下，如 allocate_empty_primary，这在集群状态为red，分片数据确实并且不可恢复的时候还是有用的。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很久没有写博客了，感觉快要生疏，今天简单写一点，记录发现的几个问题。&lt;/p&gt;
&lt;p&gt;1，&lt;br&gt;&lt;strong&gt; 在集群增加一个节点后，不要只看是否启动成功，一定要验证下是否加入集群 &lt;/strong&gt;&lt;br&gt;考虑到32G内存的官方推荐，很多人会选择同一物理机部署两个以上节点（&amp;gt;128G内存），分配两个端口。比如9300/19300.&lt;br&gt;比如集群在 10.135.30.12:9200/9300 是一个master节点，之后拷贝配置新增如下一个节点：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;cluster.name: elasts&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;node.master: false&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;node.data: true&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;transport.tcp.port: 19300&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;discovery.zen.ping.unicast.hosts: [&quot;10.135.30.12&quot;]&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;会发现该节点启动成功，但是&lt;strong&gt;&lt;em&gt;没有加入到elasts这个cluster里&lt;/em&gt;&lt;/strong&gt;。 设置为debug级别再启动，不仔细看是发现不了问题的。&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="Elasticsearch" scheme="http://thomaslau.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Weekly Reading 170910</title>
    <link href="http://thomaslau.github.io/2017/09/10/2017-09-10-weekly_reading/"/>
    <id>http://thomaslau.github.io/2017/09/10/2017-09-10-weekly_reading/</id>
    <published>2017-09-10T15:29:07.000Z</published>
    <updated>2017-09-10T17:23:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>很久没有更新了，最近比较忙。<br>今天刚好是第33个教师节，怀念因吾逃课多次而气哭却依旧对我苦口婆心谆谆教诲到毕业的高二高三班主任。可惜花无重开日，人无再少年。当爱因斯坦霍金这些天才的头脑思考想象时间之箭逆向的时候，凡夫俗子只能哀叹滚滚长江东逝水，但将白发唱黄鸡？<br>所以，第一个链接附上：邓晓芒的<a href="http://mp.weixin.qq.com/s?timestamp=1505063081&amp;src=3&amp;ver=1&amp;signature=Kp1HJzKUfeq7wGa63hXCrde4tCeSDbO9Wdak7eBQqoGKE1BA*cI01Bjlx-Lsw9UNXfO8eyDCdX5iNjtKIjSizZijosJN*8kUz0weBrkuCygcRhN70SlFPgJDD6i5Z*X9rJdeH7xTToGslS7MIUfDpBKNiLgTLPhr2WTLWKwZOQ4=" target="_blank" rel="external">邓晓芒：我的恩师修斋先生</a><br><a id="more"></a><br>-1，<br>不知道何时知道邓晓芒，但是却是自他和刘小枫一段论战时候开始关注。之前因为刘小枫主编很多非常好的系列著作而青睐，至邓后，方知大师。<br>下面只附上链接，懒癌复发，提笔忘词，故草草了之了。</p>
<p>0，<br><a href="https://stackoverflow.com/questions/3222895/what-is-the-issue-with-the-runtime-discovery-algorithm-of-apache-commons-logging" target="_blank" rel="external">https://stackoverflow.com/questions/3222895/what-is-the-issue-with-the-runtime-discovery-algorithm-of-apache-commons-logging</a></p>
<p>1，You’re not a compiler!<br><a href="https://blog.frankel.ch/you-not-compiler/#gsc.tab=0" target="_blank" rel="external">https://blog.frankel.ch/you-not-compiler/#gsc.tab=0</a><br>2，<br>spring cloud 学习(8) - sleuth &amp; zipkin 调用链跟踪<br><a href="http://www.cnblogs.com/yjmyzz/p/spring-cloud-with-zipkin.html" target="_blank" rel="external">http://www.cnblogs.com/yjmyzz/p/spring-cloud-with-zipkin.html</a><br>3，<br>Dubbo源代码分析八：再说Provider线程池被EXHAUSTED<br><a href="http://manzhizhen.iteye.com/blog/2391177" target="_blank" rel="external">http://manzhizhen.iteye.com/blog/2391177</a><br>有没有道理<br>所以，为了减少在Provider线程池打满时整个系统雪崩的风险，建议将Dispatcher设置成message：<br>4，linux性能分析好文章，消除对load average的误解，以及更好的linux system kernel metrics<br><a href="http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html" target="_blank" rel="external">http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html</a></p>
<p>5，在推特上看到一条有感：考古的囚徒困境，在古遗址发现一个泥块做的骰子，科学计算年龄分析是4000年前。<br>但是，考古学家并不能证明，这是不是哪一个19世纪的盗墓贼开的玩笑，用4000年前当时的泥块磨出的骰子？</p>
<p>6，阿里巴巴机器学习系列课程<br><a href="http://blog.csdn.net/buptgshengod/article/details/77675909" target="_blank" rel="external">http://blog.csdn.net/buptgshengod/article/details/77675909</a></p>
<p>7，如何免费的让网站启用HTTPS<br><a href="https://coolshell.cn/articles/18094.html" target="_blank" rel="external">https://coolshell.cn/articles/18094.html</a></p>
<p>8，美团点评数据平台融合实践<br><a href="https://tech.meituan.com/dataplat_coalesce.html" target="_blank" rel="external">https://tech.meituan.com/dataplat_coalesce.html</a></p>
<p>9，基于Raft分布式一致性协议实现的局限及其对数据库的风险，阿里正祥的文章。<br><a href="https://mp.weixin.qq.com/s?timestamp=1504098595&amp;src=3&amp;ver=1&amp;signature=YJFPuCcWbtbBbQQQmWiVQufHWAzMjFcJrJajcocSrJiPCd4*sXT9Jit16XzUn08bqqDalpHZy0NgvUCPGFzpK*437zVSD4PQxeM3QWOkREdkVSetPmeGewCl160Ub48X664mwmWvmefVbKbbire4XXW8LhdYi*2jOUK4rcwCwoE=" target="_blank" rel="external">https://mp.weixin.qq.com/s?timestamp=1504098595&amp;src=3&amp;ver=1&amp;signature=YJFPuCcWbtbBbQQQmWiVQufHWAzMjFcJrJajcocSrJiPCd4*sXT9Jit16XzUn08bqqDalpHZy0NgvUCPGFzpK*437zVSD4PQxeM3QWOkREdkVSetPmeGewCl160Ub48X664mwmWvmefVbKbbire4XXW8LhdYi*2jOUK4rcwCwoE=</a><br>如果上面微信公号 OceanBase过期的话，试一试这个： <a href="http://blog.sina.com.cn/s/blog_3fc85e260102wr0c.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_3fc85e260102wr0c.html</a></p>
<p>10， 城市级故障自动无损容灾的“新常态”方案<br><a href="https://mp.weixin.qq.com/s/qyFbqCQr-iAY1A8VfQuYKA" target="_blank" rel="external">https://mp.weixin.qq.com/s/qyFbqCQr-iAY1A8VfQuYKA</a></p>
<p>12，蒙特利尔大学开放MILA 2017夏季深度学习与强化学习课程视频（附完整PPT）<br><a href="https://zhuanlan.zhihu.com/p/28922147?group_id=886303000086335488" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/28922147?group_id=886303000086335488</a></p>
<p>13.Java performance techniques The cost of HotSpot runtime optimizations by Ionut Balosin<br><a href="https://www.youtube.com/watch?v=NURE0ZPBVPA" target="_blank" rel="external">https://www.youtube.com/watch?v=NURE0ZPBVPA</a></p>
<p>14.BILL JOY FINDS THE JESUS BATTERY<br><a href="https://www.wired.com/story/bill-joy-finds-the-jesus-battery/" target="_blank" rel="external">https://www.wired.com/story/bill-joy-finds-the-jesus-battery/</a><br><a href="https://twitter.com/kevin2kelly/status/898706414394163200" target="_blank" rel="external">https://twitter.com/kevin2kelly/status/898706414394163200</a></p>
<p>15，<br><a href="http://www.layer9.org/2017/08/paper-3-re-architecting-datacenter.html" target="_blank" rel="external">http://www.layer9.org/2017/08/paper-3-re-architecting-datacenter.html</a></p>
<p>16，A history of branch prediction from 1500000 BC to 1995<br><a href="https://danluu.com/branch-prediction/" target="_blank" rel="external">https://danluu.com/branch-prediction/</a><br>分支预测，大家可以搜索java分支预测优化的技术</p>
<p>17.<br><a href="http://muratbuffalo.blogspot.com/2017/08/retrospective-lightweight-distributed.html" target="_blank" rel="external">http://muratbuffalo.blogspot.com/2017/08/retrospective-lightweight-distributed.html</a></p>
<p>18，<a href="http://blog.didispace.com/why-spring-boot-tran/" target="_blank" rel="external">http://blog.didispace.com/why-spring-boot-tran/</a><br>19，！！！！！！<br><a href="https://www.kancloud.cn/kancloud/mysql-design-reference/47425" target="_blank" rel="external">https://www.kancloud.cn/kancloud/mysql-design-reference/47425</a><br>20，<br><a href="http://highscalability.com/blog/2017/9/1/stuff-the-internet-says-on-scalability-for-september-1st-201.html" target="_blank" rel="external">http://highscalability.com/blog/2017/9/1/stuff-the-internet-says-on-scalability-for-september-1st-201.html</a></p>
<p>The Amish use a canary approach when choosing which technologies to adopt. Kevin Kelley, “Wired” Founding Executive Editor &amp; “The Inevitable” author/futurist, explains how on This Week In Startups. The Amish aren’t luddites, they’re slow followers, selective curators who admit technologies into their portfolio based on deeply held core principles. Individuals don’t choose which technologies to adopt, the community decides based on how it impacts the family and community. They ask: will this technology allow me to spend more time with my family? Will this technology increase the strength of our community? Cell phones are allowed, smart phones are not. Cars were rejected because they let people travel far away from family and community. A horse &amp; buggy keeps everyone within a 15 mile radius. Eating meals together as a family is important, so the Amish create backyard businesses. Using a CNC milling machine is OK because it keeps the family together. Solar panels and chain saws are also OK. They have Amish computers, which are computers without an internet connection. And the computer is used in the office only, not at home. How do they pick which technologies to use? They try them. One or two early adopter families use a technology and they are observed. If it’s deemed the technology hurts the family or the community, then the technology is voted off the island.</p>
<p>21，<br><a href="https://github.com/Developer-Y/cs-video-courses" target="_blank" rel="external">https://github.com/Developer-Y/cs-video-courses</a><br><a href="http://muratbuffalo.blogspot.com/2017/08/retrospective-lightweight-distributed.html" target="_blank" rel="external">http://muratbuffalo.blogspot.com/2017/08/retrospective-lightweight-distributed.html</a></p>
<p>22。 <a href="https://www.ziwenxie.site/2017/01/02/unix-network-programming-asynchronous/" target="_blank" rel="external">https://www.ziwenxie.site/2017/01/02/unix-network-programming-asynchronous/</a><br>阻塞式IO(默认)，非阻塞式IO(nonblock)，IO复用(select/poll/epoll)，signal driven IO(信号驱动IO)都是属于同步型IO，因为在第二个阶段: 从内核空间拷贝数据到程序空间的时候不能干别的事。只有异步I/O模型(AIO)才是符合我们上面对于异步型IO操作的含义，在1.wait for data，2.copy data from kernel to user，这两个等待/接收数据的时间段内进程可以干其他的事情，只要等着被通知就可以了。<br>select/poll/epoll<br>即使现在的各个Linux版本普遍引入了copy on write和线程，但实际上进程/线程之间的切换依然还是一笔很大的开销，这个时候我们可以考虑使用上面提到到多路IO复用，回顾一下我们上面提到的多路IO复用模型的基本原理：一个进程可以监视多个文件描述符，一旦某个文件描述符就绪（读/写准备就绪），能够信号通知程序进行相应的读写操作。下面我们就来简单的看一下多路IO复用的三种方式。<br>select<br>int select (int maxfdp1, fd_set <em>readset, fd_set </em>writeset, fd_set <em>exceptset,<br>            const struct timeval </em>timeout);<br>如上面的方法声明所示, select监听三类描述符: readset(读), writeset(写), exceptset(异常), 我们编程的时候可以制定这三个参数监听对应的文件描述符。正如前面提到的,select调用后进程会阻塞, 当select返回后，可以通过遍历fdset，来找到就绪的描述符。<br>select优点在于它的跨平台，但是也有显著的缺点单个进程能够监视的文件描述符的数量存在最大限制，默认设置为1024/2048，虽然设置可以超过这一限制，但是这样也可能会造成效率的降低。而且select扫描的时候也是采用的轮循，算法复杂度为O(n)，这在fdset很多时效率会较低。<br>下面总结一下select的三个缺点，在下面我们来看epool是如何解决这些缺点的：<br>每次调用select，都需要将fd_set从用户态拷贝到内核态。<br>每次调用select都要在内核遍历所有传递过来的fd_set看哪些描述已经准备就绪。<br>select有1024的容量限制。<br>poll<br>int poll (struct pollfd <em>fdarray, unsigned long nfds, int timeout);<br>poll和select并没有太大的区别，但是它是基于链表实现的所以并没有最大数量限制，它将用户传入的数据拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次的遍历。算法复杂度也是O(n)。<br>epoll<br>int epoll_create(int size);<br>int epoll_ctl(int epfd, int op, int fd, struct epoll_event </em>event);<br>int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);<br>select和poll都只提供了一个函数。而epoll提供了三个函数: epoll_create是创建一个epoll句柄, epoll_ctl是注册要监听的事件类型, epoll_wait则是等待事件的产生。与select相比，epoll几乎没有描述符限制(cat /proc/sys/fs/file-max可查看)。它采用一个文件描述符管理多个描述符，将用户的文件描述符的事件存放到kernel的一个事件表中，这样在程序空间和内核空间的只要做一次拷贝。它去掉了遍历文件描述符这一步骤，采用更加先进的回调(callback)机制，算法复杂度降到了O(1)。p.s: 虽然表面看起来epoll非常好，但是对于连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，因为epoll是建立在大量的函数回调的基础之上。<br>下面我们来总结一下epoll是如何解决select的三个缺点的：<br>在epoll_ctl每次注册事件到epoll句柄的时候，会将fd拷贝到内核中，保证了每个fd在整个过程中只会拷贝一次。<br>对于第二缺点，epool_ctl为每个fd指定一个回调函数，当设备就绪，就会调用这个回调函数，而这个回调函数会把准备就绪的fd加入一个就绪链表，而不用像select那样去重新遍历一次看有哪些准备就绪的文件描述符。<br>对于第三个缺点，我们上面已经提及到了，epoll几乎没有容量限制，可以通过cat /proc/sys/fs/file-max来查看。</p>
<p>23.<br><a href="http://lovestblog.cn/blog/2015/05/12/direct-buffer/" target="_blank" rel="external">http://lovestblog.cn/blog/2015/05/12/direct-buffer/</a></p>
<p>24。<br><a href="https://shipilev.net/jvm-anatomy-park/2-transparent-huge-pages/" target="_blank" rel="external">https://shipilev.net/jvm-anatomy-park/2-transparent-huge-pages/</a></p>
<p>25.<br>Translation Lookaside Buffer：TLB<br><a href="https://zh.wikipedia.org/wiki/%E8%BD%89%E8%AD%AF%E5%BE%8C%E5%82%99%E7%B7%A9%E8%A1%9D%E5%8D%80" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%E8%BD%89%E8%AD%AF%E5%BE%8C%E5%82%99%E7%B7%A9%E8%A1%9D%E5%8D%80</a><br><a href="https://baike.baidu.com/item/TLB" target="_blank" rel="external">https://baike.baidu.com/item/TLB</a></p>
<p>26.<br><a href="http://blog.csdn.net/dm_vincent/article/details/76735888" target="_blank" rel="external">http://blog.csdn.net/dm_vincent/article/details/76735888</a><br>本文分析了Spring Boot启动时的关键步骤，主要包含以下两个方面：<br>SpringApplication实例的构建过程<br>其中主要涉及到了初始化器(Initializer)以及监听器(Listener)这两大概念，它们都通过META-INF/spring.factories完成定义。<br>SpringApplication实例run方法的执行过程<br>其中主要有一个SpringApplicationRunListeners的概念，它作为Spring Boot容器初始化时各阶段事件的中转器，将事件派发给感兴趣的Listeners(在SpringApplication实例的构建过程中得到的)。这些阶段性事件将容器的初始化过程给构造起来，提供了比较强大的可扩展性。<br>如果从可扩展性的角度出发，应用开发者可以在Spring Boot容器的启动阶段，扩展哪些内容呢：<br>初始化器(Initializer)<br>监听器(Listener)<br>容器刷新后置Runners(ApplicationRunner或者CommandLineRunner接口的实现类)<br>启动期间在Console打印Banner的具体实现类</p>
<p>27.<br>MySQL索引<br><a href="https://www.kancloud.cn/kancloud/mysql-design-reference/47425" target="_blank" rel="external">https://www.kancloud.cn/kancloud/mysql-design-reference/47425</a><br>28.<br><a href="https://www.confluent.io/blog/publishing-apache-kafka-new-york-times/?utm_source=wanqu.co&amp;utm_campaign=Wanqu+Daily&amp;utm_medium=website" target="_blank" rel="external">https://www.confluent.io/blog/publishing-apache-kafka-new-york-times/?utm_source=wanqu.co&amp;utm_campaign=Wanqu+Daily&amp;utm_medium=website</a><br>29.<br><a href="http://www.baeldung.com/java-stream-indices" target="_blank" rel="external">http://www.baeldung.com/java-stream-indices</a><br>30.<br>Spring Boot实现自动配置的基础<br><a href="http://blog.csdn.net/dm_vincent/article/details/77435515" target="_blank" rel="external">http://blog.csdn.net/dm_vincent/article/details/77435515</a><br>31.<br>百度开源项目推荐<br><a href="http://itindex.net/detail/57429-%E7%99%BE%E5%BA%A6-%E5%BC%80%E6%BA%90-%E9%A1%B9%E7%9B%AE" target="_blank" rel="external">http://itindex.net/detail/57429-%E7%99%BE%E5%BA%A6-%E5%BC%80%E6%BA%90-%E9%A1%B9%E7%9B%AE</a><br>32.<br>Lucene’s near-real-time segment index replication<br><a href="http://blog.mikemccandless.com/2017/09/lucenes-near-real-time-segment-index.html" target="_blank" rel="external">http://blog.mikemccandless.com/2017/09/lucenes-near-real-time-segment-index.html</a><br>33.<br>不使用synchronized和lock，如何实现一个线程安全的单例？<br><a href="http://www.hollischuang.com/archives/1860" target="_blank" rel="external">http://www.hollischuang.com/archives/1860</a><br>34.<br>reddit搜索简史<br><a href="https://redditblog.com/2017/09/07/the-search-for-better-search-at-reddit/" target="_blank" rel="external">https://redditblog.com/2017/09/07/the-search-for-better-search-at-reddit/</a><br>35.<br>分布式学习资源list Resources for Getting Started with Distributed Systems<br><a href="https://caitiem.com/2017/09/07/getting-started-with-distributed-systems/" target="_blank" rel="external">https://caitiem.com/2017/09/07/getting-started-with-distributed-systems/</a><br>36.<br><a href="http://www.cakesolutions.net/teamblogs/scalameta-tut-cache" target="_blank" rel="external">http://www.cakesolutions.net/teamblogs/scalameta-tut-cache</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很久没有更新了，最近比较忙。&lt;br&gt;今天刚好是第33个教师节，怀念因吾逃课多次而气哭却依旧对我苦口婆心谆谆教诲到毕业的高二高三班主任。可惜花无重开日，人无再少年。当爱因斯坦霍金这些天才的头脑思考想象时间之箭逆向的时候，凡夫俗子只能哀叹滚滚长江东逝水，但将白发唱黄鸡？&lt;br&gt;所以，第一个链接附上：邓晓芒的&lt;a href=&quot;http://mp.weixin.qq.com/s?timestamp=1505063081&amp;amp;src=3&amp;amp;ver=1&amp;amp;signature=Kp1HJzKUfeq7wGa63hXCrde4tCeSDbO9Wdak7eBQqoGKE1BA*cI01Bjlx-Lsw9UNXfO8eyDCdX5iNjtKIjSizZijosJN*8kUz0weBrkuCygcRhN70SlFPgJDD6i5Z*X9rJdeH7xTToGslS7MIUfDpBKNiLgTLPhr2WTLWKwZOQ4=&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;邓晓芒：我的恩师修斋先生&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
  <entry>
    <title>Weekly Reading 170825</title>
    <link href="http://thomaslau.github.io/2017/08/26/2017-08-26-weekly_reading/"/>
    <id>http://thomaslau.github.io/2017/08/26/2017-08-26-weekly_reading/</id>
    <published>2017-08-26T02:29:07.000Z</published>
    <updated>2017-08-26T02:25:23.000Z</updated>
    
    <content type="html"><![CDATA[<ol>
<li><a href="http://gao-xianglong.iteye.com/blog/2390697?from=thomaslau.github.io" target="_blank" rel="external">优雅停机</a><br>dubbo原生是支持优雅停机的，其实也就是采用JDK的ShudownHook来实现，当然仅限kill -15 PID。这里也顺带说一下dubbo优雅停机的原理，如下所示：<br>服务提供方<br>· 停止时，先标记为不接收新请求，新请求过来时直接报错，让客户端重试其它机器。<br>· 然后，检测线程池中的线程是否正在运行，如果有，等待所有线程执行完成，除非超时，则强制关闭。<br>服务消费方<br>· 停止时，不再发起新的调用请求，所有新的调用在客户端即报错。<br>· 然后，检测有没有请求的响应还没有返回，等待响应返回，除非超时，则强制关闭。<a id="more"></a></li>
<li><a href="https://blog.risingstack.com/designing-microservices-architecture-for-failure?from=thomaslau.github.io" target="_blank" rel="external">Designing a Microservices Architecture for Failure</a>，这是译文版的<a href="https://segmentfault.com/a/1190000010799109?from=thomaslau.github.io" target="_blank" rel="external">设计一个容错的微服务架构</a>， infoq好像有类似，这里再推荐下。<br>注意点: Graceful Service Degradation, Change management, Health-check and Load Balancing, Self-healing, Failover Caching, Retry Logic, Rate Limiters and Load Shedders, Fail Fast and Independently, Bulkheads, Circuit Breakers, Testing for Failures.<br>Key Takeways<br>1) Dynamic environments and distributed systems - like microservices - lead to a higher chance of failures.<br>2) Services should fail separately, achieve graceful degradation to improve user experience.<br>3) 70% of the outages are caused by changes, reverting code is not a bad thing.<br>Fail fast and independently. Teams have no control over their service dependencies.<br>4) Architectural patterns and techniques like caching, bulkheads, circuit breakers and rate-limiters help to build reliable microservices.</li>
<li>grep递归查询<br>习惯用 find . -type f -exec grep -l ‘alvin’ {} \; 的可以试一试grep -rl alvin .<br>递归查询多个目录：grep -ril alvin /home/cato /htdocs/zenf</li>
<li><a href="https://peadarcoyle.wordpress.com/2017/08/16/why-zalandos-tech-radar-sucks-as-a-stack/" target="_blank" rel="external">WHY  ZALANDO’S  TECH  RADAR  SUCKS  AS  A  STACK
</a></li>
<li><a href="https://www.zhihu.com/question/30508773/answer/205831957" target="_blank" rel="external">反欺诈(Fraud Detection)中所用到的机器学习模型有哪些？</a>, 有点乱，不过有点参考意义。其实答案里提到的解法，看上去不论可视化或者异常检测对比，从描述来看，这都很依赖人工验证。</li>
<li><a href="http://blog.csdn.net/chdhust/article/details/77507453" target="_blank" rel="external">基于SEDA的异步框架设计与实现</a>, SEDA技术是个存在了很久的概念。<br>目前，面对并发环境，主流互联网服务器编程模型有两种：多线程模型以及事件驱动模型。但是这两个模型都不足以解决这个问题。我们来首先看一下这两种编程模型。</li>
<li>飒然Hang的<a href="http://www.rowkey.me/blog/2017/08/24/arch/?from=thomaslau.github.io" target="_blank" rel="external">谈谈架构</a></li>
<li>API设计，DDD，REST，CQRS<br><a href="http://blog.didispace.com/use-ddd-design-rest-api/" target="_blank" rel="external">http://blog.didispace.com/use-ddd-design-rest-api/</a><br><a href="http://blog.didispace.com/spring-boot-starter-swagger-1.2.0/" target="_blank" rel="external">http://blog.didispace.com/spring-boot-starter-swagger-1.2.0/</a></li>
<li><a href="http://blog.didispace.com/spring-cloud-starter-dalston-6-1/" target="_blank" rel="external">Spring Cloud构建微服务架构：服务网关</a>, 算是初步了解下Spring Cloud.<br>文中因为权限带来状态，所以将权限认证放在API GateWay，其实这样gateway也会有状态的。<br>而且，权限，面向具体服务还是整个系统通用，比如内网限制／ip限制这里通用、用户只能更新自己数据这类business logic。</li>
<li>最近看了Brew的时隔十多年的两篇CAP和Lynch的2002年的CAP证明，发觉他们其实描述的不是同一个东西，至少，他们对一种理论的约束条件定义不同，甚至对Patition tolerance定义也是不同。比如CAP在十多年里就引起许多争论，大多是对A／P理解不同，Brew两篇文章都没有清晰定义。<br>CAP存在的原因，其实就是工程师和理论派的差异的地方了，一个注重理解和实用，哪怕是靠记忆记住，即便是不完全的真理，另一个侧重证明。比如有专家发文为NoSQL没有实现一致性遗憾，比如有自称是CA的，但是后来经验证被认为是CA特性，但是极致情况下表现AP特性。<br>可以看看<a href="https://aphyr.com/tags/jepsen" target="_blank" rel="external">aphyr的jepson</a>系列，实用Jepson验证一些分布式系统。<br>后面会再写篇关于CAP的文章，先立个flag，天气原因，今天就先写到这里了。</li>
<li><p>冯·诺伊曼关于拟合大象的比喻。<br><a href="https://www.quora.com/What-exactly-does-John-Von-Neumanns-quote-with-four-parameters-I-can-fit-an-elephant-with-five-I-can-make-him-wiggle-his-trunk-mean" target="_blank" rel="external">What exactly does John Von Neumann’s quote “with four parameters I can fit an elephant, with five I can make him wiggle his trunk” mean?</a>, <a href="https://www.johndcook.com/blog/2011/06/21/how-to-fit-an-elephant/" target="_blank" rel="external">How-to-fit-an-elephant/</a><br>以下摘录网上：<br>1953年春天，26岁即是康奈尔大学教授的戴森和自己的学生利用赝标介子理论计算了介子与质子的散射截面，得到了与费米的实验观测值十分相符的结果。喜不自禁的长途跋涉去告之费米，费米扫了一眼说，“有两种方式做理论物理学的计算。一种是我喜欢的，就是要对你正在计算的过程拥有一个清晰的物理图象。另一种是得到精确而且自洽的数学形式体系。这两者都是你的计算不具备的。”<br>戴森当时有点懵了，但他还是斗胆问费米，为什么他在计算中所采用的赝标介子理论算不上是自洽的数学形式体系。得到了简洁的解答之后，绝望的戴森又问费米对理论计算与实验测量结果的相符做何感想。费米反问道：“你们在计算过程中引入了多少个任意参数？”戴森回答说四个。于是费米讲了一句日后很著名的话：“<strong>我记得我的朋友约翰·冯·诺依曼（John von Neumann）曾经说过，用四个参数我可以拟合出一头大象，而用五个参数我可以让它的鼻子摆动。</strong>”对话结束了，沮丧的戴森赶回康奈尔大学，向自己的学生告知了费米的意见。尽管他们决定还是把手头的计算做完并发表，但达成共识：这个工作之后就转换研究方向。</p>
<p>故事可能是搞笑成分居多，甚至2010年6月，Jurgen Mayer也发表了题为“<a href="https://publications.mpi-cbg.de/Mayer_2010_4314.pdf" target="_blank" rel="external">用四个复参数画出一头大象</a>”的有点戏谑的论文。<br>其实有些理论参数最多达二十几，但是太多参数限制了理论的自由度，不论是从理论分析还是实践，简洁是最好的选择。自爱因斯坦玻尔海森堡等黄金时代科学家那一代，费米／奥本海默等是少有的理论和实验均有造诣，他们都参与了原子弹的研发，此后估计物理学理论和实验<a href="http://blog.sciencenet.cn/blog-3779-803730.html" target="_blank" rel="external">似乎走上了不同的道路</a>。<br><a href="http://blog.sciencenet.cn/blog-3779-1071332.html" target="_blank" rel="external">http://blog.sciencenet.cn/blog-3779-1071332.html</a><br>这里也有一个<a href="http://www.wolframalpha.com/input/?i=elephant+curve&amp;lk=1&amp;a=ClashPrefs_*PlaneCurve.ElephantCurve-" target="_blank" rel="external">wolframalpha版本的大象拟合</a>, 有兴趣可以输入 heart curve看看，在马上到来的七夕之前. Matrix67也有文章描述怎么画一个breoken heart curve。<br><img alt="Elephant Curve" src="http://www5b.wolframalpha.com/Calculate/MSP/MSP131520778i9g08099ai40000587f1ig8cd9a32c4?MSPStoreType=image/gif&s=41" width="480" data-file-width="480" data-file-height="409"><br>来源：<a href="https://en.wikiquote.org/wiki/John_von_Neumann" target="_blank" rel="external">wikiquote John_von_Neumann</a></p>
</li>
<li>摘自月光的blog：<br>布林和佩奇到了中国后，在访问百度公司时，李彦宏邀请他们吃Subway三明治，布林和佩奇拒绝了。<br>Google中文域名的前期准备活动正在有条不紊的进行之中，直到2005年5月7号，一份意料之外的电子邮件飞进了埃里克·施密特（Eric Schmidt）收件箱中。这份邮件来自微软一位名叫李开复的计算机专家兼高层。“我已经听说Google正准备进军中国市场。”他在邮件中写道：“我想告诉你的是，如果Google真有意在华大干一番，我会有兴趣跟你谈谈。”<br>。。。<br>2009年6月，新出现的问题牵涉到Google搜索建议（Google Suggest），用户在搜索框中输入一两个词字时，就立即显示完整的搜索关键词。Google搜索团队意识到中文用户因嫌打字麻烦通常只会在搜索框中输入一些短的关键词，这一创新功能最初就是针对此问题在中国开发出来的，最后才在全球范围应用开来。但中国官方发现令其不安的内容，搜索建议提供的一些内容与色情有关。<br>2010年3月，粉丝在中国总部门前的Google标志边上点亮蜡烛，留下鲜花和卡片，写下祝福话语。<br>对于Google中国的雇员，这天让人终身难忘。他们中没有人事先到消息。大卫在北京时间上午6点的时候发布了公告。北京和上海的不少Googler都是在同事叫醒他们后，才第一次听到这条消息的。员工涌入办公室，一脸地惊讶。那天下午，Google告诉所有雇员不用上班，给他们发电影片去看《阿凡达》。第二天，所有人都聚集在咖啡厅，与布林以及其他高管开电话会议，几位高管在会议上试图解释Google这样做的原因。这并非易事。Google的新任政府公关负责人朱莉·朱对员工和海外高层做了一次感性的陈词。山景城的高层犹如是战场上抛弃了自己士兵的将军。她争辩道，你们不应该放弃，你们应该继续战斗下。<br>李开复称，如果眼光放长点（20年或30年后）看中国，中国无疑会变得越来越开放。Google撤出大陆的决定只是这一进程的插曲，此次事件的导火索主要是由于中国领导人已经退到底线了。“不出两年的时间，下一代将走上舞台。”李开复说。“他们更年轻，更进步，许多受过美国的教育。许多在商界工作，掌管银行业——他们会变得更加开放。”</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://gao-xianglong.iteye.com/blog/2390697?from=thomaslau.github.io&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;优雅停机&lt;/a&gt;&lt;br&gt;dubbo原生是支持优雅停机的，其实也就是采用JDK的ShudownHook来实现，当然仅限kill -15 PID。这里也顺带说一下dubbo优雅停机的原理，如下所示：&lt;br&gt;服务提供方&lt;br&gt;· 停止时，先标记为不接收新请求，新请求过来时直接报错，让客户端重试其它机器。&lt;br&gt;· 然后，检测线程池中的线程是否正在运行，如果有，等待所有线程执行完成，除非超时，则强制关闭。&lt;br&gt;服务消费方&lt;br&gt;· 停止时，不再发起新的调用请求，所有新的调用在客户端即报错。&lt;br&gt;· 然后，检测有没有请求的响应还没有返回，等待响应返回，除非超时，则强制关闭。
    
    </summary>
    
    
      <category term="Tech" scheme="http://thomaslau.github.io/tags/Tech/"/>
    
      <category term="weeklyreading" scheme="http://thomaslau.github.io/tags/weeklyreading/"/>
    
  </entry>
  
</feed>
